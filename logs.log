2024-06-13 09:14:02,859:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 09:14:02,859:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 09:14:02,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 09:14:02,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 09:14:13,837:INFO:PyCaret ClassificationExperiment
2024-06-13 09:14:13,837:INFO:Logging name: credit
2024-06-13 09:14:13,837:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-13 09:14:13,838:INFO:version 3.3.2
2024-06-13 09:14:13,838:INFO:Initializing setup()
2024-06-13 09:14:13,838:INFO:self.USI: 0bef
2024-06-13 09:14:13,838:INFO:self._variable_keys: {'memory', 'pipeline', 'log_plots_param', 'fold_groups_param', 'target_param', 'fold_generator', 'html_param', 'n_jobs_param', 'fold_shuffle_param', 'seed', 'is_multiclass', 'y', 'exp_id', 'y_train', 'X', 'X_test', 'data', 'idx', 'X_train', '_available_plots', 'logging_param', '_ml_usecase', 'fix_imbalance', 'exp_name_log', 'y_test', 'gpu_param', 'USI', 'gpu_n_jobs_param'}
2024-06-13 09:14:13,838:INFO:Checking environment
2024-06-13 09:14:13,838:INFO:python_version: 3.11.1
2024-06-13 09:14:13,838:INFO:python_build: ('tags/v3.11.1:a7a450f', 'Dec  6 2022 19:58:39')
2024-06-13 09:14:13,838:INFO:machine: AMD64
2024-06-13 09:14:13,838:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-13 09:14:13,842:INFO:Memory: svmem(total=25760481280, available=16306327552, percent=36.7, used=9454153728, free=16306327552)
2024-06-13 09:14:13,842:INFO:Physical Core: 6
2024-06-13 09:14:13,842:INFO:Logical Core: 12
2024-06-13 09:14:13,843:INFO:Checking libraries
2024-06-13 09:14:13,843:INFO:System:
2024-06-13 09:14:13,843:INFO:    python: 3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]
2024-06-13 09:14:13,843:INFO:executable: e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\python.exe
2024-06-13 09:14:13,843:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-13 09:14:13,843:INFO:PyCaret required dependencies:
2024-06-13 09:14:14,126:INFO:                 pip: 22.3.1
2024-06-13 09:14:14,126:INFO:          setuptools: 65.5.0
2024-06-13 09:14:14,126:INFO:             pycaret: 3.3.2
2024-06-13 09:14:14,126:INFO:             IPython: 8.25.0
2024-06-13 09:14:14,126:INFO:          ipywidgets: 8.1.3
2024-06-13 09:14:14,127:INFO:                tqdm: 4.66.4
2024-06-13 09:14:14,127:INFO:               numpy: 1.26.4
2024-06-13 09:14:14,127:INFO:              pandas: 2.1.4
2024-06-13 09:14:14,127:INFO:              jinja2: 3.1.4
2024-06-13 09:14:14,127:INFO:               scipy: 1.11.4
2024-06-13 09:14:14,127:INFO:              joblib: 1.3.2
2024-06-13 09:14:14,127:INFO:             sklearn: 1.4.2
2024-06-13 09:14:14,127:INFO:                pyod: 2.0.0
2024-06-13 09:14:14,127:INFO:            imblearn: 0.12.3
2024-06-13 09:14:14,127:INFO:   category_encoders: 2.6.3
2024-06-13 09:14:14,127:INFO:            lightgbm: 4.3.0
2024-06-13 09:14:14,128:INFO:               numba: 0.59.1
2024-06-13 09:14:14,128:INFO:            requests: 2.32.3
2024-06-13 09:14:14,128:INFO:          matplotlib: 3.7.5
2024-06-13 09:14:14,128:INFO:          scikitplot: 0.3.7
2024-06-13 09:14:14,128:INFO:         yellowbrick: 1.5
2024-06-13 09:14:14,128:INFO:              plotly: 5.22.0
2024-06-13 09:14:14,128:INFO:    plotly-resampler: Not installed
2024-06-13 09:14:14,128:INFO:             kaleido: 0.2.1
2024-06-13 09:14:14,128:INFO:           schemdraw: 0.15
2024-06-13 09:14:14,128:INFO:         statsmodels: 0.14.2
2024-06-13 09:14:14,128:INFO:              sktime: 0.26.0
2024-06-13 09:14:14,129:INFO:               tbats: 1.1.3
2024-06-13 09:14:14,129:INFO:            pmdarima: 2.0.4
2024-06-13 09:14:14,129:INFO:              psutil: 5.9.8
2024-06-13 09:14:14,129:INFO:          markupsafe: 2.1.5
2024-06-13 09:14:14,129:INFO:             pickle5: Not installed
2024-06-13 09:14:14,129:INFO:         cloudpickle: 3.0.0
2024-06-13 09:14:14,129:INFO:         deprecation: 2.1.0
2024-06-13 09:14:14,129:INFO:              xxhash: 3.4.1
2024-06-13 09:14:14,129:INFO:           wurlitzer: Not installed
2024-06-13 09:14:14,129:INFO:PyCaret optional dependencies:
2024-06-13 09:14:14,177:INFO:                shap: Not installed
2024-06-13 09:14:14,177:INFO:           interpret: Not installed
2024-06-13 09:14:14,177:INFO:                umap: Not installed
2024-06-13 09:14:14,178:INFO:     ydata_profiling: Not installed
2024-06-13 09:14:14,178:INFO:  explainerdashboard: Not installed
2024-06-13 09:14:14,178:INFO:             autoviz: Not installed
2024-06-13 09:14:14,178:INFO:           fairlearn: Not installed
2024-06-13 09:14:14,178:INFO:          deepchecks: Not installed
2024-06-13 09:14:14,178:INFO:             xgboost: Not installed
2024-06-13 09:14:14,178:INFO:            catboost: Not installed
2024-06-13 09:14:14,178:INFO:              kmodes: Not installed
2024-06-13 09:14:14,179:INFO:             mlxtend: Not installed
2024-06-13 09:14:14,179:INFO:       statsforecast: Not installed
2024-06-13 09:14:14,179:INFO:        tune_sklearn: Not installed
2024-06-13 09:14:14,179:INFO:                 ray: Not installed
2024-06-13 09:14:14,179:INFO:            hyperopt: Not installed
2024-06-13 09:14:14,179:INFO:              optuna: Not installed
2024-06-13 09:14:14,180:INFO:               skopt: Not installed
2024-06-13 09:14:14,180:INFO:              mlflow: Not installed
2024-06-13 09:14:14,180:INFO:              gradio: Not installed
2024-06-13 09:14:14,180:INFO:             fastapi: Not installed
2024-06-13 09:14:14,180:INFO:             uvicorn: Not installed
2024-06-13 09:14:14,180:INFO:              m2cgen: Not installed
2024-06-13 09:14:14,181:INFO:           evidently: Not installed
2024-06-13 09:14:14,181:INFO:               fugue: Not installed
2024-06-13 09:14:14,181:INFO:           streamlit: Not installed
2024-06-13 09:14:14,181:INFO:             prophet: Not installed
2024-06-13 09:14:14,181:INFO:None
2024-06-13 09:14:14,181:INFO:Set up data.
2024-06-13 09:14:14,298:INFO:Set up folding strategy.
2024-06-13 09:14:14,298:INFO:Set up train/test split.
2024-06-13 09:14:14,672:INFO:Set up index.
2024-06-13 09:14:14,716:INFO:Assigning column types.
2024-06-13 09:14:14,843:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-13 09:14:14,953:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-13 09:14:14,962:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 09:14:15,060:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:15,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:15,167:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-13 09:14:15,168:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 09:14:15,233:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:15,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:15,235:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-13 09:14:15,355:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 09:14:15,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:15,453:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:15,561:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 09:14:15,628:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:15,628:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:15,628:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-13 09:14:15,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:15,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:16,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:16,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:16,006:INFO:Preparing preprocessing pipeline...
2024-06-13 09:14:16,032:INFO:Set up simple imputation.
2024-06-13 09:14:16,686:INFO:Set up encoding of ordinal features.
2024-06-13 09:14:16,730:INFO:Set up encoding of categorical features.
2024-06-13 09:14:16,731:INFO:Set up column transformation.
2024-06-13 09:14:16,731:INFO:Set up feature normalization.
2024-06-13 09:14:19,244:INFO:Finished creating preprocessing pipeline.
2024-06-13 09:14:19,272:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-06-13 09:14:19,272:INFO:Creating final display dataframe.
2024-06-13 09:14:21,616:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target              mau
2                   Target type           Binary
3           Original data shape     (600000, 13)
4        Transformed data shape     (600000, 30)
5   Transformed train set shape     (420000, 30)
6    Transformed test set shape     (180000, 30)
7              Numeric features                5
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Transformation             True
16        Transformation method         quantile
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           credit
25                          USI             0bef
2024-06-13 09:14:21,797:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:21,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:21,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:21,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:21,992:INFO:setup() successfully completed in 8.3s...............
2024-06-13 09:14:22,001:INFO:gpu_param set to False
2024-06-13 09:14:22,178:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:22,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:22,360:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:22,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:14:22,379:INFO:Initializing create_model()
2024-06-13 09:14:22,379:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB32EC3990>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 09:14:22,379:INFO:Checking exceptions
2024-06-13 09:14:22,404:INFO:Importing libraries
2024-06-13 09:14:22,404:INFO:Copying training dataset
2024-06-13 09:14:22,818:INFO:Defining folds
2024-06-13 09:14:22,818:INFO:Declaring metric variables
2024-06-13 09:14:22,822:INFO:Importing untrained model
2024-06-13 09:14:22,826:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 09:14:22,835:INFO:Starting cross validation
2024-06-13 09:14:22,838:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 09:15:19,302:INFO:Calculating mean and std
2024-06-13 09:15:19,304:INFO:Creating metrics dataframe
2024-06-13 09:15:19,312:INFO:Finalizing model
2024-06-13 09:15:29,306:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-13 09:15:29,307:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-06-13 09:15:29,360:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020767 seconds.
2024-06-13 09:15:29,361:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-13 09:15:29,361:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-13 09:15:29,361:INFO:[LightGBM] [Info] Total Bins 643
2024-06-13 09:15:29,362:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-06-13 09:15:29,365:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-06-13 09:15:29,365:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-06-13 09:15:30,409:INFO:Uploading results into container
2024-06-13 09:15:30,412:INFO:Uploading model into container now
2024-06-13 09:15:30,437:INFO:_master_model_container: 1
2024-06-13 09:15:30,438:INFO:_display_container: 2
2024-06-13 09:15:30,440:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 09:15:30,440:INFO:create_model() successfully completed......................................
2024-06-13 09:15:30,695:INFO:Initializing tune_model()
2024-06-13 09:15:30,696:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB32EC3990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=1, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-13 09:15:30,696:INFO:Checking exceptions
2024-06-13 09:15:30,928:INFO:Copying training dataset
2024-06-13 09:15:31,234:INFO:Checking base model
2024-06-13 09:15:31,234:INFO:Base model : Light Gradient Boosting Machine
2024-06-13 09:15:31,240:INFO:Declaring metric variables
2024-06-13 09:15:31,246:INFO:Defining Hyperparameters
2024-06-13 09:15:31,587:INFO:Tuning with n_jobs=-1
2024-06-13 09:15:31,587:INFO:Initializing RandomizedSearchCV
2024-06-13 09:16:18,777:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.7}
2024-06-13 09:16:18,778:INFO:Hyperparameter search completed
2024-06-13 09:16:18,779:INFO:SubProcess create_model() called ==================================
2024-06-13 09:16:18,779:INFO:Initializing create_model()
2024-06-13 09:16:18,779:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB32EC3990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB51E5EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 3, 'num_leaves': 256, 'n_estimators': 30, 'min_split_gain': 0.2, 'min_child_samples': 1, 'learning_rate': 0.0005, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.7})
2024-06-13 09:16:18,780:INFO:Checking exceptions
2024-06-13 09:16:18,780:INFO:Importing libraries
2024-06-13 09:16:18,780:INFO:Copying training dataset
2024-06-13 09:16:19,200:INFO:Defining folds
2024-06-13 09:16:19,200:INFO:Declaring metric variables
2024-06-13 09:16:19,205:INFO:Importing untrained model
2024-06-13 09:16:19,205:INFO:Declaring custom model
2024-06-13 09:16:19,211:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 09:16:19,220:INFO:Starting cross validation
2024-06-13 09:16:19,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 09:17:02,589:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:17:03,045:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:17:03,238:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:17:03,400:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:17:04,112:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:17:04,423:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:17:04,750:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:17:04,873:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:17:05,646:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:17:05,753:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:17:05,932:INFO:Calculating mean and std
2024-06-13 09:17:05,936:INFO:Creating metrics dataframe
2024-06-13 09:17:05,950:INFO:Finalizing model
2024-06-13 09:17:14,813:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-06-13 09:17:14,814:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-13 09:17:14,814:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-13 09:17:15,272:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-13 09:17:15,273:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-06-13 09:17:15,273:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-13 09:17:15,273:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-13 09:17:15,274:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-06-13 09:17:15,335:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020698 seconds.
2024-06-13 09:17:15,335:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-13 09:17:15,335:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-13 09:17:15,335:INFO:[LightGBM] [Info] Total Bins 647
2024-06-13 09:17:15,336:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 29
2024-06-13 09:17:15,343:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-06-13 09:17:15,343:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-06-13 09:17:15,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:17:15,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:17:15,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:17:16,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:17:16,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:17:16,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:17:16,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:17:16,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:17:16,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:17:16,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:17:16,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:17:16,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:17:16,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:17:16,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:17:16,907:INFO:Uploading results into container
2024-06-13 09:17:16,908:INFO:Uploading model into container now
2024-06-13 09:17:16,909:INFO:_master_model_container: 2
2024-06-13 09:17:16,910:INFO:_display_container: 3
2024-06-13 09:17:16,911:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 09:17:16,911:INFO:create_model() successfully completed......................................
2024-06-13 09:17:17,137:INFO:SubProcess create_model() end ==================================
2024-06-13 09:17:17,137:INFO:choose_better activated
2024-06-13 09:17:17,141:INFO:SubProcess create_model() called ==================================
2024-06-13 09:17:17,142:INFO:Initializing create_model()
2024-06-13 09:17:17,142:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB32EC3990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 09:17:17,142:INFO:Checking exceptions
2024-06-13 09:17:17,144:INFO:Importing libraries
2024-06-13 09:17:17,145:INFO:Copying training dataset
2024-06-13 09:17:17,534:INFO:Defining folds
2024-06-13 09:17:17,534:INFO:Declaring metric variables
2024-06-13 09:17:17,534:INFO:Importing untrained model
2024-06-13 09:17:17,535:INFO:Declaring custom model
2024-06-13 09:17:17,535:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 09:17:17,536:INFO:Starting cross validation
2024-06-13 09:17:17,538:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 09:18:05,783:INFO:Calculating mean and std
2024-06-13 09:18:05,784:INFO:Creating metrics dataframe
2024-06-13 09:18:05,786:INFO:Finalizing model
2024-06-13 09:18:15,195:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-13 09:18:15,196:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-06-13 09:18:15,249:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019744 seconds.
2024-06-13 09:18:15,249:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-13 09:18:15,249:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-13 09:18:15,250:INFO:[LightGBM] [Info] Total Bins 643
2024-06-13 09:18:15,250:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-06-13 09:18:15,253:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-06-13 09:18:15,253:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-06-13 09:18:16,245:INFO:Uploading results into container
2024-06-13 09:18:16,245:INFO:Uploading model into container now
2024-06-13 09:18:16,246:INFO:_master_model_container: 3
2024-06-13 09:18:16,246:INFO:_display_container: 4
2024-06-13 09:18:16,247:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 09:18:16,247:INFO:create_model() successfully completed......................................
2024-06-13 09:18:16,470:INFO:SubProcess create_model() end ==================================
2024-06-13 09:18:16,471:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0113
2024-06-13 09:18:16,471:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0
2024-06-13 09:18:16,472:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-13 09:18:16,472:INFO:choose_better completed
2024-06-13 09:18:16,472:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-06-13 09:18:16,484:INFO:_master_model_container: 3
2024-06-13 09:18:16,484:INFO:_display_container: 3
2024-06-13 09:18:16,485:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 09:18:16,485:INFO:tune_model() successfully completed......................................
2024-06-13 09:18:16,720:INFO:Initializing plot_model()
2024-06-13 09:18:16,720:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB32EC3990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 09:18:16,720:INFO:Checking exceptions
2024-06-13 09:18:16,862:INFO:Preloading libraries
2024-06-13 09:18:16,871:INFO:Copying training dataset
2024-06-13 09:18:16,871:INFO:Plot type: auc
2024-06-13 09:18:18,719:INFO:Fitting Model
2024-06-13 09:18:18,733:INFO:Scoring test/hold-out set
2024-06-13 09:18:19,627:INFO:Visual Rendered Successfully
2024-06-13 09:18:19,845:INFO:plot_model() successfully completed......................................
2024-06-13 09:18:19,901:INFO:Initializing plot_model()
2024-06-13 09:18:19,901:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB32EC3990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 09:18:19,901:INFO:Checking exceptions
2024-06-13 09:18:20,094:INFO:Preloading libraries
2024-06-13 09:18:20,102:INFO:Copying training dataset
2024-06-13 09:18:20,102:INFO:Plot type: pr
2024-06-13 09:18:21,674:INFO:Fitting Model
2024-06-13 09:18:21,696:INFO:Scoring test/hold-out set
2024-06-13 09:18:22,423:INFO:Visual Rendered Successfully
2024-06-13 09:18:22,637:INFO:plot_model() successfully completed......................................
2024-06-13 09:18:22,654:INFO:Initializing plot_model()
2024-06-13 09:18:22,654:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB32EC3990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 09:18:22,654:INFO:Checking exceptions
2024-06-13 09:18:22,793:INFO:Preloading libraries
2024-06-13 09:18:22,803:INFO:Copying training dataset
2024-06-13 09:18:22,804:INFO:Plot type: feature
2024-06-13 09:18:22,804:WARNING:No coef_ found. Trying feature_importances_
2024-06-13 09:18:23,574:INFO:Visual Rendered Successfully
2024-06-13 09:18:23,784:INFO:plot_model() successfully completed......................................
2024-06-13 09:18:23,803:INFO:Initializing plot_model()
2024-06-13 09:18:23,803:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB32EC3990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 09:18:23,803:INFO:Checking exceptions
2024-06-13 09:18:24,023:INFO:Preloading libraries
2024-06-13 09:18:24,035:INFO:Copying training dataset
2024-06-13 09:18:24,035:INFO:Plot type: confusion_matrix
2024-06-13 09:18:25,350:INFO:Fitting Model
2024-06-13 09:18:25,366:INFO:Scoring test/hold-out set
2024-06-13 09:18:25,925:INFO:Visual Rendered Successfully
2024-06-13 09:18:26,139:INFO:plot_model() successfully completed......................................
2024-06-13 09:18:26,206:INFO:Initializing predict_model()
2024-06-13 09:18:26,206:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB32EC3990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FB7B45B7E0>)
2024-06-13 09:18:26,206:INFO:Checking exceptions
2024-06-13 09:18:26,206:INFO:Preloading libraries
2024-06-13 09:18:28,300:INFO:Initializing finalize_model()
2024-06-13 09:18:28,300:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB32EC3990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-13 09:18:28,300:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 09:18:28,439:INFO:Initializing create_model()
2024-06-13 09:18:28,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB32EC3990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 09:18:28,439:INFO:Checking exceptions
2024-06-13 09:18:28,441:INFO:Importing libraries
2024-06-13 09:18:28,441:INFO:Copying training dataset
2024-06-13 09:18:28,453:INFO:Defining folds
2024-06-13 09:18:28,453:INFO:Declaring metric variables
2024-06-13 09:18:28,454:INFO:Importing untrained model
2024-06-13 09:18:28,454:INFO:Declaring custom model
2024-06-13 09:18:28,455:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 09:18:28,458:INFO:Cross validation set to False
2024-06-13 09:18:28,458:INFO:Fitting Model
2024-06-13 09:18:41,549:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-13 09:18:41,550:INFO:[LightGBM] [Info] Number of positive: 36643, number of negative: 563357
2024-06-13 09:18:41,637:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037722 seconds.
2024-06-13 09:18:41,637:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-13 09:18:41,637:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-13 09:18:41,637:INFO:[LightGBM] [Info] Total Bins 642
2024-06-13 09:18:41,648:INFO:[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 27
2024-06-13 09:18:41,649:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061072 -> initscore=-2.732691
2024-06-13 09:18:41,649:INFO:[LightGBM] [Info] Start training from score -2.732691
2024-06-13 09:18:43,210:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-13 09:18:43,210:INFO:create_model() successfully completed......................................
2024-06-13 09:18:43,424:INFO:_master_model_container: 3
2024-06-13 09:18:43,424:INFO:_display_container: 4
2024-06-13 09:18:43,450:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-13 09:18:43,450:INFO:finalize_model() successfully completed......................................
2024-06-13 09:18:43,771:INFO:Initializing predict_model()
2024-06-13 09:18:43,771:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB32EC3990>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FB48FE11C0>)
2024-06-13 09:18:43,771:INFO:Checking exceptions
2024-06-13 09:18:43,771:INFO:Preloading libraries
2024-06-13 09:18:43,771:INFO:Set up data.
2024-06-13 09:18:43,825:INFO:Set up index.
2024-06-13 09:18:46,987:INFO:Initializing save_model()
2024-06-13 09:18:46,987:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=Final Light GBM Model Jun2024, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-06-13 09:18:46,987:INFO:Adding model into prep_pipe
2024-06-13 09:18:46,987:WARNING:Only Model saved as it was a pipeline.
2024-06-13 09:18:47,000:INFO:Final Light GBM Model Jun2024.pkl saved in current working directory
2024-06-13 09:18:47,040:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-13 09:18:47,040:INFO:save_model() successfully completed......................................
2024-06-13 09:31:56,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 09:31:56,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 09:31:56,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 09:31:56,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 09:32:00,289:INFO:PyCaret ClassificationExperiment
2024-06-13 09:32:00,289:INFO:Logging name: credit
2024-06-13 09:32:00,290:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-13 09:32:00,290:INFO:version 3.3.2
2024-06-13 09:32:00,290:INFO:Initializing setup()
2024-06-13 09:32:00,290:INFO:self.USI: 5065
2024-06-13 09:32:00,290:INFO:self._variable_keys: {'fold_shuffle_param', 'exp_id', 'fold_groups_param', 'X_test', '_ml_usecase', 'X', 'seed', 'y_test', 'exp_name_log', 'y_train', 'data', 'memory', 'X_train', 'fix_imbalance', 'log_plots_param', 'is_multiclass', 'y', 'logging_param', 'html_param', 'idx', '_available_plots', 'pipeline', 'gpu_param', 'target_param', 'n_jobs_param', 'fold_generator', 'USI', 'gpu_n_jobs_param'}
2024-06-13 09:32:00,290:INFO:Checking environment
2024-06-13 09:32:00,290:INFO:python_version: 3.11.1
2024-06-13 09:32:00,290:INFO:python_build: ('tags/v3.11.1:a7a450f', 'Dec  6 2022 19:58:39')
2024-06-13 09:32:00,290:INFO:machine: AMD64
2024-06-13 09:32:00,290:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-13 09:32:00,294:INFO:Memory: svmem(total=25760481280, available=16421609472, percent=36.3, used=9338871808, free=16421609472)
2024-06-13 09:32:00,294:INFO:Physical Core: 6
2024-06-13 09:32:00,294:INFO:Logical Core: 12
2024-06-13 09:32:00,294:INFO:Checking libraries
2024-06-13 09:32:00,295:INFO:System:
2024-06-13 09:32:00,295:INFO:    python: 3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]
2024-06-13 09:32:00,295:INFO:executable: e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\python.exe
2024-06-13 09:32:00,295:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-13 09:32:00,295:INFO:PyCaret required dependencies:
2024-06-13 09:32:00,333:INFO:                 pip: 22.3.1
2024-06-13 09:32:00,333:INFO:          setuptools: 65.5.0
2024-06-13 09:32:00,333:INFO:             pycaret: 3.3.2
2024-06-13 09:32:00,333:INFO:             IPython: 8.25.0
2024-06-13 09:32:00,334:INFO:          ipywidgets: 8.1.3
2024-06-13 09:32:00,334:INFO:                tqdm: 4.66.4
2024-06-13 09:32:00,334:INFO:               numpy: 1.26.4
2024-06-13 09:32:00,334:INFO:              pandas: 2.1.4
2024-06-13 09:32:00,334:INFO:              jinja2: 3.1.4
2024-06-13 09:32:00,334:INFO:               scipy: 1.11.4
2024-06-13 09:32:00,334:INFO:              joblib: 1.3.2
2024-06-13 09:32:00,334:INFO:             sklearn: 1.4.2
2024-06-13 09:32:00,334:INFO:                pyod: 2.0.0
2024-06-13 09:32:00,334:INFO:            imblearn: 0.12.3
2024-06-13 09:32:00,334:INFO:   category_encoders: 2.6.3
2024-06-13 09:32:00,335:INFO:            lightgbm: 4.3.0
2024-06-13 09:32:00,335:INFO:               numba: 0.59.1
2024-06-13 09:32:00,335:INFO:            requests: 2.32.3
2024-06-13 09:32:00,335:INFO:          matplotlib: 3.7.5
2024-06-13 09:32:00,335:INFO:          scikitplot: 0.3.7
2024-06-13 09:32:00,335:INFO:         yellowbrick: 1.5
2024-06-13 09:32:00,335:INFO:              plotly: 5.22.0
2024-06-13 09:32:00,335:INFO:    plotly-resampler: Not installed
2024-06-13 09:32:00,335:INFO:             kaleido: 0.2.1
2024-06-13 09:32:00,335:INFO:           schemdraw: 0.15
2024-06-13 09:32:00,335:INFO:         statsmodels: 0.14.2
2024-06-13 09:32:00,336:INFO:              sktime: 0.26.0
2024-06-13 09:32:00,336:INFO:               tbats: 1.1.3
2024-06-13 09:32:00,336:INFO:            pmdarima: 2.0.4
2024-06-13 09:32:00,336:INFO:              psutil: 5.9.8
2024-06-13 09:32:00,336:INFO:          markupsafe: 2.1.5
2024-06-13 09:32:00,336:INFO:             pickle5: Not installed
2024-06-13 09:32:00,336:INFO:         cloudpickle: 3.0.0
2024-06-13 09:32:00,336:INFO:         deprecation: 2.1.0
2024-06-13 09:32:00,336:INFO:              xxhash: 3.4.1
2024-06-13 09:32:00,336:INFO:           wurlitzer: Not installed
2024-06-13 09:32:00,336:INFO:PyCaret optional dependencies:
2024-06-13 09:32:00,378:INFO:                shap: Not installed
2024-06-13 09:32:00,378:INFO:           interpret: Not installed
2024-06-13 09:32:00,378:INFO:                umap: Not installed
2024-06-13 09:32:00,379:INFO:     ydata_profiling: Not installed
2024-06-13 09:32:00,379:INFO:  explainerdashboard: Not installed
2024-06-13 09:32:00,379:INFO:             autoviz: Not installed
2024-06-13 09:32:00,379:INFO:           fairlearn: Not installed
2024-06-13 09:32:00,379:INFO:          deepchecks: Not installed
2024-06-13 09:32:00,379:INFO:             xgboost: Not installed
2024-06-13 09:32:00,379:INFO:            catboost: Not installed
2024-06-13 09:32:00,379:INFO:              kmodes: Not installed
2024-06-13 09:32:00,379:INFO:             mlxtend: Not installed
2024-06-13 09:32:00,379:INFO:       statsforecast: Not installed
2024-06-13 09:32:00,379:INFO:        tune_sklearn: Not installed
2024-06-13 09:32:00,380:INFO:                 ray: Not installed
2024-06-13 09:32:00,380:INFO:            hyperopt: Not installed
2024-06-13 09:32:00,380:INFO:              optuna: Not installed
2024-06-13 09:32:00,380:INFO:               skopt: Not installed
2024-06-13 09:32:00,380:INFO:              mlflow: Not installed
2024-06-13 09:32:00,380:INFO:              gradio: Not installed
2024-06-13 09:32:00,380:INFO:             fastapi: Not installed
2024-06-13 09:32:00,380:INFO:             uvicorn: Not installed
2024-06-13 09:32:00,380:INFO:              m2cgen: Not installed
2024-06-13 09:32:00,380:INFO:           evidently: Not installed
2024-06-13 09:32:00,380:INFO:               fugue: Not installed
2024-06-13 09:32:00,381:INFO:           streamlit: Not installed
2024-06-13 09:32:00,381:INFO:             prophet: Not installed
2024-06-13 09:32:00,381:INFO:None
2024-06-13 09:32:00,381:INFO:Set up data.
2024-06-13 09:32:00,506:INFO:Set up folding strategy.
2024-06-13 09:32:00,506:INFO:Set up train/test split.
2024-06-13 09:32:00,864:INFO:Set up index.
2024-06-13 09:32:00,905:INFO:Assigning column types.
2024-06-13 09:32:01,027:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-13 09:32:01,138:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-13 09:32:01,143:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 09:32:01,226:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:01,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:01,355:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-13 09:32:01,357:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 09:32:01,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:01,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:01,442:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-13 09:32:01,558:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 09:32:01,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:01,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:01,736:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 09:32:01,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:01,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:01,804:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-13 09:32:01,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:01,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:02,163:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:02,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:02,166:INFO:Preparing preprocessing pipeline...
2024-06-13 09:32:02,192:INFO:Set up simple imputation.
2024-06-13 09:32:02,713:INFO:Set up encoding of ordinal features.
2024-06-13 09:32:02,758:INFO:Set up encoding of categorical features.
2024-06-13 09:32:02,759:INFO:Set up column transformation.
2024-06-13 09:32:02,759:INFO:Set up feature normalization.
2024-06-13 09:32:04,360:INFO:Finished creating preprocessing pipeline.
2024-06-13 09:32:04,388:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-06-13 09:32:04,389:INFO:Creating final display dataframe.
2024-06-13 09:32:06,258:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target              mau
2                   Target type           Binary
3           Original data shape     (600000, 13)
4        Transformed data shape     (600000, 30)
5   Transformed train set shape     (420000, 30)
6    Transformed test set shape     (180000, 30)
7              Numeric features                5
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Transformation             True
16        Transformation method         quantile
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           credit
25                          USI             5065
2024-06-13 09:32:06,466:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:06,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:06,652:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:06,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:06,654:INFO:setup() successfully completed in 6.49s...............
2024-06-13 09:32:06,703:INFO:gpu_param set to False
2024-06-13 09:32:06,898:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:06,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:07,075:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:07,076:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 09:32:07,108:INFO:Initializing create_model()
2024-06-13 09:32:07,108:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015DC934BDD0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 09:32:07,108:INFO:Checking exceptions
2024-06-13 09:32:07,129:INFO:Importing libraries
2024-06-13 09:32:07,129:INFO:Copying training dataset
2024-06-13 09:32:07,580:INFO:Defining folds
2024-06-13 09:32:07,581:INFO:Declaring metric variables
2024-06-13 09:32:07,586:INFO:Importing untrained model
2024-06-13 09:32:07,591:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 09:32:07,599:INFO:Starting cross validation
2024-06-13 09:32:07,602:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 09:33:06,760:INFO:Calculating mean and std
2024-06-13 09:33:06,762:INFO:Creating metrics dataframe
2024-06-13 09:33:06,770:INFO:Finalizing model
2024-06-13 09:33:16,192:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-13 09:33:16,194:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-06-13 09:33:16,257:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026756 seconds.
2024-06-13 09:33:16,257:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-13 09:33:16,258:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-13 09:33:16,258:INFO:[LightGBM] [Info] Total Bins 643
2024-06-13 09:33:16,258:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-06-13 09:33:16,261:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-06-13 09:33:16,262:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-06-13 09:33:17,473:INFO:Uploading results into container
2024-06-13 09:33:17,474:INFO:Uploading model into container now
2024-06-13 09:33:17,496:INFO:_master_model_container: 1
2024-06-13 09:33:17,496:INFO:_display_container: 2
2024-06-13 09:33:17,497:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 09:33:17,497:INFO:create_model() successfully completed......................................
2024-06-13 09:33:17,753:INFO:Initializing tune_model()
2024-06-13 09:33:17,753:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015DC934BDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=1, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-13 09:33:17,753:INFO:Checking exceptions
2024-06-13 09:33:18,064:INFO:Copying training dataset
2024-06-13 09:33:18,357:INFO:Checking base model
2024-06-13 09:33:18,357:INFO:Base model : Light Gradient Boosting Machine
2024-06-13 09:33:18,362:INFO:Declaring metric variables
2024-06-13 09:33:18,366:INFO:Defining Hyperparameters
2024-06-13 09:33:18,590:INFO:Tuning with n_jobs=-1
2024-06-13 09:33:18,590:INFO:Initializing RandomizedSearchCV
2024-06-13 09:34:09,361:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.7}
2024-06-13 09:34:09,362:INFO:Hyperparameter search completed
2024-06-13 09:34:09,362:INFO:SubProcess create_model() called ==================================
2024-06-13 09:34:09,363:INFO:Initializing create_model()
2024-06-13 09:34:09,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015DC934BDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015DB2C0AAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 3, 'num_leaves': 256, 'n_estimators': 30, 'min_split_gain': 0.2, 'min_child_samples': 1, 'learning_rate': 0.0005, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.7})
2024-06-13 09:34:09,363:INFO:Checking exceptions
2024-06-13 09:34:09,363:INFO:Importing libraries
2024-06-13 09:34:09,364:INFO:Copying training dataset
2024-06-13 09:34:09,883:INFO:Defining folds
2024-06-13 09:34:09,884:INFO:Declaring metric variables
2024-06-13 09:34:09,889:INFO:Importing untrained model
2024-06-13 09:34:09,889:INFO:Declaring custom model
2024-06-13 09:34:09,895:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 09:34:09,905:INFO:Starting cross validation
2024-06-13 09:34:09,909:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 09:34:53,575:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:34:53,749:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:34:54,971:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:34:55,052:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:34:55,194:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:34:55,418:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:34:55,450:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:34:56,380:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:34:56,453:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:34:56,629:WARNING:e:\rafael-doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 09:34:56,783:INFO:Calculating mean and std
2024-06-13 09:34:56,784:INFO:Creating metrics dataframe
2024-06-13 09:34:56,791:INFO:Finalizing model
2024-06-13 09:35:05,630:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-06-13 09:35:05,630:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-13 09:35:05,630:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-13 09:35:06,100:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-13 09:35:06,101:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-06-13 09:35:06,101:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-13 09:35:06,101:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-13 09:35:06,102:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-06-13 09:35:06,175:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025490 seconds.
2024-06-13 09:35:06,175:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-13 09:35:06,175:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-13 09:35:06,175:INFO:[LightGBM] [Info] Total Bins 647
2024-06-13 09:35:06,176:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 29
2024-06-13 09:35:06,182:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-06-13 09:35:06,182:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-06-13 09:35:06,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:35:06,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:35:06,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:35:06,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:35:06,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:35:06,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:35:07,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:35:07,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:35:07,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:35:07,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:35:07,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:35:07,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:35:07,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:35:07,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 09:35:07,420:INFO:Uploading results into container
2024-06-13 09:35:07,422:INFO:Uploading model into container now
2024-06-13 09:35:07,422:INFO:_master_model_container: 2
2024-06-13 09:35:07,423:INFO:_display_container: 3
2024-06-13 09:35:07,423:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 09:35:07,424:INFO:create_model() successfully completed......................................
2024-06-13 09:35:07,654:INFO:SubProcess create_model() end ==================================
2024-06-13 09:35:07,654:INFO:choose_better activated
2024-06-13 09:35:07,658:INFO:SubProcess create_model() called ==================================
2024-06-13 09:35:07,659:INFO:Initializing create_model()
2024-06-13 09:35:07,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015DC934BDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 09:35:07,659:INFO:Checking exceptions
2024-06-13 09:35:07,662:INFO:Importing libraries
2024-06-13 09:35:07,662:INFO:Copying training dataset
2024-06-13 09:35:08,089:INFO:Defining folds
2024-06-13 09:35:08,089:INFO:Declaring metric variables
2024-06-13 09:35:08,089:INFO:Importing untrained model
2024-06-13 09:35:08,089:INFO:Declaring custom model
2024-06-13 09:35:08,090:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 09:35:08,090:INFO:Starting cross validation
2024-06-13 09:35:08,093:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 09:36:00,615:INFO:Calculating mean and std
2024-06-13 09:36:00,617:INFO:Creating metrics dataframe
2024-06-13 09:36:00,622:INFO:Finalizing model
2024-06-13 09:36:10,381:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-13 09:36:10,383:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-06-13 09:36:10,461:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027245 seconds.
2024-06-13 09:36:10,461:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-13 09:36:10,461:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-13 09:36:10,462:INFO:[LightGBM] [Info] Total Bins 643
2024-06-13 09:36:10,462:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-06-13 09:36:10,465:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-06-13 09:36:10,466:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-06-13 09:36:11,859:INFO:Uploading results into container
2024-06-13 09:36:11,860:INFO:Uploading model into container now
2024-06-13 09:36:11,861:INFO:_master_model_container: 3
2024-06-13 09:36:11,861:INFO:_display_container: 4
2024-06-13 09:36:11,862:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 09:36:11,862:INFO:create_model() successfully completed......................................
2024-06-13 09:36:12,101:INFO:SubProcess create_model() end ==================================
2024-06-13 09:36:12,102:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0113
2024-06-13 09:36:12,103:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0
2024-06-13 09:36:12,104:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-13 09:36:12,104:INFO:choose_better completed
2024-06-13 09:36:12,105:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-06-13 09:36:12,118:INFO:_master_model_container: 3
2024-06-13 09:36:12,118:INFO:_display_container: 3
2024-06-13 09:36:12,119:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 09:36:12,119:INFO:tune_model() successfully completed......................................
2024-06-13 09:36:12,360:INFO:Initializing plot_model()
2024-06-13 09:36:12,360:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015DC934BDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 09:36:12,360:INFO:Checking exceptions
2024-06-13 09:36:12,539:INFO:Preloading libraries
2024-06-13 09:36:12,550:INFO:Copying training dataset
2024-06-13 09:36:12,550:INFO:Plot type: auc
2024-06-13 09:36:14,166:INFO:Fitting Model
2024-06-13 09:36:14,182:INFO:Scoring test/hold-out set
2024-06-13 09:36:15,143:INFO:Visual Rendered Successfully
2024-06-13 09:36:15,369:INFO:plot_model() successfully completed......................................
2024-06-13 09:36:15,399:INFO:Initializing plot_model()
2024-06-13 09:36:15,399:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015DC934BDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 09:36:15,400:INFO:Checking exceptions
2024-06-13 09:36:15,565:INFO:Preloading libraries
2024-06-13 09:36:15,575:INFO:Copying training dataset
2024-06-13 09:36:15,575:INFO:Plot type: pr
2024-06-13 09:36:17,242:INFO:Fitting Model
2024-06-13 09:36:17,265:INFO:Scoring test/hold-out set
2024-06-13 09:36:18,111:INFO:Visual Rendered Successfully
2024-06-13 09:36:18,345:INFO:plot_model() successfully completed......................................
2024-06-13 09:36:18,362:INFO:Initializing plot_model()
2024-06-13 09:36:18,362:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015DC934BDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 09:36:18,362:INFO:Checking exceptions
2024-06-13 09:36:18,540:INFO:Preloading libraries
2024-06-13 09:36:18,550:INFO:Copying training dataset
2024-06-13 09:36:18,550:INFO:Plot type: feature
2024-06-13 09:36:18,551:WARNING:No coef_ found. Trying feature_importances_
2024-06-13 09:36:19,356:INFO:Visual Rendered Successfully
2024-06-13 09:36:19,619:INFO:plot_model() successfully completed......................................
2024-06-13 09:36:19,667:INFO:Initializing plot_model()
2024-06-13 09:36:19,667:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015DC934BDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 09:36:19,667:INFO:Checking exceptions
2024-06-13 09:36:19,892:INFO:Preloading libraries
2024-06-13 09:36:19,902:INFO:Copying training dataset
2024-06-13 09:36:19,902:INFO:Plot type: confusion_matrix
2024-06-13 09:36:21,411:INFO:Fitting Model
2024-06-13 09:36:21,419:INFO:Scoring test/hold-out set
2024-06-13 09:36:22,060:INFO:Visual Rendered Successfully
2024-06-13 09:36:22,286:INFO:plot_model() successfully completed......................................
2024-06-13 09:36:22,358:INFO:Initializing predict_model()
2024-06-13 09:36:22,358:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015DC934BDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000015DAC411760>)
2024-06-13 09:36:22,358:INFO:Checking exceptions
2024-06-13 09:36:22,358:INFO:Preloading libraries
2024-06-13 09:36:24,749:INFO:Initializing finalize_model()
2024-06-13 09:36:24,750:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015DC934BDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-13 09:36:24,750:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 09:36:24,860:INFO:Initializing create_model()
2024-06-13 09:36:24,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015DC934BDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 09:36:24,860:INFO:Checking exceptions
2024-06-13 09:36:24,862:INFO:Importing libraries
2024-06-13 09:36:24,862:INFO:Copying training dataset
2024-06-13 09:36:24,875:INFO:Defining folds
2024-06-13 09:36:24,876:INFO:Declaring metric variables
2024-06-13 09:36:24,876:INFO:Importing untrained model
2024-06-13 09:36:24,876:INFO:Declaring custom model
2024-06-13 09:36:24,877:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 09:36:24,880:INFO:Cross validation set to False
2024-06-13 09:36:24,881:INFO:Fitting Model
2024-06-13 09:36:38,980:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-13 09:36:38,981:INFO:[LightGBM] [Info] Number of positive: 36643, number of negative: 563357
2024-06-13 09:36:39,068:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028621 seconds.
2024-06-13 09:36:39,068:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-13 09:36:39,068:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-13 09:36:39,068:INFO:[LightGBM] [Info] Total Bins 642
2024-06-13 09:36:39,069:INFO:[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 27
2024-06-13 09:36:39,073:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061072 -> initscore=-2.732691
2024-06-13 09:36:39,073:INFO:[LightGBM] [Info] Start training from score -2.732691
2024-06-13 09:36:41,255:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-13 09:36:41,255:INFO:create_model() successfully completed......................................
2024-06-13 09:36:41,491:INFO:_master_model_container: 3
2024-06-13 09:36:41,491:INFO:_display_container: 4
2024-06-13 09:36:41,521:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-13 09:36:41,521:INFO:finalize_model() successfully completed......................................
2024-06-13 09:36:41,907:INFO:Initializing predict_model()
2024-06-13 09:36:41,908:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015DC934BDD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000015DBA3F42C0>)
2024-06-13 09:36:41,908:INFO:Checking exceptions
2024-06-13 09:36:41,908:INFO:Preloading libraries
2024-06-13 09:36:41,911:INFO:Set up data.
2024-06-13 09:36:41,945:INFO:Set up index.
2024-06-13 09:36:45,348:INFO:Initializing save_model()
2024-06-13 09:36:45,348:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=Final Light GBM Model Jun2024, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-06-13 09:36:45,348:INFO:Adding model into prep_pipe
2024-06-13 09:36:45,348:WARNING:Only Model saved as it was a pipeline.
2024-06-13 09:36:45,398:INFO:Final Light GBM Model Jun2024.pkl saved in current working directory
2024-06-13 09:36:45,457:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-13 09:36:45,458:INFO:save_model() successfully completed......................................
2024-07-08 09:45:03,209:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-08 09:45:03,209:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-08 09:45:03,209:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-08 09:45:03,209:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-08 09:45:06,366:INFO:PyCaret ClassificationExperiment
2024-07-08 09:45:06,367:INFO:Logging name: credit
2024-07-08 09:45:06,367:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-08 09:45:06,367:INFO:version 3.3.2
2024-07-08 09:45:06,367:INFO:Initializing setup()
2024-07-08 09:45:06,367:INFO:self.USI: cdfe
2024-07-08 09:45:06,367:INFO:self._variable_keys: {'seed', 'data', 'logging_param', 'n_jobs_param', 'exp_name_log', 'fold_generator', 'pipeline', 'is_multiclass', 'y_test', 'X_train', '_ml_usecase', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y', 'gpu_param', 'idx', 'fold_shuffle_param', 'log_plots_param', 'X', 'target_param', 'y_train', 'X_test', 'fold_groups_param', 'USI', 'memory', 'exp_id'}
2024-07-08 09:45:06,367:INFO:Checking environment
2024-07-08 09:45:06,367:INFO:python_version: 3.11.7
2024-07-08 09:45:06,367:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2024-07-08 09:45:06,368:INFO:machine: AMD64
2024-07-08 09:45:06,368:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-08 09:45:06,372:INFO:Memory: svmem(total=16849293312, available=4145512448, percent=75.4, used=12703780864, free=4145512448)
2024-07-08 09:45:06,372:INFO:Physical Core: 12
2024-07-08 09:45:06,373:INFO:Logical Core: 16
2024-07-08 09:45:06,373:INFO:Checking libraries
2024-07-08 09:45:06,373:INFO:System:
2024-07-08 09:45:06,373:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2024-07-08 09:45:06,373:INFO:executable: c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\python.exe
2024-07-08 09:45:06,373:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-08 09:45:06,373:INFO:PyCaret required dependencies:
2024-07-08 09:45:06,407:INFO:                 pip: 24.1.2
2024-07-08 09:45:06,407:INFO:          setuptools: 65.5.0
2024-07-08 09:45:06,407:INFO:             pycaret: 3.3.2
2024-07-08 09:45:06,407:INFO:             IPython: 8.26.0
2024-07-08 09:45:06,408:INFO:          ipywidgets: 8.1.3
2024-07-08 09:45:06,408:INFO:                tqdm: 4.66.4
2024-07-08 09:45:06,408:INFO:               numpy: 1.26.4
2024-07-08 09:45:06,408:INFO:              pandas: 2.1.4
2024-07-08 09:45:06,408:INFO:              jinja2: 3.1.4
2024-07-08 09:45:06,408:INFO:               scipy: 1.11.4
2024-07-08 09:45:06,408:INFO:              joblib: 1.3.2
2024-07-08 09:45:06,408:INFO:             sklearn: 1.4.2
2024-07-08 09:45:06,408:INFO:                pyod: 2.0.1
2024-07-08 09:45:06,408:INFO:            imblearn: 0.12.3
2024-07-08 09:45:06,408:INFO:   category_encoders: 2.6.3
2024-07-08 09:45:06,408:INFO:            lightgbm: 4.4.0
2024-07-08 09:45:06,408:INFO:               numba: 0.60.0
2024-07-08 09:45:06,408:INFO:            requests: 2.32.3
2024-07-08 09:45:06,408:INFO:          matplotlib: 3.7.5
2024-07-08 09:45:06,408:INFO:          scikitplot: 0.3.7
2024-07-08 09:45:06,408:INFO:         yellowbrick: 1.5
2024-07-08 09:45:06,408:INFO:              plotly: 5.22.0
2024-07-08 09:45:06,408:INFO:    plotly-resampler: Not installed
2024-07-08 09:45:06,408:INFO:             kaleido: 0.2.1
2024-07-08 09:45:06,408:INFO:           schemdraw: 0.15
2024-07-08 09:45:06,408:INFO:         statsmodels: 0.14.2
2024-07-08 09:45:06,408:INFO:              sktime: 0.26.0
2024-07-08 09:45:06,408:INFO:               tbats: 1.1.3
2024-07-08 09:45:06,408:INFO:            pmdarima: 2.0.4
2024-07-08 09:45:06,408:INFO:              psutil: 6.0.0
2024-07-08 09:45:06,408:INFO:          markupsafe: 2.1.5
2024-07-08 09:45:06,408:INFO:             pickle5: Not installed
2024-07-08 09:45:06,408:INFO:         cloudpickle: 3.0.0
2024-07-08 09:45:06,409:INFO:         deprecation: 2.1.0
2024-07-08 09:45:06,409:INFO:              xxhash: 3.4.1
2024-07-08 09:45:06,409:INFO:           wurlitzer: Not installed
2024-07-08 09:45:06,409:INFO:PyCaret optional dependencies:
2024-07-08 09:45:06,424:INFO:                shap: Not installed
2024-07-08 09:45:06,424:INFO:           interpret: Not installed
2024-07-08 09:45:06,424:INFO:                umap: Not installed
2024-07-08 09:45:06,425:INFO:     ydata_profiling: Not installed
2024-07-08 09:45:06,425:INFO:  explainerdashboard: Not installed
2024-07-08 09:45:06,425:INFO:             autoviz: Not installed
2024-07-08 09:45:06,425:INFO:           fairlearn: Not installed
2024-07-08 09:45:06,425:INFO:          deepchecks: Not installed
2024-07-08 09:45:06,425:INFO:             xgboost: Not installed
2024-07-08 09:45:06,425:INFO:            catboost: Not installed
2024-07-08 09:45:06,425:INFO:              kmodes: Not installed
2024-07-08 09:45:06,425:INFO:             mlxtend: Not installed
2024-07-08 09:45:06,425:INFO:       statsforecast: Not installed
2024-07-08 09:45:06,425:INFO:        tune_sklearn: Not installed
2024-07-08 09:45:06,425:INFO:                 ray: Not installed
2024-07-08 09:45:06,425:INFO:            hyperopt: Not installed
2024-07-08 09:45:06,426:INFO:              optuna: Not installed
2024-07-08 09:45:06,426:INFO:               skopt: Not installed
2024-07-08 09:45:06,426:INFO:              mlflow: Not installed
2024-07-08 09:45:06,426:INFO:              gradio: Not installed
2024-07-08 09:45:06,426:INFO:             fastapi: Not installed
2024-07-08 09:45:06,426:INFO:             uvicorn: Not installed
2024-07-08 09:45:06,426:INFO:              m2cgen: Not installed
2024-07-08 09:45:06,426:INFO:           evidently: Not installed
2024-07-08 09:45:06,426:INFO:               fugue: Not installed
2024-07-08 09:45:06,426:INFO:           streamlit: Not installed
2024-07-08 09:45:06,426:INFO:             prophet: Not installed
2024-07-08 09:45:06,426:INFO:None
2024-07-08 09:45:06,426:INFO:Set up data.
2024-07-08 09:45:06,521:INFO:Set up folding strategy.
2024-07-08 09:45:06,522:INFO:Set up train/test split.
2024-07-08 09:45:06,826:INFO:Set up index.
2024-07-08 09:45:06,869:INFO:Assigning column types.
2024-07-08 09:45:06,964:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-08 09:45:07,012:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 09:45:07,016:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:45:07,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:07,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:07,096:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 09:45:07,098:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:45:07,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:07,128:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:07,128:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-08 09:45:07,173:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:45:07,203:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:07,204:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:07,252:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:45:07,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:07,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:07,280:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-08 09:45:07,357:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:07,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:07,474:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:07,474:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:07,479:INFO:Preparing preprocessing pipeline...
2024-07-08 09:45:07,496:INFO:Set up simple imputation.
2024-07-08 09:45:08,030:INFO:Set up encoding of ordinal features.
2024-07-08 09:45:08,065:INFO:Set up encoding of categorical features.
2024-07-08 09:45:08,066:INFO:Set up column transformation.
2024-07-08 09:45:08,066:INFO:Set up feature normalization.
2024-07-08 09:45:18,511:INFO:Finished creating preprocessing pipeline.
2024-07-08 09:45:18,529:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-07-08 09:45:18,529:INFO:Creating final display dataframe.
2024-07-08 09:45:24,425:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target              mau
2                   Target type           Binary
3           Original data shape     (600000, 13)
4        Transformed data shape     (600000, 30)
5   Transformed train set shape     (420000, 30)
6    Transformed test set shape     (180000, 30)
7              Numeric features                5
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Transformation             True
16        Transformation method         quantile
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           credit
25                          USI             cdfe
2024-07-08 09:45:24,520:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:24,520:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:24,597:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:24,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:24,599:INFO:setup() successfully completed in 18.24s...............
2024-07-08 09:45:24,609:INFO:gpu_param set to False
2024-07-08 09:45:24,697:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:24,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:24,777:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:24,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:45:24,810:INFO:Initializing create_model()
2024-07-08 09:45:24,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002635DDEC250>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:45:24,811:INFO:Checking exceptions
2024-07-08 09:45:24,828:INFO:Importing libraries
2024-07-08 09:45:24,828:INFO:Copying training dataset
2024-07-08 09:45:25,148:INFO:Defining folds
2024-07-08 09:45:25,148:INFO:Declaring metric variables
2024-07-08 09:45:25,151:INFO:Importing untrained model
2024-07-08 09:45:25,154:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-08 09:45:25,161:INFO:Starting cross validation
2024-07-08 09:45:25,165:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:45:57,732:INFO:Calculating mean and std
2024-07-08 09:45:57,754:INFO:Creating metrics dataframe
2024-07-08 09:45:57,814:INFO:Finalizing model
2024-07-08 09:46:06,518:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 09:46:06,519:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-08 09:46:06,608:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025164 seconds.
2024-07-08 09:46:06,608:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 09:46:06,608:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 09:46:06,613:INFO:[LightGBM] [Info] Total Bins 643
2024-07-08 09:46:06,614:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-08 09:46:06,617:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-08 09:46:06,617:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-08 09:46:07,198:INFO:Uploading results into container
2024-07-08 09:46:07,199:INFO:Uploading model into container now
2024-07-08 09:46:07,212:INFO:_master_model_container: 1
2024-07-08 09:46:07,212:INFO:_display_container: 2
2024-07-08 09:46:07,214:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-08 09:46:07,215:INFO:create_model() successfully completed......................................
2024-07-08 09:46:07,529:INFO:Initializing tune_model()
2024-07-08 09:46:07,529:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002635DDEC250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=1, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-08 09:46:07,530:INFO:Checking exceptions
2024-07-08 09:46:07,683:INFO:Copying training dataset
2024-07-08 09:46:07,900:INFO:Checking base model
2024-07-08 09:46:07,900:INFO:Base model : Light Gradient Boosting Machine
2024-07-08 09:46:07,904:INFO:Declaring metric variables
2024-07-08 09:46:07,909:INFO:Defining Hyperparameters
2024-07-08 09:46:08,090:INFO:Tuning with n_jobs=-1
2024-07-08 09:46:08,091:INFO:Initializing RandomizedSearchCV
2024-07-08 09:46:33,248:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.7}
2024-07-08 09:46:33,249:INFO:Hyperparameter search completed
2024-07-08 09:46:33,250:INFO:SubProcess create_model() called ==================================
2024-07-08 09:46:33,251:INFO:Initializing create_model()
2024-07-08 09:46:33,251:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002635DDEC250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000263503199D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 3, 'num_leaves': 256, 'n_estimators': 30, 'min_split_gain': 0.2, 'min_child_samples': 1, 'learning_rate': 0.0005, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.7})
2024-07-08 09:46:33,251:INFO:Checking exceptions
2024-07-08 09:46:33,251:INFO:Importing libraries
2024-07-08 09:46:33,251:INFO:Copying training dataset
2024-07-08 09:46:33,703:INFO:Defining folds
2024-07-08 09:46:33,703:INFO:Declaring metric variables
2024-07-08 09:46:33,709:INFO:Importing untrained model
2024-07-08 09:46:33,709:INFO:Declaring custom model
2024-07-08 09:46:33,714:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-08 09:46:33,724:INFO:Starting cross validation
2024-07-08 09:46:33,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:46:55,664:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:46:56,191:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:46:56,504:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:46:56,709:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:46:56,847:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:46:56,969:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:46:57,026:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:46:57,097:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:46:57,119:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:46:57,201:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:46:57,353:INFO:Calculating mean and std
2024-07-08 09:46:57,354:INFO:Creating metrics dataframe
2024-07-08 09:46:57,368:INFO:Finalizing model
2024-07-08 09:47:05,522:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-08 09:47:05,522:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-08 09:47:05,523:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-08 09:47:05,811:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 09:47:05,811:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-08 09:47:05,812:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-08 09:47:05,812:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-08 09:47:05,812:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-08 09:47:05,891:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019992 seconds.
2024-07-08 09:47:05,891:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 09:47:05,891:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 09:47:05,891:INFO:[LightGBM] [Info] Total Bins 647
2024-07-08 09:47:05,892:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 29
2024-07-08 09:47:05,898:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-08 09:47:05,898:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-08 09:47:05,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:47:06,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:47:06,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:47:06,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:47:06,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:47:06,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:47:06,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:47:06,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:47:06,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:47:06,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:47:06,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:47:06,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:47:06,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:47:06,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:47:06,929:INFO:Uploading results into container
2024-07-08 09:47:06,930:INFO:Uploading model into container now
2024-07-08 09:47:06,930:INFO:_master_model_container: 2
2024-07-08 09:47:06,931:INFO:_display_container: 3
2024-07-08 09:47:06,931:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-08 09:47:06,932:INFO:create_model() successfully completed......................................
2024-07-08 09:47:07,253:INFO:SubProcess create_model() end ==================================
2024-07-08 09:47:07,253:INFO:choose_better activated
2024-07-08 09:47:07,257:INFO:SubProcess create_model() called ==================================
2024-07-08 09:47:07,257:INFO:Initializing create_model()
2024-07-08 09:47:07,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002635DDEC250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:47:07,258:INFO:Checking exceptions
2024-07-08 09:47:07,260:INFO:Importing libraries
2024-07-08 09:47:07,261:INFO:Copying training dataset
2024-07-08 09:47:07,649:INFO:Defining folds
2024-07-08 09:47:07,650:INFO:Declaring metric variables
2024-07-08 09:47:07,650:INFO:Importing untrained model
2024-07-08 09:47:07,650:INFO:Declaring custom model
2024-07-08 09:47:07,651:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-08 09:47:07,651:INFO:Starting cross validation
2024-07-08 09:47:07,653:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:47:28,868:INFO:Calculating mean and std
2024-07-08 09:47:28,869:INFO:Creating metrics dataframe
2024-07-08 09:47:28,872:INFO:Finalizing model
2024-07-08 09:47:37,386:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 09:47:37,387:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-08 09:47:37,457:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022604 seconds.
2024-07-08 09:47:37,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 09:47:37,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 09:47:37,458:INFO:[LightGBM] [Info] Total Bins 643
2024-07-08 09:47:37,458:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-08 09:47:37,461:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-08 09:47:37,461:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-08 09:47:38,069:INFO:Uploading results into container
2024-07-08 09:47:38,070:INFO:Uploading model into container now
2024-07-08 09:47:38,071:INFO:_master_model_container: 3
2024-07-08 09:47:38,071:INFO:_display_container: 4
2024-07-08 09:47:38,071:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-08 09:47:38,071:INFO:create_model() successfully completed......................................
2024-07-08 09:47:38,257:INFO:SubProcess create_model() end ==================================
2024-07-08 09:47:38,258:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0113
2024-07-08 09:47:38,259:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0
2024-07-08 09:47:38,259:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-07-08 09:47:38,259:INFO:choose_better completed
2024-07-08 09:47:38,259:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-08 09:47:38,279:INFO:_master_model_container: 3
2024-07-08 09:47:38,279:INFO:_display_container: 3
2024-07-08 09:47:38,280:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-08 09:47:38,280:INFO:tune_model() successfully completed......................................
2024-07-08 09:47:38,488:INFO:Initializing plot_model()
2024-07-08 09:47:38,489:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002635DDEC250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-08 09:47:38,489:INFO:Checking exceptions
2024-07-08 09:47:38,609:INFO:Preloading libraries
2024-07-08 09:47:38,617:INFO:Copying training dataset
2024-07-08 09:47:38,617:INFO:Plot type: auc
2024-07-08 09:47:39,772:INFO:Fitting Model
2024-07-08 09:47:39,783:INFO:Scoring test/hold-out set
2024-07-08 09:47:40,469:INFO:Visual Rendered Successfully
2024-07-08 09:47:40,670:INFO:plot_model() successfully completed......................................
2024-07-08 09:47:40,700:INFO:Initializing plot_model()
2024-07-08 09:47:40,700:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002635DDEC250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-08 09:47:40,700:INFO:Checking exceptions
2024-07-08 09:47:40,853:INFO:Preloading libraries
2024-07-08 09:47:40,861:INFO:Copying training dataset
2024-07-08 09:47:40,861:INFO:Plot type: pr
2024-07-08 09:47:42,072:INFO:Fitting Model
2024-07-08 09:47:42,089:INFO:Scoring test/hold-out set
2024-07-08 09:47:42,602:INFO:Visual Rendered Successfully
2024-07-08 09:47:42,775:INFO:plot_model() successfully completed......................................
2024-07-08 09:47:42,801:INFO:Initializing plot_model()
2024-07-08 09:47:42,801:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002635DDEC250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-08 09:47:42,801:INFO:Checking exceptions
2024-07-08 09:47:42,907:INFO:Preloading libraries
2024-07-08 09:47:42,914:INFO:Copying training dataset
2024-07-08 09:47:42,914:INFO:Plot type: feature
2024-07-08 09:47:42,914:WARNING:No coef_ found. Trying feature_importances_
2024-07-08 09:47:43,459:INFO:Visual Rendered Successfully
2024-07-08 09:47:43,630:INFO:plot_model() successfully completed......................................
2024-07-08 09:47:43,654:INFO:Initializing plot_model()
2024-07-08 09:47:43,654:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002635DDEC250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-08 09:47:43,654:INFO:Checking exceptions
2024-07-08 09:47:43,767:INFO:Preloading libraries
2024-07-08 09:47:43,775:INFO:Copying training dataset
2024-07-08 09:47:43,775:INFO:Plot type: confusion_matrix
2024-07-08 09:47:44,914:INFO:Fitting Model
2024-07-08 09:47:44,918:INFO:Scoring test/hold-out set
2024-07-08 09:47:45,308:INFO:Visual Rendered Successfully
2024-07-08 09:47:45,473:INFO:plot_model() successfully completed......................................
2024-07-08 09:47:45,534:INFO:Initializing predict_model()
2024-07-08 09:47:45,534:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002635DDEC250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000263680BEA20>)
2024-07-08 09:47:45,534:INFO:Checking exceptions
2024-07-08 09:47:45,534:INFO:Preloading libraries
2024-07-08 09:47:47,135:INFO:Initializing finalize_model()
2024-07-08 09:47:47,135:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002635DDEC250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-08 09:47:47,135:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-08 09:47:47,206:INFO:Initializing create_model()
2024-07-08 09:47:47,206:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002635DDEC250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:47:47,207:INFO:Checking exceptions
2024-07-08 09:47:47,208:INFO:Importing libraries
2024-07-08 09:47:47,208:INFO:Copying training dataset
2024-07-08 09:47:47,219:INFO:Defining folds
2024-07-08 09:47:47,219:INFO:Declaring metric variables
2024-07-08 09:47:47,220:INFO:Importing untrained model
2024-07-08 09:47:47,220:INFO:Declaring custom model
2024-07-08 09:47:47,220:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-08 09:47:47,222:INFO:Cross validation set to False
2024-07-08 09:47:47,222:INFO:Fitting Model
2024-07-08 09:47:59,246:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 09:47:59,248:INFO:[LightGBM] [Info] Number of positive: 36643, number of negative: 563357
2024-07-08 09:47:59,347:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029191 seconds.
2024-07-08 09:47:59,347:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 09:47:59,348:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 09:47:59,348:INFO:[LightGBM] [Info] Total Bins 642
2024-07-08 09:47:59,348:INFO:[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 27
2024-07-08 09:47:59,352:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061072 -> initscore=-2.732691
2024-07-08 09:47:59,352:INFO:[LightGBM] [Info] Start training from score -2.732691
2024-07-08 09:48:00,264:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-08 09:48:00,264:INFO:create_model() successfully completed......................................
2024-07-08 09:48:00,434:INFO:_master_model_container: 3
2024-07-08 09:48:00,436:INFO:_display_container: 4
2024-07-08 09:48:00,456:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-08 09:48:00,456:INFO:finalize_model() successfully completed......................................
2024-07-08 09:48:00,698:INFO:Initializing predict_model()
2024-07-08 09:48:00,698:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002635DDEC250>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002634FF0E020>)
2024-07-08 09:48:00,698:INFO:Checking exceptions
2024-07-08 09:48:00,699:INFO:Preloading libraries
2024-07-08 09:48:00,701:INFO:Set up data.
2024-07-08 09:48:00,739:INFO:Set up index.
2024-07-08 09:48:03,510:INFO:Initializing save_model()
2024-07-08 09:48:03,511:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=Final Light GBM Model Jul2024, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-08 09:48:03,511:INFO:Adding model into prep_pipe
2024-07-08 09:48:03,511:WARNING:Only Model saved as it was a pipeline.
2024-07-08 09:48:03,529:INFO:Final Light GBM Model Jul2024.pkl saved in current working directory
2024-07-08 09:48:03,552:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-08 09:48:03,552:INFO:save_model() successfully completed......................................
2024-07-08 09:50:44,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-08 09:50:44,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-08 09:50:44,186:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-08 09:50:44,186:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-08 09:50:47,418:INFO:PyCaret ClassificationExperiment
2024-07-08 09:50:47,418:INFO:Logging name: credit
2024-07-08 09:50:47,418:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-08 09:50:47,418:INFO:version 3.3.2
2024-07-08 09:50:47,419:INFO:Initializing setup()
2024-07-08 09:50:47,419:INFO:self.USI: 1574
2024-07-08 09:50:47,419:INFO:self._variable_keys: {'exp_id', 'y', 'gpu_n_jobs_param', 'is_multiclass', 'fix_imbalance', 'data', 'logging_param', 'log_plots_param', 'USI', 'X_train', 'target_param', 'gpu_param', 'pipeline', 'X', 'n_jobs_param', 'y_train', 'memory', 'fold_groups_param', '_ml_usecase', 'fold_generator', 'y_test', 'X_test', 'exp_name_log', 'seed', 'fold_shuffle_param', 'html_param', '_available_plots', 'idx'}
2024-07-08 09:50:47,419:INFO:Checking environment
2024-07-08 09:50:47,419:INFO:python_version: 3.11.7
2024-07-08 09:50:47,419:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2024-07-08 09:50:47,419:INFO:machine: AMD64
2024-07-08 09:50:47,419:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-08 09:50:47,423:INFO:Memory: svmem(total=16849293312, available=7795838976, percent=53.7, used=9053454336, free=7795838976)
2024-07-08 09:50:47,423:INFO:Physical Core: 12
2024-07-08 09:50:47,423:INFO:Logical Core: 16
2024-07-08 09:50:47,423:INFO:Checking libraries
2024-07-08 09:50:47,423:INFO:System:
2024-07-08 09:50:47,423:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2024-07-08 09:50:47,423:INFO:executable: c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\python.exe
2024-07-08 09:50:47,423:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-08 09:50:47,423:INFO:PyCaret required dependencies:
2024-07-08 09:50:47,458:INFO:                 pip: 24.1.2
2024-07-08 09:50:47,458:INFO:          setuptools: 65.5.0
2024-07-08 09:50:47,458:INFO:             pycaret: 3.3.2
2024-07-08 09:50:47,458:INFO:             IPython: 8.26.0
2024-07-08 09:50:47,458:INFO:          ipywidgets: 8.1.3
2024-07-08 09:50:47,458:INFO:                tqdm: 4.66.4
2024-07-08 09:50:47,458:INFO:               numpy: 1.26.4
2024-07-08 09:50:47,458:INFO:              pandas: 2.1.4
2024-07-08 09:50:47,458:INFO:              jinja2: 3.1.4
2024-07-08 09:50:47,458:INFO:               scipy: 1.11.4
2024-07-08 09:50:47,458:INFO:              joblib: 1.3.2
2024-07-08 09:50:47,458:INFO:             sklearn: 1.4.2
2024-07-08 09:50:47,458:INFO:                pyod: 2.0.1
2024-07-08 09:50:47,458:INFO:            imblearn: 0.12.3
2024-07-08 09:50:47,458:INFO:   category_encoders: 2.6.3
2024-07-08 09:50:47,458:INFO:            lightgbm: 4.4.0
2024-07-08 09:50:47,458:INFO:               numba: 0.60.0
2024-07-08 09:50:47,458:INFO:            requests: 2.32.3
2024-07-08 09:50:47,458:INFO:          matplotlib: 3.7.5
2024-07-08 09:50:47,458:INFO:          scikitplot: 0.3.7
2024-07-08 09:50:47,458:INFO:         yellowbrick: 1.5
2024-07-08 09:50:47,458:INFO:              plotly: 5.22.0
2024-07-08 09:50:47,459:INFO:    plotly-resampler: Not installed
2024-07-08 09:50:47,459:INFO:             kaleido: 0.2.1
2024-07-08 09:50:47,459:INFO:           schemdraw: 0.15
2024-07-08 09:50:47,459:INFO:         statsmodels: 0.14.2
2024-07-08 09:50:47,459:INFO:              sktime: 0.26.0
2024-07-08 09:50:47,459:INFO:               tbats: 1.1.3
2024-07-08 09:50:47,459:INFO:            pmdarima: 2.0.4
2024-07-08 09:50:47,459:INFO:              psutil: 6.0.0
2024-07-08 09:50:47,459:INFO:          markupsafe: 2.1.5
2024-07-08 09:50:47,459:INFO:             pickle5: Not installed
2024-07-08 09:50:47,459:INFO:         cloudpickle: 3.0.0
2024-07-08 09:50:47,459:INFO:         deprecation: 2.1.0
2024-07-08 09:50:47,459:INFO:              xxhash: 3.4.1
2024-07-08 09:50:47,459:INFO:           wurlitzer: Not installed
2024-07-08 09:50:47,459:INFO:PyCaret optional dependencies:
2024-07-08 09:50:47,480:INFO:                shap: Not installed
2024-07-08 09:50:47,480:INFO:           interpret: Not installed
2024-07-08 09:50:47,480:INFO:                umap: Not installed
2024-07-08 09:50:47,480:INFO:     ydata_profiling: Not installed
2024-07-08 09:50:47,480:INFO:  explainerdashboard: Not installed
2024-07-08 09:50:47,480:INFO:             autoviz: Not installed
2024-07-08 09:50:47,480:INFO:           fairlearn: Not installed
2024-07-08 09:50:47,480:INFO:          deepchecks: Not installed
2024-07-08 09:50:47,480:INFO:             xgboost: Not installed
2024-07-08 09:50:47,480:INFO:            catboost: Not installed
2024-07-08 09:50:47,480:INFO:              kmodes: Not installed
2024-07-08 09:50:47,480:INFO:             mlxtend: Not installed
2024-07-08 09:50:47,480:INFO:       statsforecast: Not installed
2024-07-08 09:50:47,480:INFO:        tune_sklearn: Not installed
2024-07-08 09:50:47,480:INFO:                 ray: Not installed
2024-07-08 09:50:47,481:INFO:            hyperopt: Not installed
2024-07-08 09:50:47,481:INFO:              optuna: Not installed
2024-07-08 09:50:47,481:INFO:               skopt: Not installed
2024-07-08 09:50:47,481:INFO:              mlflow: Not installed
2024-07-08 09:50:47,481:INFO:              gradio: Not installed
2024-07-08 09:50:47,481:INFO:             fastapi: Not installed
2024-07-08 09:50:47,481:INFO:             uvicorn: Not installed
2024-07-08 09:50:47,481:INFO:              m2cgen: Not installed
2024-07-08 09:50:47,481:INFO:           evidently: Not installed
2024-07-08 09:50:47,481:INFO:               fugue: Not installed
2024-07-08 09:50:47,481:INFO:           streamlit: Not installed
2024-07-08 09:50:47,481:INFO:             prophet: Not installed
2024-07-08 09:50:47,481:INFO:None
2024-07-08 09:50:47,481:INFO:Set up data.
2024-07-08 09:50:47,574:INFO:Set up folding strategy.
2024-07-08 09:50:47,574:INFO:Set up train/test split.
2024-07-08 09:50:47,902:INFO:Set up index.
2024-07-08 09:50:47,942:INFO:Assigning column types.
2024-07-08 09:50:48,037:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-08 09:50:48,096:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 09:50:48,106:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:50:48,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:50:48,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:50:48,201:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 09:50:48,201:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:50:48,236:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:50:48,237:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:50:48,237:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-08 09:50:48,294:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:50:48,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:50:48,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:50:48,381:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:50:48,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:50:48,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:50:48,416:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-08 09:50:48,523:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:50:48,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:50:48,607:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:50:48,608:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:50:48,613:INFO:Preparing preprocessing pipeline...
2024-07-08 09:50:48,634:INFO:Set up simple imputation.
2024-07-08 09:50:49,039:INFO:Set up encoding of ordinal features.
2024-07-08 09:50:49,074:INFO:Set up encoding of categorical features.
2024-07-08 09:50:49,075:INFO:Set up column transformation.
2024-07-08 09:50:49,075:INFO:Set up feature normalization.
2024-07-08 09:50:53,552:INFO:Finished creating preprocessing pipeline.
2024-07-08 09:50:53,571:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-07-08 09:50:53,571:INFO:Creating final display dataframe.
2024-07-08 09:51:02,957:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target              mau
2                   Target type           Binary
3           Original data shape     (600000, 13)
4        Transformed data shape     (600000, 30)
5   Transformed train set shape     (420000, 30)
6    Transformed test set shape     (180000, 30)
7              Numeric features                5
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Transformation             True
16        Transformation method         quantile
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           credit
25                          USI             1574
2024-07-08 09:51:03,060:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:51:03,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:51:03,164:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:51:03,164:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:51:03,167:INFO:setup() successfully completed in 15.77s...............
2024-07-08 09:51:03,178:INFO:gpu_param set to False
2024-07-08 09:51:03,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:51:03,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:51:03,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:51:03,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:51:03,448:INFO:Initializing create_model()
2024-07-08 09:51:03,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197F29DDF50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:51:03,449:INFO:Checking exceptions
2024-07-08 09:51:03,468:INFO:Importing libraries
2024-07-08 09:51:03,469:INFO:Copying training dataset
2024-07-08 09:51:03,836:INFO:Defining folds
2024-07-08 09:51:03,836:INFO:Declaring metric variables
2024-07-08 09:51:03,841:INFO:Importing untrained model
2024-07-08 09:51:03,846:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-08 09:51:03,856:INFO:Starting cross validation
2024-07-08 09:51:03,858:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:51:32,899:INFO:Calculating mean and std
2024-07-08 09:51:32,901:INFO:Creating metrics dataframe
2024-07-08 09:51:32,911:INFO:Finalizing model
2024-07-08 09:51:41,993:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 09:51:41,993:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-08 09:51:42,071:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025844 seconds.
2024-07-08 09:51:42,071:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 09:51:42,071:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 09:51:42,072:INFO:[LightGBM] [Info] Total Bins 643
2024-07-08 09:51:42,072:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-08 09:51:42,075:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-08 09:51:42,076:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-08 09:51:42,920:INFO:Uploading results into container
2024-07-08 09:51:42,921:INFO:Uploading model into container now
2024-07-08 09:51:42,933:INFO:_master_model_container: 1
2024-07-08 09:51:42,934:INFO:_display_container: 2
2024-07-08 09:51:42,934:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-08 09:51:42,935:INFO:create_model() successfully completed......................................
2024-07-08 09:51:43,160:INFO:Initializing tune_model()
2024-07-08 09:51:43,160:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197F29DDF50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=1, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-08 09:51:43,161:INFO:Checking exceptions
2024-07-08 09:51:43,376:INFO:Copying training dataset
2024-07-08 09:51:43,688:INFO:Checking base model
2024-07-08 09:51:43,689:INFO:Base model : Light Gradient Boosting Machine
2024-07-08 09:51:43,694:INFO:Declaring metric variables
2024-07-08 09:51:43,700:INFO:Defining Hyperparameters
2024-07-08 09:51:43,886:INFO:Tuning with n_jobs=-1
2024-07-08 09:51:43,886:INFO:Initializing RandomizedSearchCV
2024-07-08 09:52:11,481:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.7}
2024-07-08 09:52:11,483:INFO:Hyperparameter search completed
2024-07-08 09:52:11,483:INFO:SubProcess create_model() called ==================================
2024-07-08 09:52:11,484:INFO:Initializing create_model()
2024-07-08 09:52:11,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197F29DDF50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197EAE90F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 3, 'num_leaves': 256, 'n_estimators': 30, 'min_split_gain': 0.2, 'min_child_samples': 1, 'learning_rate': 0.0005, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.7})
2024-07-08 09:52:11,484:INFO:Checking exceptions
2024-07-08 09:52:11,484:INFO:Importing libraries
2024-07-08 09:52:11,484:INFO:Copying training dataset
2024-07-08 09:52:11,842:INFO:Defining folds
2024-07-08 09:52:11,842:INFO:Declaring metric variables
2024-07-08 09:52:11,848:INFO:Importing untrained model
2024-07-08 09:52:11,848:INFO:Declaring custom model
2024-07-08 09:52:11,852:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-08 09:52:11,860:INFO:Starting cross validation
2024-07-08 09:52:11,863:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:52:35,091:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:52:35,120:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:52:35,362:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:52:35,401:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:52:35,492:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:52:35,596:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:52:35,672:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:52:35,707:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:52:36,108:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:52:36,235:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:52:36,375:INFO:Calculating mean and std
2024-07-08 09:52:36,377:INFO:Creating metrics dataframe
2024-07-08 09:52:36,383:INFO:Finalizing model
2024-07-08 09:52:44,767:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-08 09:52:44,767:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-08 09:52:44,767:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-08 09:52:45,068:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 09:52:45,069:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-08 09:52:45,069:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-08 09:52:45,069:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-08 09:52:45,069:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-08 09:52:45,149:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023079 seconds.
2024-07-08 09:52:45,149:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 09:52:45,149:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 09:52:45,150:INFO:[LightGBM] [Info] Total Bins 647
2024-07-08 09:52:45,150:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 29
2024-07-08 09:52:45,156:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-08 09:52:45,156:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-08 09:52:45,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:52:45,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:52:45,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:52:45,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:52:45,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:52:45,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:52:45,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:52:45,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:52:45,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:52:45,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:52:45,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:52:45,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:52:45,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:52:45,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 09:52:45,940:INFO:Uploading results into container
2024-07-08 09:52:45,940:INFO:Uploading model into container now
2024-07-08 09:52:45,941:INFO:_master_model_container: 2
2024-07-08 09:52:45,941:INFO:_display_container: 3
2024-07-08 09:52:45,942:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-08 09:52:45,942:INFO:create_model() successfully completed......................................
2024-07-08 09:52:46,128:INFO:SubProcess create_model() end ==================================
2024-07-08 09:52:46,128:INFO:choose_better activated
2024-07-08 09:52:46,133:INFO:SubProcess create_model() called ==================================
2024-07-08 09:52:46,134:INFO:Initializing create_model()
2024-07-08 09:52:46,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197F29DDF50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:52:46,134:INFO:Checking exceptions
2024-07-08 09:52:46,135:INFO:Importing libraries
2024-07-08 09:52:46,136:INFO:Copying training dataset
2024-07-08 09:52:46,460:INFO:Defining folds
2024-07-08 09:52:46,461:INFO:Declaring metric variables
2024-07-08 09:52:46,461:INFO:Importing untrained model
2024-07-08 09:52:46,461:INFO:Declaring custom model
2024-07-08 09:52:46,462:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-08 09:52:46,462:INFO:Starting cross validation
2024-07-08 09:52:46,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:53:09,463:INFO:Calculating mean and std
2024-07-08 09:53:09,464:INFO:Creating metrics dataframe
2024-07-08 09:53:09,466:INFO:Finalizing model
2024-07-08 09:53:18,399:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 09:53:18,399:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-08 09:53:18,465:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021678 seconds.
2024-07-08 09:53:18,466:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 09:53:18,466:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 09:53:18,466:INFO:[LightGBM] [Info] Total Bins 643
2024-07-08 09:53:18,466:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-08 09:53:18,470:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-08 09:53:18,470:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-08 09:53:19,206:INFO:Uploading results into container
2024-07-08 09:53:19,207:INFO:Uploading model into container now
2024-07-08 09:53:19,208:INFO:_master_model_container: 3
2024-07-08 09:53:19,208:INFO:_display_container: 4
2024-07-08 09:53:19,208:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-08 09:53:19,208:INFO:create_model() successfully completed......................................
2024-07-08 09:53:19,391:INFO:SubProcess create_model() end ==================================
2024-07-08 09:53:19,392:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0113
2024-07-08 09:53:19,393:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0
2024-07-08 09:53:19,393:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-07-08 09:53:19,393:INFO:choose_better completed
2024-07-08 09:53:19,393:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-08 09:53:19,409:INFO:_master_model_container: 3
2024-07-08 09:53:19,409:INFO:_display_container: 3
2024-07-08 09:53:19,410:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-08 09:53:19,410:INFO:tune_model() successfully completed......................................
2024-07-08 09:53:19,592:INFO:Initializing plot_model()
2024-07-08 09:53:19,592:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197F29DDF50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-08 09:53:19,592:INFO:Checking exceptions
2024-07-08 09:53:19,711:INFO:Preloading libraries
2024-07-08 09:53:19,719:INFO:Copying training dataset
2024-07-08 09:53:19,719:INFO:Plot type: auc
2024-07-08 09:53:20,950:INFO:Fitting Model
2024-07-08 09:53:20,964:INFO:Scoring test/hold-out set
2024-07-08 09:53:21,669:INFO:Visual Rendered Successfully
2024-07-08 09:53:21,854:INFO:plot_model() successfully completed......................................
2024-07-08 09:53:21,864:INFO:Initializing plot_model()
2024-07-08 09:53:21,864:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197F29DDF50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-08 09:53:21,864:INFO:Checking exceptions
2024-07-08 09:53:21,977:INFO:Preloading libraries
2024-07-08 09:53:21,985:INFO:Copying training dataset
2024-07-08 09:53:21,985:INFO:Plot type: pr
2024-07-08 09:53:23,155:INFO:Fitting Model
2024-07-08 09:53:23,175:INFO:Scoring test/hold-out set
2024-07-08 09:53:23,722:INFO:Visual Rendered Successfully
2024-07-08 09:53:23,896:INFO:plot_model() successfully completed......................................
2024-07-08 09:53:23,910:INFO:Initializing plot_model()
2024-07-08 09:53:23,910:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197F29DDF50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-08 09:53:23,910:INFO:Checking exceptions
2024-07-08 09:53:24,068:INFO:Preloading libraries
2024-07-08 09:53:24,076:INFO:Copying training dataset
2024-07-08 09:53:24,076:INFO:Plot type: feature
2024-07-08 09:53:24,077:WARNING:No coef_ found. Trying feature_importances_
2024-07-08 09:53:24,627:INFO:Visual Rendered Successfully
2024-07-08 09:53:24,796:INFO:plot_model() successfully completed......................................
2024-07-08 09:53:24,807:INFO:Initializing plot_model()
2024-07-08 09:53:24,807:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197F29DDF50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-08 09:53:24,807:INFO:Checking exceptions
2024-07-08 09:53:24,929:INFO:Preloading libraries
2024-07-08 09:53:24,936:INFO:Copying training dataset
2024-07-08 09:53:24,936:INFO:Plot type: confusion_matrix
2024-07-08 09:53:26,082:INFO:Fitting Model
2024-07-08 09:53:26,087:INFO:Scoring test/hold-out set
2024-07-08 09:53:26,470:INFO:Visual Rendered Successfully
2024-07-08 09:53:26,639:INFO:plot_model() successfully completed......................................
2024-07-08 09:53:26,660:INFO:Initializing predict_model()
2024-07-08 09:53:26,661:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197F29DDF50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000197C8353D80>)
2024-07-08 09:53:26,661:INFO:Checking exceptions
2024-07-08 09:53:26,661:INFO:Preloading libraries
2024-07-08 09:53:28,263:INFO:Initializing finalize_model()
2024-07-08 09:53:28,263:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197F29DDF50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-08 09:53:28,264:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-08 09:53:28,346:INFO:Initializing create_model()
2024-07-08 09:53:28,347:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197F29DDF50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:53:28,347:INFO:Checking exceptions
2024-07-08 09:53:28,348:INFO:Importing libraries
2024-07-08 09:53:28,349:INFO:Copying training dataset
2024-07-08 09:53:28,360:INFO:Defining folds
2024-07-08 09:53:28,360:INFO:Declaring metric variables
2024-07-08 09:53:28,360:INFO:Importing untrained model
2024-07-08 09:53:28,360:INFO:Declaring custom model
2024-07-08 09:53:28,361:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-08 09:53:28,363:INFO:Cross validation set to False
2024-07-08 09:53:28,363:INFO:Fitting Model
2024-07-08 09:53:40,313:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 09:53:40,314:INFO:[LightGBM] [Info] Number of positive: 36643, number of negative: 563357
2024-07-08 09:53:40,399:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028860 seconds.
2024-07-08 09:53:40,399:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 09:53:40,399:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 09:53:40,400:INFO:[LightGBM] [Info] Total Bins 642
2024-07-08 09:53:40,400:INFO:[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 27
2024-07-08 09:53:40,403:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061072 -> initscore=-2.732691
2024-07-08 09:53:40,403:INFO:[LightGBM] [Info] Start training from score -2.732691
2024-07-08 09:53:41,238:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-08 09:53:41,238:INFO:create_model() successfully completed......................................
2024-07-08 09:53:41,401:INFO:_master_model_container: 3
2024-07-08 09:53:41,401:INFO:_display_container: 4
2024-07-08 09:53:41,419:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-08 09:53:41,419:INFO:finalize_model() successfully completed......................................
2024-07-08 09:53:41,648:INFO:Initializing predict_model()
2024-07-08 09:53:41,648:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197F29DDF50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000197D02FB7E0>)
2024-07-08 09:53:41,648:INFO:Checking exceptions
2024-07-08 09:53:41,648:INFO:Preloading libraries
2024-07-08 09:53:41,651:INFO:Set up data.
2024-07-08 09:53:41,691:INFO:Set up index.
2024-07-08 09:53:44,396:INFO:Initializing save_model()
2024-07-08 09:53:44,396:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=Final Light GBM Model Jul2024, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-08 09:53:44,397:INFO:Adding model into prep_pipe
2024-07-08 09:53:44,397:WARNING:Only Model saved as it was a pipeline.
2024-07-08 09:53:44,417:INFO:Final Light GBM Model Jul2024.pkl saved in current working directory
2024-07-08 09:53:44,448:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-08 09:53:44,448:INFO:save_model() successfully completed......................................
2024-07-13 09:28:37,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 09:28:37,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 09:28:37,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 09:28:37,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 09:28:49,468:INFO:PyCaret ClassificationExperiment
2024-07-13 09:28:49,468:INFO:Logging name: credit
2024-07-13 09:28:49,468:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-13 09:28:49,468:INFO:version 3.3.2
2024-07-13 09:28:49,468:INFO:Initializing setup()
2024-07-13 09:28:49,468:INFO:self.USI: b501
2024-07-13 09:28:49,468:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'X', '_ml_usecase', 'X_train', 'X_test', 'exp_id', 'exp_name_log', 'USI', 'y', 'data', '_available_plots', 'logging_param', 'is_multiclass', 'html_param', 'idx', 'memory', 'gpu_param', 'pipeline', 'n_jobs_param', 'fold_shuffle_param', 'fold_generator', 'fix_imbalance', 'seed', 'fold_groups_param', 'y_test', 'y_train', 'log_plots_param'}
2024-07-13 09:28:49,468:INFO:Checking environment
2024-07-13 09:28:49,468:INFO:python_version: 3.11.7
2024-07-13 09:28:49,468:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2024-07-13 09:28:49,468:INFO:machine: AMD64
2024-07-13 09:28:49,468:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-13 09:28:49,473:INFO:Memory: svmem(total=16849293312, available=5795917824, percent=65.6, used=11053375488, free=5795917824)
2024-07-13 09:28:49,473:INFO:Physical Core: 12
2024-07-13 09:28:49,473:INFO:Logical Core: 16
2024-07-13 09:28:49,473:INFO:Checking libraries
2024-07-13 09:28:49,473:INFO:System:
2024-07-13 09:28:49,473:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2024-07-13 09:28:49,474:INFO:executable: c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\python.exe
2024-07-13 09:28:49,474:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-13 09:28:49,474:INFO:PyCaret required dependencies:
2024-07-13 09:28:49,822:INFO:                 pip: 24.1.2
2024-07-13 09:28:49,822:INFO:          setuptools: 65.5.0
2024-07-13 09:28:49,822:INFO:             pycaret: 3.3.2
2024-07-13 09:28:49,822:INFO:             IPython: 8.26.0
2024-07-13 09:28:49,822:INFO:          ipywidgets: 8.1.3
2024-07-13 09:28:49,822:INFO:                tqdm: 4.66.4
2024-07-13 09:28:49,822:INFO:               numpy: 1.26.4
2024-07-13 09:28:49,822:INFO:              pandas: 2.1.4
2024-07-13 09:28:49,822:INFO:              jinja2: 3.1.4
2024-07-13 09:28:49,822:INFO:               scipy: 1.11.4
2024-07-13 09:28:49,822:INFO:              joblib: 1.3.2
2024-07-13 09:28:49,822:INFO:             sklearn: 1.4.2
2024-07-13 09:28:49,822:INFO:                pyod: 2.0.1
2024-07-13 09:28:49,822:INFO:            imblearn: 0.12.3
2024-07-13 09:28:49,822:INFO:   category_encoders: 2.6.3
2024-07-13 09:28:49,822:INFO:            lightgbm: 4.4.0
2024-07-13 09:28:49,822:INFO:               numba: 0.60.0
2024-07-13 09:28:49,822:INFO:            requests: 2.32.3
2024-07-13 09:28:49,822:INFO:          matplotlib: 3.7.5
2024-07-13 09:28:49,822:INFO:          scikitplot: 0.3.7
2024-07-13 09:28:49,822:INFO:         yellowbrick: 1.5
2024-07-13 09:28:49,822:INFO:              plotly: 5.22.0
2024-07-13 09:28:49,822:INFO:    plotly-resampler: Not installed
2024-07-13 09:28:49,822:INFO:             kaleido: 0.2.1
2024-07-13 09:28:49,822:INFO:           schemdraw: 0.15
2024-07-13 09:28:49,823:INFO:         statsmodels: 0.14.2
2024-07-13 09:28:49,823:INFO:              sktime: 0.26.0
2024-07-13 09:28:49,823:INFO:               tbats: 1.1.3
2024-07-13 09:28:49,823:INFO:            pmdarima: 2.0.4
2024-07-13 09:28:49,823:INFO:              psutil: 6.0.0
2024-07-13 09:28:49,823:INFO:          markupsafe: 2.1.5
2024-07-13 09:28:49,823:INFO:             pickle5: Not installed
2024-07-13 09:28:49,823:INFO:         cloudpickle: 3.0.0
2024-07-13 09:28:49,823:INFO:         deprecation: 2.1.0
2024-07-13 09:28:49,823:INFO:              xxhash: 3.4.1
2024-07-13 09:28:49,823:INFO:           wurlitzer: Not installed
2024-07-13 09:28:49,823:INFO:PyCaret optional dependencies:
2024-07-13 09:28:49,838:INFO:                shap: Not installed
2024-07-13 09:28:49,839:INFO:           interpret: Not installed
2024-07-13 09:28:49,839:INFO:                umap: Not installed
2024-07-13 09:28:49,839:INFO:     ydata_profiling: Not installed
2024-07-13 09:28:49,839:INFO:  explainerdashboard: Not installed
2024-07-13 09:28:49,839:INFO:             autoviz: Not installed
2024-07-13 09:28:49,839:INFO:           fairlearn: Not installed
2024-07-13 09:28:49,839:INFO:          deepchecks: Not installed
2024-07-13 09:28:49,839:INFO:             xgboost: Not installed
2024-07-13 09:28:49,839:INFO:            catboost: Not installed
2024-07-13 09:28:49,839:INFO:              kmodes: Not installed
2024-07-13 09:28:49,839:INFO:             mlxtend: Not installed
2024-07-13 09:28:49,839:INFO:       statsforecast: Not installed
2024-07-13 09:28:49,839:INFO:        tune_sklearn: Not installed
2024-07-13 09:28:49,839:INFO:                 ray: Not installed
2024-07-13 09:28:49,839:INFO:            hyperopt: Not installed
2024-07-13 09:28:49,839:INFO:              optuna: Not installed
2024-07-13 09:28:49,839:INFO:               skopt: Not installed
2024-07-13 09:28:49,839:INFO:              mlflow: Not installed
2024-07-13 09:28:49,840:INFO:              gradio: Not installed
2024-07-13 09:28:49,840:INFO:             fastapi: Not installed
2024-07-13 09:28:49,840:INFO:             uvicorn: Not installed
2024-07-13 09:28:49,840:INFO:              m2cgen: Not installed
2024-07-13 09:28:49,840:INFO:           evidently: Not installed
2024-07-13 09:28:49,840:INFO:               fugue: Not installed
2024-07-13 09:28:49,840:INFO:           streamlit: Not installed
2024-07-13 09:28:49,840:INFO:             prophet: Not installed
2024-07-13 09:28:49,840:INFO:None
2024-07-13 09:28:49,840:INFO:Set up data.
2024-07-13 09:28:49,933:INFO:Set up folding strategy.
2024-07-13 09:28:49,933:INFO:Set up train/test split.
2024-07-13 09:28:50,232:INFO:Set up index.
2024-07-13 09:28:50,277:INFO:Assigning column types.
2024-07-13 09:28:50,373:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-13 09:28:50,420:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-13 09:28:50,429:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 09:28:50,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:50,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:50,578:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-13 09:28:50,579:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 09:28:50,609:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:50,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:50,610:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-13 09:28:50,658:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 09:28:50,687:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:50,688:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:50,742:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 09:28:50,771:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:50,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:50,772:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-13 09:28:50,850:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:50,851:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:50,927:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:50,927:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:50,937:INFO:Preparing preprocessing pipeline...
2024-07-13 09:28:50,957:INFO:Set up simple imputation.
2024-07-13 09:28:51,335:INFO:Set up encoding of ordinal features.
2024-07-13 09:28:51,366:INFO:Set up encoding of categorical features.
2024-07-13 09:28:51,367:INFO:Set up column transformation.
2024-07-13 09:28:51,367:INFO:Set up feature normalization.
2024-07-13 09:28:52,863:INFO:Finished creating preprocessing pipeline.
2024-07-13 09:28:52,883:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-07-13 09:28:52,883:INFO:Creating final display dataframe.
2024-07-13 09:28:55,762:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target              mau
2                   Target type           Binary
3           Original data shape     (600000, 13)
4        Transformed data shape     (600000, 30)
5   Transformed train set shape     (420000, 30)
6    Transformed test set shape     (180000, 30)
7              Numeric features                5
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Transformation             True
16        Transformation method         quantile
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           credit
25                          USI             b501
2024-07-13 09:28:55,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:55,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:55,918:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:55,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:55,919:INFO:setup() successfully completed in 6.48s...............
2024-07-13 09:28:55,928:INFO:gpu_param set to False
2024-07-13 09:28:56,014:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:56,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:56,275:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:56,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:28:56,292:INFO:Initializing create_model()
2024-07-13 09:28:56,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019709110AD0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-13 09:28:56,293:INFO:Checking exceptions
2024-07-13 09:28:56,309:INFO:Importing libraries
2024-07-13 09:28:56,309:INFO:Copying training dataset
2024-07-13 09:28:56,649:INFO:Defining folds
2024-07-13 09:28:56,649:INFO:Declaring metric variables
2024-07-13 09:28:56,652:INFO:Importing untrained model
2024-07-13 09:28:56,656:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 09:28:56,664:INFO:Starting cross validation
2024-07-13 09:28:56,666:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 09:29:24,053:INFO:Calculating mean and std
2024-07-13 09:29:24,057:INFO:Creating metrics dataframe
2024-07-13 09:29:24,064:INFO:Finalizing model
2024-07-13 09:29:32,194:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 09:29:32,195:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-13 09:29:32,253:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021185 seconds.
2024-07-13 09:29:32,253:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 09:29:32,253:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 09:29:32,253:INFO:[LightGBM] [Info] Total Bins 643
2024-07-13 09:29:32,254:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-13 09:29:32,257:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-13 09:29:32,257:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-13 09:29:32,869:INFO:Uploading results into container
2024-07-13 09:29:32,870:INFO:Uploading model into container now
2024-07-13 09:29:32,881:INFO:_master_model_container: 1
2024-07-13 09:29:32,881:INFO:_display_container: 2
2024-07-13 09:29:32,882:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 09:29:32,882:INFO:create_model() successfully completed......................................
2024-07-13 09:29:33,069:INFO:Initializing tune_model()
2024-07-13 09:29:33,069:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019709110AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=1, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-13 09:29:33,069:INFO:Checking exceptions
2024-07-13 09:29:33,225:INFO:Copying training dataset
2024-07-13 09:29:33,469:INFO:Checking base model
2024-07-13 09:29:33,470:INFO:Base model : Light Gradient Boosting Machine
2024-07-13 09:29:33,475:INFO:Declaring metric variables
2024-07-13 09:29:33,480:INFO:Defining Hyperparameters
2024-07-13 09:29:33,660:INFO:Tuning with n_jobs=-1
2024-07-13 09:29:33,660:INFO:Initializing RandomizedSearchCV
2024-07-13 09:29:56,184:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.7}
2024-07-13 09:29:56,186:INFO:Hyperparameter search completed
2024-07-13 09:29:56,186:INFO:SubProcess create_model() called ==================================
2024-07-13 09:29:56,187:INFO:Initializing create_model()
2024-07-13 09:29:56,187:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019709110AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001971C87AF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 3, 'num_leaves': 256, 'n_estimators': 30, 'min_split_gain': 0.2, 'min_child_samples': 1, 'learning_rate': 0.0005, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.7})
2024-07-13 09:29:56,187:INFO:Checking exceptions
2024-07-13 09:29:56,187:INFO:Importing libraries
2024-07-13 09:29:56,187:INFO:Copying training dataset
2024-07-13 09:29:56,515:INFO:Defining folds
2024-07-13 09:29:56,516:INFO:Declaring metric variables
2024-07-13 09:29:56,520:INFO:Importing untrained model
2024-07-13 09:29:56,520:INFO:Declaring custom model
2024-07-13 09:29:56,525:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 09:29:56,531:INFO:Starting cross validation
2024-07-13 09:29:56,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 09:30:17,234:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:30:17,963:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:30:18,193:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:30:18,218:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:30:18,353:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:30:18,418:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:30:18,422:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:30:18,462:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:30:18,498:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:30:18,627:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:30:18,773:INFO:Calculating mean and std
2024-07-13 09:30:18,776:INFO:Creating metrics dataframe
2024-07-13 09:30:18,789:INFO:Finalizing model
2024-07-13 09:30:26,924:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-13 09:30:26,924:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-13 09:30:26,924:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-13 09:30:27,223:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 09:30:27,224:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-13 09:30:27,224:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-13 09:30:27,224:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-13 09:30:27,224:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-13 09:30:27,285:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021867 seconds.
2024-07-13 09:30:27,286:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 09:30:27,286:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 09:30:27,286:INFO:[LightGBM] [Info] Total Bins 647
2024-07-13 09:30:27,287:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 29
2024-07-13 09:30:27,293:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-13 09:30:27,293:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-13 09:30:27,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:30:27,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:30:27,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:30:27,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:30:27,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:30:27,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:30:28,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:30:28,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:30:28,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:30:28,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:30:28,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:30:28,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:30:28,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:30:28,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:30:28,365:INFO:Uploading results into container
2024-07-13 09:30:28,366:INFO:Uploading model into container now
2024-07-13 09:30:28,368:INFO:_master_model_container: 2
2024-07-13 09:30:28,368:INFO:_display_container: 3
2024-07-13 09:30:28,380:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 09:30:28,380:INFO:create_model() successfully completed......................................
2024-07-13 09:30:28,846:INFO:SubProcess create_model() end ==================================
2024-07-13 09:30:28,846:INFO:choose_better activated
2024-07-13 09:30:28,850:INFO:SubProcess create_model() called ==================================
2024-07-13 09:30:28,851:INFO:Initializing create_model()
2024-07-13 09:30:28,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019709110AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-13 09:30:28,851:INFO:Checking exceptions
2024-07-13 09:30:28,854:INFO:Importing libraries
2024-07-13 09:30:28,854:INFO:Copying training dataset
2024-07-13 09:30:29,168:INFO:Defining folds
2024-07-13 09:30:29,168:INFO:Declaring metric variables
2024-07-13 09:30:29,168:INFO:Importing untrained model
2024-07-13 09:30:29,168:INFO:Declaring custom model
2024-07-13 09:30:29,169:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 09:30:29,169:INFO:Starting cross validation
2024-07-13 09:30:29,171:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 09:30:48,495:INFO:Calculating mean and std
2024-07-13 09:30:48,495:INFO:Creating metrics dataframe
2024-07-13 09:30:48,497:INFO:Finalizing model
2024-07-13 09:30:56,663:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 09:30:56,664:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-13 09:30:56,730:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018380 seconds.
2024-07-13 09:30:56,731:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 09:30:56,731:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 09:30:56,731:INFO:[LightGBM] [Info] Total Bins 643
2024-07-13 09:30:56,731:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-13 09:30:56,734:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-13 09:30:56,734:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-13 09:30:57,381:INFO:Uploading results into container
2024-07-13 09:30:57,382:INFO:Uploading model into container now
2024-07-13 09:30:57,383:INFO:_master_model_container: 3
2024-07-13 09:30:57,383:INFO:_display_container: 4
2024-07-13 09:30:57,383:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 09:30:57,383:INFO:create_model() successfully completed......................................
2024-07-13 09:30:57,546:INFO:SubProcess create_model() end ==================================
2024-07-13 09:30:57,546:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0113
2024-07-13 09:30:57,547:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0
2024-07-13 09:30:57,547:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-07-13 09:30:57,547:INFO:choose_better completed
2024-07-13 09:30:57,547:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-13 09:30:57,567:INFO:_master_model_container: 3
2024-07-13 09:30:57,567:INFO:_display_container: 3
2024-07-13 09:30:57,567:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 09:30:57,567:INFO:tune_model() successfully completed......................................
2024-07-13 09:30:57,763:INFO:Initializing plot_model()
2024-07-13 09:30:57,763:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019709110AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-13 09:30:57,764:INFO:Checking exceptions
2024-07-13 09:30:57,885:INFO:Preloading libraries
2024-07-13 09:30:57,891:INFO:Copying training dataset
2024-07-13 09:30:57,892:INFO:Plot type: auc
2024-07-13 09:31:00,820:INFO:Fitting Model
2024-07-13 09:31:00,833:INFO:Scoring test/hold-out set
2024-07-13 09:31:01,574:INFO:Visual Rendered Successfully
2024-07-13 09:31:01,757:INFO:plot_model() successfully completed......................................
2024-07-13 09:31:01,810:INFO:Initializing plot_model()
2024-07-13 09:31:01,810:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019709110AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-13 09:31:01,810:INFO:Checking exceptions
2024-07-13 09:31:01,929:INFO:Preloading libraries
2024-07-13 09:31:01,936:INFO:Copying training dataset
2024-07-13 09:31:01,936:INFO:Plot type: pr
2024-07-13 09:31:03,197:INFO:Fitting Model
2024-07-13 09:31:03,213:INFO:Scoring test/hold-out set
2024-07-13 09:31:03,736:INFO:Visual Rendered Successfully
2024-07-13 09:31:03,908:INFO:plot_model() successfully completed......................................
2024-07-13 09:31:03,924:INFO:Initializing plot_model()
2024-07-13 09:31:03,924:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019709110AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-13 09:31:03,924:INFO:Checking exceptions
2024-07-13 09:31:04,032:INFO:Preloading libraries
2024-07-13 09:31:04,039:INFO:Copying training dataset
2024-07-13 09:31:04,039:INFO:Plot type: feature
2024-07-13 09:31:04,039:WARNING:No coef_ found. Trying feature_importances_
2024-07-13 09:31:04,610:INFO:Visual Rendered Successfully
2024-07-13 09:31:04,773:INFO:plot_model() successfully completed......................................
2024-07-13 09:31:04,790:INFO:Initializing plot_model()
2024-07-13 09:31:04,790:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019709110AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-13 09:31:04,790:INFO:Checking exceptions
2024-07-13 09:31:04,913:INFO:Preloading libraries
2024-07-13 09:31:04,922:INFO:Copying training dataset
2024-07-13 09:31:04,922:INFO:Plot type: confusion_matrix
2024-07-13 09:31:06,033:INFO:Fitting Model
2024-07-13 09:31:06,039:INFO:Scoring test/hold-out set
2024-07-13 09:31:06,409:INFO:Visual Rendered Successfully
2024-07-13 09:31:06,586:INFO:plot_model() successfully completed......................................
2024-07-13 09:31:06,636:INFO:Initializing predict_model()
2024-07-13 09:31:06,636:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019709110AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000019709056340>)
2024-07-13 09:31:06,638:INFO:Checking exceptions
2024-07-13 09:31:06,638:INFO:Preloading libraries
2024-07-13 09:31:08,267:INFO:Initializing finalize_model()
2024-07-13 09:31:08,268:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019709110AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-13 09:31:08,268:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 09:31:08,345:INFO:Initializing create_model()
2024-07-13 09:31:08,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019709110AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-13 09:31:08,345:INFO:Checking exceptions
2024-07-13 09:31:08,347:INFO:Importing libraries
2024-07-13 09:31:08,347:INFO:Copying training dataset
2024-07-13 09:31:08,355:INFO:Defining folds
2024-07-13 09:31:08,355:INFO:Declaring metric variables
2024-07-13 09:31:08,355:INFO:Importing untrained model
2024-07-13 09:31:08,355:INFO:Declaring custom model
2024-07-13 09:31:08,356:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 09:31:08,358:INFO:Cross validation set to False
2024-07-13 09:31:08,358:INFO:Fitting Model
2024-07-13 09:31:20,178:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 09:31:20,178:INFO:[LightGBM] [Info] Number of positive: 36643, number of negative: 563357
2024-07-13 09:31:20,270:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026053 seconds.
2024-07-13 09:31:20,271:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 09:31:20,271:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 09:31:20,271:INFO:[LightGBM] [Info] Total Bins 642
2024-07-13 09:31:20,271:INFO:[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 27
2024-07-13 09:31:20,275:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061072 -> initscore=-2.732691
2024-07-13 09:31:20,275:INFO:[LightGBM] [Info] Start training from score -2.732691
2024-07-13 09:31:21,105:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-13 09:31:21,105:INFO:create_model() successfully completed......................................
2024-07-13 09:31:21,268:INFO:_master_model_container: 3
2024-07-13 09:31:21,268:INFO:_display_container: 4
2024-07-13 09:31:21,287:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-13 09:31:21,287:INFO:finalize_model() successfully completed......................................
2024-07-13 09:31:21,545:INFO:Initializing predict_model()
2024-07-13 09:31:21,546:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019709110AD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000019709056340>)
2024-07-13 09:31:21,546:INFO:Checking exceptions
2024-07-13 09:31:21,546:INFO:Preloading libraries
2024-07-13 09:31:21,549:INFO:Set up data.
2024-07-13 09:31:21,591:INFO:Set up index.
2024-07-13 09:31:24,574:INFO:Initializing save_model()
2024-07-13 09:31:24,575:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=Final Light GBM Model Jul2024, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-13 09:31:24,575:INFO:Adding model into prep_pipe
2024-07-13 09:31:24,575:WARNING:Only Model saved as it was a pipeline.
2024-07-13 09:31:24,600:INFO:Final Light GBM Model Jul2024.pkl saved in current working directory
2024-07-13 09:31:24,622:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-13 09:31:24,622:INFO:save_model() successfully completed......................................
2024-07-13 09:54:34,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 09:54:34,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 09:54:34,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 09:54:34,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 09:54:37,867:INFO:PyCaret ClassificationExperiment
2024-07-13 09:54:37,868:INFO:Logging name: credit
2024-07-13 09:54:37,868:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-13 09:54:37,868:INFO:version 3.3.2
2024-07-13 09:54:37,868:INFO:Initializing setup()
2024-07-13 09:54:37,869:INFO:self.USI: 7303
2024-07-13 09:54:37,869:INFO:self._variable_keys: {'fold_shuffle_param', 'X_test', 'y_test', '_available_plots', 'n_jobs_param', 'fold_groups_param', 'seed', 'data', 'gpu_n_jobs_param', 'y_train', 'is_multiclass', '_ml_usecase', 'idx', 'fold_generator', 'log_plots_param', 'y', 'exp_name_log', 'memory', 'X', 'USI', 'exp_id', 'gpu_param', 'fix_imbalance', 'html_param', 'pipeline', 'X_train', 'logging_param', 'target_param'}
2024-07-13 09:54:37,869:INFO:Checking environment
2024-07-13 09:54:37,869:INFO:python_version: 3.11.7
2024-07-13 09:54:37,869:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2024-07-13 09:54:37,869:INFO:machine: AMD64
2024-07-13 09:54:37,869:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-13 09:54:37,873:INFO:Memory: svmem(total=16849293312, available=7731646464, percent=54.1, used=9117646848, free=7731646464)
2024-07-13 09:54:37,873:INFO:Physical Core: 12
2024-07-13 09:54:37,874:INFO:Logical Core: 16
2024-07-13 09:54:37,874:INFO:Checking libraries
2024-07-13 09:54:37,874:INFO:System:
2024-07-13 09:54:37,874:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2024-07-13 09:54:37,874:INFO:executable: c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\python.exe
2024-07-13 09:54:37,874:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-13 09:54:37,874:INFO:PyCaret required dependencies:
2024-07-13 09:54:37,911:INFO:                 pip: 24.1.2
2024-07-13 09:54:37,911:INFO:          setuptools: 65.5.0
2024-07-13 09:54:37,911:INFO:             pycaret: 3.3.2
2024-07-13 09:54:37,911:INFO:             IPython: 8.26.0
2024-07-13 09:54:37,911:INFO:          ipywidgets: 8.1.3
2024-07-13 09:54:37,911:INFO:                tqdm: 4.66.4
2024-07-13 09:54:37,911:INFO:               numpy: 1.26.4
2024-07-13 09:54:37,911:INFO:              pandas: 2.1.4
2024-07-13 09:54:37,911:INFO:              jinja2: 3.1.4
2024-07-13 09:54:37,911:INFO:               scipy: 1.11.4
2024-07-13 09:54:37,911:INFO:              joblib: 1.3.2
2024-07-13 09:54:37,912:INFO:             sklearn: 1.4.2
2024-07-13 09:54:37,912:INFO:                pyod: 2.0.1
2024-07-13 09:54:37,912:INFO:            imblearn: 0.12.3
2024-07-13 09:54:37,912:INFO:   category_encoders: 2.6.3
2024-07-13 09:54:37,912:INFO:            lightgbm: 4.4.0
2024-07-13 09:54:37,912:INFO:               numba: 0.60.0
2024-07-13 09:54:37,912:INFO:            requests: 2.32.3
2024-07-13 09:54:37,912:INFO:          matplotlib: 3.7.5
2024-07-13 09:54:37,912:INFO:          scikitplot: 0.3.7
2024-07-13 09:54:37,912:INFO:         yellowbrick: 1.5
2024-07-13 09:54:37,912:INFO:              plotly: 5.22.0
2024-07-13 09:54:37,912:INFO:    plotly-resampler: Not installed
2024-07-13 09:54:37,912:INFO:             kaleido: 0.2.1
2024-07-13 09:54:37,912:INFO:           schemdraw: 0.15
2024-07-13 09:54:37,912:INFO:         statsmodels: 0.14.2
2024-07-13 09:54:37,912:INFO:              sktime: 0.26.0
2024-07-13 09:54:37,912:INFO:               tbats: 1.1.3
2024-07-13 09:54:37,912:INFO:            pmdarima: 2.0.4
2024-07-13 09:54:37,912:INFO:              psutil: 6.0.0
2024-07-13 09:54:37,912:INFO:          markupsafe: 2.1.5
2024-07-13 09:54:37,912:INFO:             pickle5: Not installed
2024-07-13 09:54:37,912:INFO:         cloudpickle: 3.0.0
2024-07-13 09:54:37,912:INFO:         deprecation: 2.1.0
2024-07-13 09:54:37,912:INFO:              xxhash: 3.4.1
2024-07-13 09:54:37,912:INFO:           wurlitzer: Not installed
2024-07-13 09:54:37,912:INFO:PyCaret optional dependencies:
2024-07-13 09:54:37,931:INFO:                shap: Not installed
2024-07-13 09:54:37,931:INFO:           interpret: Not installed
2024-07-13 09:54:37,931:INFO:                umap: Not installed
2024-07-13 09:54:37,931:INFO:     ydata_profiling: Not installed
2024-07-13 09:54:37,931:INFO:  explainerdashboard: Not installed
2024-07-13 09:54:37,931:INFO:             autoviz: Not installed
2024-07-13 09:54:37,931:INFO:           fairlearn: Not installed
2024-07-13 09:54:37,931:INFO:          deepchecks: Not installed
2024-07-13 09:54:37,931:INFO:             xgboost: Not installed
2024-07-13 09:54:37,931:INFO:            catboost: Not installed
2024-07-13 09:54:37,931:INFO:              kmodes: Not installed
2024-07-13 09:54:37,932:INFO:             mlxtend: Not installed
2024-07-13 09:54:37,932:INFO:       statsforecast: Not installed
2024-07-13 09:54:37,932:INFO:        tune_sklearn: Not installed
2024-07-13 09:54:37,932:INFO:                 ray: Not installed
2024-07-13 09:54:37,932:INFO:            hyperopt: Not installed
2024-07-13 09:54:37,932:INFO:              optuna: Not installed
2024-07-13 09:54:37,932:INFO:               skopt: Not installed
2024-07-13 09:54:37,932:INFO:              mlflow: Not installed
2024-07-13 09:54:37,932:INFO:              gradio: Not installed
2024-07-13 09:54:37,932:INFO:             fastapi: Not installed
2024-07-13 09:54:37,932:INFO:             uvicorn: Not installed
2024-07-13 09:54:37,932:INFO:              m2cgen: Not installed
2024-07-13 09:54:37,932:INFO:           evidently: Not installed
2024-07-13 09:54:37,932:INFO:               fugue: Not installed
2024-07-13 09:54:37,932:INFO:           streamlit: Not installed
2024-07-13 09:54:37,932:INFO:             prophet: Not installed
2024-07-13 09:54:37,932:INFO:None
2024-07-13 09:54:37,932:INFO:Set up data.
2024-07-13 09:54:38,032:INFO:Set up folding strategy.
2024-07-13 09:54:38,032:INFO:Set up train/test split.
2024-07-13 09:54:38,356:INFO:Set up index.
2024-07-13 09:54:38,397:INFO:Assigning column types.
2024-07-13 09:54:38,506:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-13 09:54:38,567:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-13 09:54:38,577:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 09:54:38,622:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:38,622:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:38,682:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-13 09:54:38,682:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 09:54:38,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:38,715:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:38,716:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-13 09:54:38,769:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 09:54:38,801:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:38,802:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:38,858:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 09:54:38,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:38,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:38,894:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-13 09:54:38,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:38,978:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:39,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:39,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:39,090:INFO:Preparing preprocessing pipeline...
2024-07-13 09:54:39,112:INFO:Set up simple imputation.
2024-07-13 09:54:39,503:INFO:Set up encoding of ordinal features.
2024-07-13 09:54:39,537:INFO:Set up encoding of categorical features.
2024-07-13 09:54:39,537:INFO:Set up column transformation.
2024-07-13 09:54:39,537:INFO:Set up feature normalization.
2024-07-13 09:54:41,144:INFO:Finished creating preprocessing pipeline.
2024-07-13 09:54:41,170:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-07-13 09:54:41,171:INFO:Creating final display dataframe.
2024-07-13 09:54:42,657:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target              mau
2                   Target type           Binary
3           Original data shape     (600000, 13)
4        Transformed data shape     (600000, 30)
5   Transformed train set shape     (420000, 30)
6    Transformed test set shape     (180000, 30)
7              Numeric features                5
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Transformation             True
16        Transformation method         quantile
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           credit
25                          USI             7303
2024-07-13 09:54:42,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:42,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:42,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:42,857:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:42,857:INFO:setup() successfully completed in 5.02s...............
2024-07-13 09:54:42,873:INFO:gpu_param set to False
2024-07-13 09:54:42,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:42,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:43,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:43,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:54:43,097:INFO:Initializing create_model()
2024-07-13 09:54:43,097:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002118174B9D0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-13 09:54:43,097:INFO:Checking exceptions
2024-07-13 09:54:43,116:INFO:Importing libraries
2024-07-13 09:54:43,116:INFO:Copying training dataset
2024-07-13 09:54:43,473:INFO:Defining folds
2024-07-13 09:54:43,473:INFO:Declaring metric variables
2024-07-13 09:54:43,477:INFO:Importing untrained model
2024-07-13 09:54:43,481:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 09:54:43,489:INFO:Starting cross validation
2024-07-13 09:54:43,492:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 09:55:10,525:INFO:Calculating mean and std
2024-07-13 09:55:10,531:INFO:Creating metrics dataframe
2024-07-13 09:55:10,541:INFO:Finalizing model
2024-07-13 09:55:18,664:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 09:55:18,670:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-13 09:55:18,736:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018242 seconds.
2024-07-13 09:55:18,736:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 09:55:18,736:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 09:55:18,738:INFO:[LightGBM] [Info] Total Bins 643
2024-07-13 09:55:18,738:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-13 09:55:18,741:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-13 09:55:18,742:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-13 09:55:19,333:INFO:Uploading results into container
2024-07-13 09:55:19,334:INFO:Uploading model into container now
2024-07-13 09:55:19,347:INFO:_master_model_container: 1
2024-07-13 09:55:19,347:INFO:_display_container: 2
2024-07-13 09:55:19,348:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 09:55:19,348:INFO:create_model() successfully completed......................................
2024-07-13 09:55:19,639:INFO:Initializing tune_model()
2024-07-13 09:55:19,639:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002118174B9D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=1, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-13 09:55:19,640:INFO:Checking exceptions
2024-07-13 09:55:19,797:INFO:Copying training dataset
2024-07-13 09:55:19,996:INFO:Checking base model
2024-07-13 09:55:19,996:INFO:Base model : Light Gradient Boosting Machine
2024-07-13 09:55:20,001:INFO:Declaring metric variables
2024-07-13 09:55:20,004:INFO:Defining Hyperparameters
2024-07-13 09:55:20,168:INFO:Tuning with n_jobs=-1
2024-07-13 09:55:20,168:INFO:Initializing RandomizedSearchCV
2024-07-13 09:55:43,901:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.7}
2024-07-13 09:55:43,903:INFO:Hyperparameter search completed
2024-07-13 09:55:43,903:INFO:SubProcess create_model() called ==================================
2024-07-13 09:55:43,904:INFO:Initializing create_model()
2024-07-13 09:55:43,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002118174B9D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002119DC32AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 3, 'num_leaves': 256, 'n_estimators': 30, 'min_split_gain': 0.2, 'min_child_samples': 1, 'learning_rate': 0.0005, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.7})
2024-07-13 09:55:43,905:INFO:Checking exceptions
2024-07-13 09:55:43,905:INFO:Importing libraries
2024-07-13 09:55:43,905:INFO:Copying training dataset
2024-07-13 09:55:44,281:INFO:Defining folds
2024-07-13 09:55:44,282:INFO:Declaring metric variables
2024-07-13 09:55:44,287:INFO:Importing untrained model
2024-07-13 09:55:44,287:INFO:Declaring custom model
2024-07-13 09:55:44,292:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 09:55:44,302:INFO:Starting cross validation
2024-07-13 09:55:44,305:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 09:56:04,895:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:56:05,020:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:56:05,279:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:56:05,528:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:56:05,582:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:56:05,688:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:56:05,837:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:56:05,899:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:56:06,270:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:56:06,655:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:56:06,799:INFO:Calculating mean and std
2024-07-13 09:56:06,802:INFO:Creating metrics dataframe
2024-07-13 09:56:06,808:INFO:Finalizing model
2024-07-13 09:57:43,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 09:57:43,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 09:57:43,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 09:57:43,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 09:57:46,989:INFO:PyCaret ClassificationExperiment
2024-07-13 09:57:46,989:INFO:Logging name: credit
2024-07-13 09:57:46,989:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-13 09:57:46,989:INFO:version 3.3.2
2024-07-13 09:57:46,989:INFO:Initializing setup()
2024-07-13 09:57:46,989:INFO:self.USI: 12fc
2024-07-13 09:57:46,989:INFO:self._variable_keys: {'html_param', 'y_test', 'gpu_param', 'y', 'n_jobs_param', 'fold_generator', 'X_test', '_available_plots', 'USI', 'fold_groups_param', 'fix_imbalance', 'logging_param', 'idx', 'exp_id', 'memory', 'pipeline', 'data', 'target_param', 'X', 'log_plots_param', 'is_multiclass', 'exp_name_log', 'seed', 'fold_shuffle_param', 'y_train', '_ml_usecase', 'gpu_n_jobs_param', 'X_train'}
2024-07-13 09:57:46,989:INFO:Checking environment
2024-07-13 09:57:46,989:INFO:python_version: 3.11.7
2024-07-13 09:57:46,989:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2024-07-13 09:57:46,990:INFO:machine: AMD64
2024-07-13 09:57:46,990:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-13 09:57:46,996:INFO:Memory: svmem(total=16849293312, available=8804343808, percent=47.7, used=8044949504, free=8804343808)
2024-07-13 09:57:46,996:INFO:Physical Core: 12
2024-07-13 09:57:46,996:INFO:Logical Core: 16
2024-07-13 09:57:46,996:INFO:Checking libraries
2024-07-13 09:57:46,996:INFO:System:
2024-07-13 09:57:46,996:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2024-07-13 09:57:46,996:INFO:executable: c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\python.exe
2024-07-13 09:57:46,996:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-13 09:57:46,996:INFO:PyCaret required dependencies:
2024-07-13 09:57:47,029:INFO:                 pip: 24.1.2
2024-07-13 09:57:47,029:INFO:          setuptools: 65.5.0
2024-07-13 09:57:47,029:INFO:             pycaret: 3.3.2
2024-07-13 09:57:47,029:INFO:             IPython: 8.26.0
2024-07-13 09:57:47,029:INFO:          ipywidgets: 8.1.3
2024-07-13 09:57:47,029:INFO:                tqdm: 4.66.4
2024-07-13 09:57:47,029:INFO:               numpy: 1.26.4
2024-07-13 09:57:47,029:INFO:              pandas: 2.1.4
2024-07-13 09:57:47,029:INFO:              jinja2: 3.1.4
2024-07-13 09:57:47,029:INFO:               scipy: 1.11.4
2024-07-13 09:57:47,030:INFO:              joblib: 1.3.2
2024-07-13 09:57:47,030:INFO:             sklearn: 1.4.2
2024-07-13 09:57:47,030:INFO:                pyod: 2.0.1
2024-07-13 09:57:47,030:INFO:            imblearn: 0.12.3
2024-07-13 09:57:47,030:INFO:   category_encoders: 2.6.3
2024-07-13 09:57:47,030:INFO:            lightgbm: 4.4.0
2024-07-13 09:57:47,030:INFO:               numba: 0.60.0
2024-07-13 09:57:47,030:INFO:            requests: 2.32.3
2024-07-13 09:57:47,030:INFO:          matplotlib: 3.7.5
2024-07-13 09:57:47,030:INFO:          scikitplot: 0.3.7
2024-07-13 09:57:47,030:INFO:         yellowbrick: 1.5
2024-07-13 09:57:47,030:INFO:              plotly: 5.22.0
2024-07-13 09:57:47,030:INFO:    plotly-resampler: Not installed
2024-07-13 09:57:47,030:INFO:             kaleido: 0.2.1
2024-07-13 09:57:47,030:INFO:           schemdraw: 0.15
2024-07-13 09:57:47,030:INFO:         statsmodels: 0.14.2
2024-07-13 09:57:47,030:INFO:              sktime: 0.26.0
2024-07-13 09:57:47,030:INFO:               tbats: 1.1.3
2024-07-13 09:57:47,030:INFO:            pmdarima: 2.0.4
2024-07-13 09:57:47,031:INFO:              psutil: 6.0.0
2024-07-13 09:57:47,031:INFO:          markupsafe: 2.1.5
2024-07-13 09:57:47,031:INFO:             pickle5: Not installed
2024-07-13 09:57:47,031:INFO:         cloudpickle: 3.0.0
2024-07-13 09:57:47,031:INFO:         deprecation: 2.1.0
2024-07-13 09:57:47,031:INFO:              xxhash: 3.4.1
2024-07-13 09:57:47,031:INFO:           wurlitzer: Not installed
2024-07-13 09:57:47,031:INFO:PyCaret optional dependencies:
2024-07-13 09:57:47,044:INFO:                shap: Not installed
2024-07-13 09:57:47,045:INFO:           interpret: Not installed
2024-07-13 09:57:47,045:INFO:                umap: Not installed
2024-07-13 09:57:47,045:INFO:     ydata_profiling: Not installed
2024-07-13 09:57:47,045:INFO:  explainerdashboard: Not installed
2024-07-13 09:57:47,045:INFO:             autoviz: Not installed
2024-07-13 09:57:47,045:INFO:           fairlearn: Not installed
2024-07-13 09:57:47,045:INFO:          deepchecks: Not installed
2024-07-13 09:57:47,045:INFO:             xgboost: Not installed
2024-07-13 09:57:47,045:INFO:            catboost: Not installed
2024-07-13 09:57:47,045:INFO:              kmodes: Not installed
2024-07-13 09:57:47,045:INFO:             mlxtend: Not installed
2024-07-13 09:57:47,045:INFO:       statsforecast: Not installed
2024-07-13 09:57:47,045:INFO:        tune_sklearn: Not installed
2024-07-13 09:57:47,045:INFO:                 ray: Not installed
2024-07-13 09:57:47,045:INFO:            hyperopt: Not installed
2024-07-13 09:57:47,045:INFO:              optuna: Not installed
2024-07-13 09:57:47,045:INFO:               skopt: Not installed
2024-07-13 09:57:47,045:INFO:              mlflow: Not installed
2024-07-13 09:57:47,045:INFO:              gradio: Not installed
2024-07-13 09:57:47,045:INFO:             fastapi: Not installed
2024-07-13 09:57:47,045:INFO:             uvicorn: Not installed
2024-07-13 09:57:47,045:INFO:              m2cgen: Not installed
2024-07-13 09:57:47,045:INFO:           evidently: Not installed
2024-07-13 09:57:47,045:INFO:               fugue: Not installed
2024-07-13 09:57:47,045:INFO:           streamlit: Not installed
2024-07-13 09:57:47,045:INFO:             prophet: Not installed
2024-07-13 09:57:47,045:INFO:None
2024-07-13 09:57:47,047:INFO:Set up data.
2024-07-13 09:57:47,133:INFO:Set up folding strategy.
2024-07-13 09:57:47,133:INFO:Set up train/test split.
2024-07-13 09:57:47,421:INFO:Set up index.
2024-07-13 09:57:47,459:INFO:Assigning column types.
2024-07-13 09:57:47,559:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-13 09:57:47,608:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-13 09:57:47,613:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 09:57:47,654:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:47,655:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:47,704:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-13 09:57:47,705:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 09:57:47,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:47,735:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:47,736:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-13 09:57:47,785:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 09:57:47,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:47,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:47,866:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 09:57:47,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:47,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:47,898:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-13 09:57:47,981:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:47,982:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:48,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:48,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:48,075:INFO:Preparing preprocessing pipeline...
2024-07-13 09:57:48,098:INFO:Set up simple imputation.
2024-07-13 09:57:48,510:INFO:Set up encoding of ordinal features.
2024-07-13 09:57:48,549:INFO:Set up encoding of categorical features.
2024-07-13 09:57:48,551:INFO:Set up column transformation.
2024-07-13 09:57:48,551:INFO:Set up feature normalization.
2024-07-13 09:57:50,172:INFO:Finished creating preprocessing pipeline.
2024-07-13 09:57:50,194:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-07-13 09:57:50,194:INFO:Creating final display dataframe.
2024-07-13 09:57:51,771:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target              mau
2                   Target type           Binary
3           Original data shape     (600000, 13)
4        Transformed data shape     (600000, 30)
5   Transformed train set shape     (420000, 30)
6    Transformed test set shape     (180000, 30)
7              Numeric features                5
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Transformation             True
16        Transformation method         quantile
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           credit
25                          USI             12fc
2024-07-13 09:57:51,905:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:51,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:52,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:52,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:52,015:INFO:setup() successfully completed in 5.06s...............
2024-07-13 09:57:52,030:INFO:gpu_param set to False
2024-07-13 09:57:52,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:52,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:52,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:52,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 09:57:52,281:INFO:Initializing create_model()
2024-07-13 09:57:52,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A2BF35E210>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-13 09:57:52,281:INFO:Checking exceptions
2024-07-13 09:57:52,299:INFO:Importing libraries
2024-07-13 09:57:52,299:INFO:Copying training dataset
2024-07-13 09:57:52,648:INFO:Defining folds
2024-07-13 09:57:52,648:INFO:Declaring metric variables
2024-07-13 09:57:52,653:INFO:Importing untrained model
2024-07-13 09:57:52,656:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 09:57:52,667:INFO:Starting cross validation
2024-07-13 09:57:52,670:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 09:58:17,206:INFO:Calculating mean and std
2024-07-13 09:58:17,209:INFO:Creating metrics dataframe
2024-07-13 09:58:17,218:INFO:Finalizing model
2024-07-13 09:58:26,481:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 09:58:26,482:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-13 09:58:26,551:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023286 seconds.
2024-07-13 09:58:26,551:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 09:58:26,552:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 09:58:26,553:INFO:[LightGBM] [Info] Total Bins 643
2024-07-13 09:58:26,553:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-13 09:58:26,556:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-13 09:58:26,557:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-13 09:58:27,352:INFO:Uploading results into container
2024-07-13 09:58:27,353:INFO:Uploading model into container now
2024-07-13 09:58:27,365:INFO:_master_model_container: 1
2024-07-13 09:58:27,365:INFO:_display_container: 2
2024-07-13 09:58:27,366:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 09:58:27,366:INFO:create_model() successfully completed......................................
2024-07-13 09:58:27,618:INFO:Initializing tune_model()
2024-07-13 09:58:27,618:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A2BF35E210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=1, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-13 09:58:27,618:INFO:Checking exceptions
2024-07-13 09:58:27,808:INFO:Copying training dataset
2024-07-13 09:58:28,062:INFO:Checking base model
2024-07-13 09:58:28,063:INFO:Base model : Light Gradient Boosting Machine
2024-07-13 09:58:28,068:INFO:Declaring metric variables
2024-07-13 09:58:28,073:INFO:Defining Hyperparameters
2024-07-13 09:58:28,251:INFO:Tuning with n_jobs=-1
2024-07-13 09:58:28,251:INFO:Initializing RandomizedSearchCV
2024-07-13 09:58:52,834:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.7}
2024-07-13 09:58:52,835:INFO:Hyperparameter search completed
2024-07-13 09:58:52,835:INFO:SubProcess create_model() called ==================================
2024-07-13 09:58:52,836:INFO:Initializing create_model()
2024-07-13 09:58:52,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A2BF35E210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A2BF245E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 3, 'num_leaves': 256, 'n_estimators': 30, 'min_split_gain': 0.2, 'min_child_samples': 1, 'learning_rate': 0.0005, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.7})
2024-07-13 09:58:52,836:INFO:Checking exceptions
2024-07-13 09:58:52,837:INFO:Importing libraries
2024-07-13 09:58:52,837:INFO:Copying training dataset
2024-07-13 09:58:53,163:INFO:Defining folds
2024-07-13 09:58:53,164:INFO:Declaring metric variables
2024-07-13 09:58:53,168:INFO:Importing untrained model
2024-07-13 09:58:53,168:INFO:Declaring custom model
2024-07-13 09:58:53,174:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 09:58:53,182:INFO:Starting cross validation
2024-07-13 09:58:53,186:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 09:59:14,614:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:59:14,727:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:59:14,883:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:59:15,296:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:59:15,304:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:59:15,329:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:59:15,338:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:59:15,446:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:59:15,614:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:59:15,729:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 09:59:15,874:INFO:Calculating mean and std
2024-07-13 09:59:15,876:INFO:Creating metrics dataframe
2024-07-13 09:59:15,883:INFO:Finalizing model
2024-07-13 09:59:24,218:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-13 09:59:24,219:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-13 09:59:24,219:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-13 09:59:24,510:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 09:59:24,510:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-13 09:59:24,511:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-13 09:59:24,511:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-13 09:59:24,511:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-13 09:59:24,574:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018289 seconds.
2024-07-13 09:59:24,574:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 09:59:24,574:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 09:59:24,574:INFO:[LightGBM] [Info] Total Bins 647
2024-07-13 09:59:24,575:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 29
2024-07-13 09:59:24,581:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-13 09:59:24,581:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-13 09:59:24,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:59:24,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:59:24,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:59:24,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:59:25,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:59:25,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:59:25,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:59:25,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:59:25,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:59:25,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:59:25,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:59:25,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:59:25,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:59:25,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 09:59:25,322:INFO:Uploading results into container
2024-07-13 09:59:25,323:INFO:Uploading model into container now
2024-07-13 09:59:25,324:INFO:_master_model_container: 2
2024-07-13 09:59:25,324:INFO:_display_container: 3
2024-07-13 09:59:25,325:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 09:59:25,325:INFO:create_model() successfully completed......................................
2024-07-13 09:59:25,526:INFO:SubProcess create_model() end ==================================
2024-07-13 09:59:25,527:INFO:choose_better activated
2024-07-13 09:59:25,531:INFO:SubProcess create_model() called ==================================
2024-07-13 09:59:25,532:INFO:Initializing create_model()
2024-07-13 09:59:25,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A2BF35E210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-13 09:59:25,532:INFO:Checking exceptions
2024-07-13 09:59:25,534:INFO:Importing libraries
2024-07-13 09:59:25,534:INFO:Copying training dataset
2024-07-13 09:59:25,878:INFO:Defining folds
2024-07-13 09:59:25,878:INFO:Declaring metric variables
2024-07-13 09:59:25,878:INFO:Importing untrained model
2024-07-13 09:59:25,878:INFO:Declaring custom model
2024-07-13 09:59:25,879:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 09:59:25,879:INFO:Starting cross validation
2024-07-13 09:59:25,881:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 09:59:45,322:INFO:Calculating mean and std
2024-07-13 09:59:45,322:INFO:Creating metrics dataframe
2024-07-13 09:59:45,325:INFO:Finalizing model
2024-07-13 09:59:53,820:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 09:59:53,821:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-13 09:59:53,892:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024694 seconds.
2024-07-13 09:59:53,892:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 09:59:53,892:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 09:59:53,892:INFO:[LightGBM] [Info] Total Bins 643
2024-07-13 09:59:53,892:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-13 09:59:53,895:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-13 09:59:53,895:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-13 09:59:54,522:INFO:Uploading results into container
2024-07-13 09:59:54,523:INFO:Uploading model into container now
2024-07-13 09:59:54,523:INFO:_master_model_container: 3
2024-07-13 09:59:54,523:INFO:_display_container: 4
2024-07-13 09:59:54,524:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 09:59:54,524:INFO:create_model() successfully completed......................................
2024-07-13 09:59:54,709:INFO:SubProcess create_model() end ==================================
2024-07-13 09:59:54,710:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0113
2024-07-13 09:59:54,711:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0
2024-07-13 09:59:54,711:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-07-13 09:59:54,711:INFO:choose_better completed
2024-07-13 09:59:54,711:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-13 09:59:54,722:INFO:_master_model_container: 3
2024-07-13 09:59:54,722:INFO:_display_container: 3
2024-07-13 09:59:54,722:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 09:59:54,723:INFO:tune_model() successfully completed......................................
2024-07-13 09:59:54,918:INFO:Initializing plot_model()
2024-07-13 09:59:54,918:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A2BF35E210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-13 09:59:54,918:INFO:Checking exceptions
2024-07-13 09:59:55,027:INFO:Preloading libraries
2024-07-13 09:59:55,034:INFO:Copying training dataset
2024-07-13 09:59:55,034:INFO:Plot type: auc
2024-07-13 09:59:56,159:INFO:Fitting Model
2024-07-13 09:59:56,171:INFO:Scoring test/hold-out set
2024-07-13 09:59:56,844:INFO:Visual Rendered Successfully
2024-07-13 09:59:57,024:INFO:plot_model() successfully completed......................................
2024-07-13 09:59:57,041:INFO:Initializing plot_model()
2024-07-13 09:59:57,041:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A2BF35E210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-13 09:59:57,042:INFO:Checking exceptions
2024-07-13 09:59:57,147:INFO:Preloading libraries
2024-07-13 09:59:57,156:INFO:Copying training dataset
2024-07-13 09:59:57,156:INFO:Plot type: pr
2024-07-13 09:59:58,238:INFO:Fitting Model
2024-07-13 09:59:58,254:INFO:Scoring test/hold-out set
2024-07-13 09:59:58,759:INFO:Visual Rendered Successfully
2024-07-13 09:59:58,939:INFO:plot_model() successfully completed......................................
2024-07-13 09:59:58,962:INFO:Initializing plot_model()
2024-07-13 09:59:58,962:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A2BF35E210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-13 09:59:58,962:INFO:Checking exceptions
2024-07-13 09:59:59,091:INFO:Preloading libraries
2024-07-13 09:59:59,099:INFO:Copying training dataset
2024-07-13 09:59:59,100:INFO:Plot type: feature
2024-07-13 09:59:59,100:WARNING:No coef_ found. Trying feature_importances_
2024-07-13 09:59:59,724:INFO:Visual Rendered Successfully
2024-07-13 09:59:59,902:INFO:plot_model() successfully completed......................................
2024-07-13 09:59:59,927:INFO:Initializing plot_model()
2024-07-13 09:59:59,928:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A2BF35E210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-13 09:59:59,928:INFO:Checking exceptions
2024-07-13 10:00:00,068:INFO:Preloading libraries
2024-07-13 10:00:00,079:INFO:Copying training dataset
2024-07-13 10:00:00,079:INFO:Plot type: confusion_matrix
2024-07-13 10:00:01,390:INFO:Fitting Model
2024-07-13 10:00:01,397:INFO:Scoring test/hold-out set
2024-07-13 10:00:01,794:INFO:Visual Rendered Successfully
2024-07-13 10:00:01,978:INFO:plot_model() successfully completed......................................
2024-07-13 10:00:02,021:INFO:Initializing predict_model()
2024-07-13 10:00:02,021:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A2BF35E210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A2BF3B4E00>)
2024-07-13 10:00:02,022:INFO:Checking exceptions
2024-07-13 10:00:02,022:INFO:Preloading libraries
2024-07-13 10:00:03,746:INFO:Initializing finalize_model()
2024-07-13 10:00:03,746:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A2BF35E210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-13 10:00:03,747:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 10:00:03,829:INFO:Initializing create_model()
2024-07-13 10:00:03,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A2BF35E210>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-13 10:00:03,829:INFO:Checking exceptions
2024-07-13 10:00:03,830:INFO:Importing libraries
2024-07-13 10:00:03,830:INFO:Copying training dataset
2024-07-13 10:00:03,841:INFO:Defining folds
2024-07-13 10:00:03,841:INFO:Declaring metric variables
2024-07-13 10:00:03,841:INFO:Importing untrained model
2024-07-13 10:00:03,841:INFO:Declaring custom model
2024-07-13 10:00:03,842:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 10:00:03,844:INFO:Cross validation set to False
2024-07-13 10:00:03,844:INFO:Fitting Model
2024-07-13 10:00:16,306:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 10:00:16,307:INFO:[LightGBM] [Info] Number of positive: 36643, number of negative: 563357
2024-07-13 10:00:16,418:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031081 seconds.
2024-07-13 10:00:16,418:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 10:00:16,418:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 10:00:16,418:INFO:[LightGBM] [Info] Total Bins 642
2024-07-13 10:00:16,419:INFO:[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 27
2024-07-13 10:00:16,422:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061072 -> initscore=-2.732691
2024-07-13 10:00:16,422:INFO:[LightGBM] [Info] Start training from score -2.732691
2024-07-13 10:00:17,313:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-13 10:00:17,313:INFO:create_model() successfully completed......................................
2024-07-13 10:00:17,480:INFO:_master_model_container: 3
2024-07-13 10:00:17,482:INFO:_display_container: 4
2024-07-13 10:00:17,503:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-13 10:00:17,503:INFO:finalize_model() successfully completed......................................
2024-07-13 10:00:17,823:INFO:Initializing predict_model()
2024-07-13 10:00:17,823:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A2BF35E210>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A2BF381B20>)
2024-07-13 10:00:17,823:INFO:Checking exceptions
2024-07-13 10:00:17,823:INFO:Preloading libraries
2024-07-13 10:00:17,827:INFO:Set up data.
2024-07-13 10:00:17,869:INFO:Set up index.
2024-07-13 10:00:20,603:INFO:Initializing save_model()
2024-07-13 10:00:20,603:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=Final Light GBM Model Jul2024, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-13 10:00:20,603:INFO:Adding model into prep_pipe
2024-07-13 10:00:20,603:WARNING:Only Model saved as it was a pipeline.
2024-07-13 10:00:20,627:INFO:Final Light GBM Model Jul2024.pkl saved in current working directory
2024-07-13 10:00:20,649:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-13 10:00:20,650:INFO:save_model() successfully completed......................................
2024-07-13 10:03:03,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 10:03:03,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 10:03:03,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 10:03:03,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 10:03:06,391:INFO:PyCaret ClassificationExperiment
2024-07-13 10:03:06,391:INFO:Logging name: credit
2024-07-13 10:03:06,391:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-13 10:03:06,391:INFO:version 3.3.2
2024-07-13 10:03:06,391:INFO:Initializing setup()
2024-07-13 10:03:06,391:INFO:self.USI: 0135
2024-07-13 10:03:06,391:INFO:self._variable_keys: {'y_test', 'exp_id', 'pipeline', '_ml_usecase', 'exp_name_log', 'fold_groups_param', 'fold_shuffle_param', 'idx', 'logging_param', 'target_param', 'seed', 'memory', 'y', 'html_param', 'X', 'is_multiclass', 'data', 'fold_generator', 'fix_imbalance', '_available_plots', 'X_test', 'gpu_n_jobs_param', 'n_jobs_param', 'log_plots_param', 'X_train', 'y_train', 'USI', 'gpu_param'}
2024-07-13 10:03:06,391:INFO:Checking environment
2024-07-13 10:03:06,391:INFO:python_version: 3.11.7
2024-07-13 10:03:06,392:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2024-07-13 10:03:06,392:INFO:machine: AMD64
2024-07-13 10:03:06,392:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-13 10:03:06,396:INFO:Memory: svmem(total=16849293312, available=8847437824, percent=47.5, used=8001855488, free=8847437824)
2024-07-13 10:03:06,396:INFO:Physical Core: 12
2024-07-13 10:03:06,396:INFO:Logical Core: 16
2024-07-13 10:03:06,396:INFO:Checking libraries
2024-07-13 10:03:06,396:INFO:System:
2024-07-13 10:03:06,396:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2024-07-13 10:03:06,397:INFO:executable: c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\python.exe
2024-07-13 10:03:06,397:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-13 10:03:06,397:INFO:PyCaret required dependencies:
2024-07-13 10:03:06,427:INFO:                 pip: 24.1.2
2024-07-13 10:03:06,427:INFO:          setuptools: 65.5.0
2024-07-13 10:03:06,427:INFO:             pycaret: 3.3.2
2024-07-13 10:03:06,427:INFO:             IPython: 8.26.0
2024-07-13 10:03:06,427:INFO:          ipywidgets: 8.1.3
2024-07-13 10:03:06,427:INFO:                tqdm: 4.66.4
2024-07-13 10:03:06,427:INFO:               numpy: 1.26.4
2024-07-13 10:03:06,427:INFO:              pandas: 2.1.4
2024-07-13 10:03:06,427:INFO:              jinja2: 3.1.4
2024-07-13 10:03:06,427:INFO:               scipy: 1.11.4
2024-07-13 10:03:06,427:INFO:              joblib: 1.3.2
2024-07-13 10:03:06,427:INFO:             sklearn: 1.4.2
2024-07-13 10:03:06,427:INFO:                pyod: 2.0.1
2024-07-13 10:03:06,427:INFO:            imblearn: 0.12.3
2024-07-13 10:03:06,427:INFO:   category_encoders: 2.6.3
2024-07-13 10:03:06,427:INFO:            lightgbm: 4.4.0
2024-07-13 10:03:06,427:INFO:               numba: 0.60.0
2024-07-13 10:03:06,427:INFO:            requests: 2.32.3
2024-07-13 10:03:06,427:INFO:          matplotlib: 3.7.5
2024-07-13 10:03:06,427:INFO:          scikitplot: 0.3.7
2024-07-13 10:03:06,427:INFO:         yellowbrick: 1.5
2024-07-13 10:03:06,427:INFO:              plotly: 5.22.0
2024-07-13 10:03:06,427:INFO:    plotly-resampler: Not installed
2024-07-13 10:03:06,428:INFO:             kaleido: 0.2.1
2024-07-13 10:03:06,428:INFO:           schemdraw: 0.15
2024-07-13 10:03:06,428:INFO:         statsmodels: 0.14.2
2024-07-13 10:03:06,428:INFO:              sktime: 0.26.0
2024-07-13 10:03:06,428:INFO:               tbats: 1.1.3
2024-07-13 10:03:06,428:INFO:            pmdarima: 2.0.4
2024-07-13 10:03:06,428:INFO:              psutil: 6.0.0
2024-07-13 10:03:06,428:INFO:          markupsafe: 2.1.5
2024-07-13 10:03:06,428:INFO:             pickle5: Not installed
2024-07-13 10:03:06,428:INFO:         cloudpickle: 3.0.0
2024-07-13 10:03:06,428:INFO:         deprecation: 2.1.0
2024-07-13 10:03:06,428:INFO:              xxhash: 3.4.1
2024-07-13 10:03:06,428:INFO:           wurlitzer: Not installed
2024-07-13 10:03:06,428:INFO:PyCaret optional dependencies:
2024-07-13 10:03:06,443:INFO:                shap: Not installed
2024-07-13 10:03:06,443:INFO:           interpret: Not installed
2024-07-13 10:03:06,443:INFO:                umap: Not installed
2024-07-13 10:03:06,443:INFO:     ydata_profiling: Not installed
2024-07-13 10:03:06,443:INFO:  explainerdashboard: Not installed
2024-07-13 10:03:06,443:INFO:             autoviz: Not installed
2024-07-13 10:03:06,443:INFO:           fairlearn: Not installed
2024-07-13 10:03:06,443:INFO:          deepchecks: Not installed
2024-07-13 10:03:06,443:INFO:             xgboost: Not installed
2024-07-13 10:03:06,443:INFO:            catboost: Not installed
2024-07-13 10:03:06,443:INFO:              kmodes: Not installed
2024-07-13 10:03:06,443:INFO:             mlxtend: Not installed
2024-07-13 10:03:06,443:INFO:       statsforecast: Not installed
2024-07-13 10:03:06,443:INFO:        tune_sklearn: Not installed
2024-07-13 10:03:06,443:INFO:                 ray: Not installed
2024-07-13 10:03:06,444:INFO:            hyperopt: Not installed
2024-07-13 10:03:06,444:INFO:              optuna: Not installed
2024-07-13 10:03:06,444:INFO:               skopt: Not installed
2024-07-13 10:03:06,444:INFO:              mlflow: Not installed
2024-07-13 10:03:06,444:INFO:              gradio: Not installed
2024-07-13 10:03:06,444:INFO:             fastapi: Not installed
2024-07-13 10:03:06,444:INFO:             uvicorn: Not installed
2024-07-13 10:03:06,444:INFO:              m2cgen: Not installed
2024-07-13 10:03:06,444:INFO:           evidently: Not installed
2024-07-13 10:03:06,444:INFO:               fugue: Not installed
2024-07-13 10:03:06,444:INFO:           streamlit: Not installed
2024-07-13 10:03:06,444:INFO:             prophet: Not installed
2024-07-13 10:03:06,444:INFO:None
2024-07-13 10:03:06,444:INFO:Set up data.
2024-07-13 10:03:06,532:INFO:Set up folding strategy.
2024-07-13 10:03:06,532:INFO:Set up train/test split.
2024-07-13 10:03:06,810:INFO:Set up index.
2024-07-13 10:03:06,852:INFO:Assigning column types.
2024-07-13 10:03:06,944:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-13 10:03:06,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-13 10:03:06,996:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 10:03:07,037:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:07,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:07,082:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-13 10:03:07,083:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 10:03:07,112:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:07,112:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:07,112:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-13 10:03:07,158:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 10:03:07,187:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:07,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:07,234:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 10:03:07,262:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:07,262:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:07,263:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-13 10:03:07,344:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:07,345:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:07,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:07,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:07,423:INFO:Preparing preprocessing pipeline...
2024-07-13 10:03:07,444:INFO:Set up simple imputation.
2024-07-13 10:03:07,809:INFO:Set up encoding of ordinal features.
2024-07-13 10:03:07,843:INFO:Set up encoding of categorical features.
2024-07-13 10:03:07,844:INFO:Set up column transformation.
2024-07-13 10:03:07,844:INFO:Set up feature normalization.
2024-07-13 10:03:09,284:INFO:Finished creating preprocessing pipeline.
2024-07-13 10:03:09,304:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-07-13 10:03:09,304:INFO:Creating final display dataframe.
2024-07-13 10:03:10,661:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target              mau
2                   Target type           Binary
3           Original data shape     (600000, 13)
4        Transformed data shape     (600000, 30)
5   Transformed train set shape     (420000, 30)
6    Transformed test set shape     (180000, 30)
7              Numeric features                5
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Transformation             True
16        Transformation method         quantile
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           credit
25                          USI             0135
2024-07-13 10:03:10,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:10,747:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:10,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:10,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:10,821:INFO:setup() successfully completed in 4.46s...............
2024-07-13 10:03:10,836:INFO:gpu_param set to False
2024-07-13 10:03:10,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:10,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:10,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:10,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:03:11,018:INFO:Initializing create_model()
2024-07-13 10:03:11,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014468258690>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-13 10:03:11,019:INFO:Checking exceptions
2024-07-13 10:03:11,034:INFO:Importing libraries
2024-07-13 10:03:11,034:INFO:Copying training dataset
2024-07-13 10:03:11,332:INFO:Defining folds
2024-07-13 10:03:11,332:INFO:Declaring metric variables
2024-07-13 10:03:11,335:INFO:Importing untrained model
2024-07-13 10:03:11,339:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 10:03:11,347:INFO:Starting cross validation
2024-07-13 10:03:11,351:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 10:05:16,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 10:05:16,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 10:05:16,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 10:05:16,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 10:05:19,912:INFO:PyCaret ClassificationExperiment
2024-07-13 10:05:19,913:INFO:Logging name: credit
2024-07-13 10:05:19,913:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-13 10:05:19,913:INFO:version 3.3.2
2024-07-13 10:05:19,913:INFO:Initializing setup()
2024-07-13 10:05:19,913:INFO:self.USI: d06a
2024-07-13 10:05:19,913:INFO:self._variable_keys: {'seed', 'target_param', 'html_param', 'y', 'memory', 'y_train', 'X_test', 'n_jobs_param', 'X', '_ml_usecase', 'fold_generator', 'y_test', 'pipeline', 'X_train', 'exp_id', 'USI', 'log_plots_param', 'data', 'idx', 'is_multiclass', 'logging_param', 'fold_groups_param', 'fix_imbalance', 'exp_name_log', '_available_plots', 'gpu_n_jobs_param', 'gpu_param', 'fold_shuffle_param'}
2024-07-13 10:05:19,913:INFO:Checking environment
2024-07-13 10:05:19,913:INFO:python_version: 3.11.7
2024-07-13 10:05:19,913:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2024-07-13 10:05:19,914:INFO:machine: AMD64
2024-07-13 10:05:19,914:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-13 10:05:19,920:INFO:Memory: svmem(total=16849293312, available=8087932928, percent=52.0, used=8761360384, free=8087932928)
2024-07-13 10:05:19,920:INFO:Physical Core: 12
2024-07-13 10:05:19,920:INFO:Logical Core: 16
2024-07-13 10:05:19,920:INFO:Checking libraries
2024-07-13 10:05:19,920:INFO:System:
2024-07-13 10:05:19,921:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2024-07-13 10:05:19,921:INFO:executable: c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\python.exe
2024-07-13 10:05:19,921:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-13 10:05:19,921:INFO:PyCaret required dependencies:
2024-07-13 10:05:19,959:INFO:                 pip: 24.1.2
2024-07-13 10:05:19,960:INFO:          setuptools: 65.5.0
2024-07-13 10:05:19,960:INFO:             pycaret: 3.3.2
2024-07-13 10:05:19,960:INFO:             IPython: 8.26.0
2024-07-13 10:05:19,960:INFO:          ipywidgets: 8.1.3
2024-07-13 10:05:19,960:INFO:                tqdm: 4.66.4
2024-07-13 10:05:19,960:INFO:               numpy: 1.26.4
2024-07-13 10:05:19,960:INFO:              pandas: 2.1.4
2024-07-13 10:05:19,960:INFO:              jinja2: 3.1.4
2024-07-13 10:05:19,960:INFO:               scipy: 1.11.4
2024-07-13 10:05:19,960:INFO:              joblib: 1.3.2
2024-07-13 10:05:19,960:INFO:             sklearn: 1.4.2
2024-07-13 10:05:19,961:INFO:                pyod: 2.0.1
2024-07-13 10:05:19,961:INFO:            imblearn: 0.12.3
2024-07-13 10:05:19,961:INFO:   category_encoders: 2.6.3
2024-07-13 10:05:19,961:INFO:            lightgbm: 4.4.0
2024-07-13 10:05:19,961:INFO:               numba: 0.60.0
2024-07-13 10:05:19,961:INFO:            requests: 2.32.3
2024-07-13 10:05:19,961:INFO:          matplotlib: 3.7.5
2024-07-13 10:05:19,961:INFO:          scikitplot: 0.3.7
2024-07-13 10:05:19,961:INFO:         yellowbrick: 1.5
2024-07-13 10:05:19,961:INFO:              plotly: 5.22.0
2024-07-13 10:05:19,961:INFO:    plotly-resampler: Not installed
2024-07-13 10:05:19,961:INFO:             kaleido: 0.2.1
2024-07-13 10:05:19,962:INFO:           schemdraw: 0.15
2024-07-13 10:05:19,962:INFO:         statsmodels: 0.14.2
2024-07-13 10:05:19,962:INFO:              sktime: 0.26.0
2024-07-13 10:05:19,962:INFO:               tbats: 1.1.3
2024-07-13 10:05:19,962:INFO:            pmdarima: 2.0.4
2024-07-13 10:05:19,962:INFO:              psutil: 6.0.0
2024-07-13 10:05:19,962:INFO:          markupsafe: 2.1.5
2024-07-13 10:05:19,962:INFO:             pickle5: Not installed
2024-07-13 10:05:19,962:INFO:         cloudpickle: 3.0.0
2024-07-13 10:05:19,963:INFO:         deprecation: 2.1.0
2024-07-13 10:05:19,963:INFO:              xxhash: 3.4.1
2024-07-13 10:05:19,963:INFO:           wurlitzer: Not installed
2024-07-13 10:05:19,963:INFO:PyCaret optional dependencies:
2024-07-13 10:05:19,991:INFO:                shap: Not installed
2024-07-13 10:05:19,991:INFO:           interpret: Not installed
2024-07-13 10:05:19,991:INFO:                umap: Not installed
2024-07-13 10:05:19,991:INFO:     ydata_profiling: Not installed
2024-07-13 10:05:19,991:INFO:  explainerdashboard: Not installed
2024-07-13 10:05:19,991:INFO:             autoviz: Not installed
2024-07-13 10:05:19,992:INFO:           fairlearn: Not installed
2024-07-13 10:05:19,992:INFO:          deepchecks: Not installed
2024-07-13 10:05:19,992:INFO:             xgboost: Not installed
2024-07-13 10:05:19,992:INFO:            catboost: Not installed
2024-07-13 10:05:19,992:INFO:              kmodes: Not installed
2024-07-13 10:05:19,992:INFO:             mlxtend: Not installed
2024-07-13 10:05:19,992:INFO:       statsforecast: Not installed
2024-07-13 10:05:19,992:INFO:        tune_sklearn: Not installed
2024-07-13 10:05:19,992:INFO:                 ray: Not installed
2024-07-13 10:05:19,992:INFO:            hyperopt: Not installed
2024-07-13 10:05:19,992:INFO:              optuna: Not installed
2024-07-13 10:05:19,992:INFO:               skopt: Not installed
2024-07-13 10:05:19,992:INFO:              mlflow: Not installed
2024-07-13 10:05:19,992:INFO:              gradio: Not installed
2024-07-13 10:05:19,992:INFO:             fastapi: Not installed
2024-07-13 10:05:19,993:INFO:             uvicorn: Not installed
2024-07-13 10:05:19,993:INFO:              m2cgen: Not installed
2024-07-13 10:05:19,993:INFO:           evidently: Not installed
2024-07-13 10:05:19,993:INFO:               fugue: Not installed
2024-07-13 10:05:19,993:INFO:           streamlit: Not installed
2024-07-13 10:05:19,993:INFO:             prophet: Not installed
2024-07-13 10:05:19,993:INFO:None
2024-07-13 10:05:19,993:INFO:Set up data.
2024-07-13 10:05:20,097:INFO:Set up folding strategy.
2024-07-13 10:05:20,097:INFO:Set up train/test split.
2024-07-13 10:05:20,461:INFO:Set up index.
2024-07-13 10:05:20,510:INFO:Assigning column types.
2024-07-13 10:05:20,669:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-13 10:05:20,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-13 10:05:20,781:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 10:05:20,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:20,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:20,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-13 10:05:20,974:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 10:05:21,062:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:21,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:21,063:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-13 10:05:21,178:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 10:05:21,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:21,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:21,350:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 10:05:21,420:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:21,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:21,421:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-13 10:05:21,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:21,563:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:21,723:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:21,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:21,726:INFO:Preparing preprocessing pipeline...
2024-07-13 10:05:21,754:INFO:Set up simple imputation.
2024-07-13 10:05:22,184:INFO:Set up encoding of ordinal features.
2024-07-13 10:05:22,228:INFO:Set up encoding of categorical features.
2024-07-13 10:05:22,229:INFO:Set up column transformation.
2024-07-13 10:05:22,229:INFO:Set up feature normalization.
2024-07-13 10:05:23,819:INFO:Finished creating preprocessing pipeline.
2024-07-13 10:05:23,846:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-07-13 10:05:23,846:INFO:Creating final display dataframe.
2024-07-13 10:05:25,459:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target              mau
2                   Target type           Binary
3           Original data shape     (600000, 13)
4        Transformed data shape     (600000, 30)
5   Transformed train set shape     (420000, 30)
6    Transformed test set shape     (180000, 30)
7              Numeric features                5
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Transformation             True
16        Transformation method         quantile
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           credit
25                          USI             d06a
2024-07-13 10:05:25,626:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:25,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:25,758:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:25,758:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:25,760:INFO:setup() successfully completed in 5.88s...............
2024-07-13 10:05:25,777:INFO:gpu_param set to False
2024-07-13 10:05:25,909:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:25,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:26,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:26,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:05:26,072:INFO:Initializing create_model()
2024-07-13 10:05:26,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C4B442FDD0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-13 10:05:26,072:INFO:Checking exceptions
2024-07-13 10:05:26,093:INFO:Importing libraries
2024-07-13 10:05:26,093:INFO:Copying training dataset
2024-07-13 10:05:26,499:INFO:Defining folds
2024-07-13 10:05:26,499:INFO:Declaring metric variables
2024-07-13 10:05:26,504:INFO:Importing untrained model
2024-07-13 10:05:26,508:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 10:05:26,516:INFO:Starting cross validation
2024-07-13 10:05:26,518:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 10:05:53,613:INFO:Calculating mean and std
2024-07-13 10:05:53,616:INFO:Creating metrics dataframe
2024-07-13 10:05:53,623:INFO:Finalizing model
2024-07-13 10:06:02,950:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 10:06:02,950:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-13 10:06:03,023:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019189 seconds.
2024-07-13 10:06:03,023:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 10:06:03,023:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 10:06:03,024:INFO:[LightGBM] [Info] Total Bins 643
2024-07-13 10:06:03,026:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-13 10:06:03,028:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-13 10:06:03,029:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-13 10:06:03,598:INFO:Uploading results into container
2024-07-13 10:06:03,599:INFO:Uploading model into container now
2024-07-13 10:06:03,616:INFO:_master_model_container: 1
2024-07-13 10:06:03,616:INFO:_display_container: 2
2024-07-13 10:06:03,617:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 10:06:03,617:INFO:create_model() successfully completed......................................
2024-07-13 10:06:03,870:INFO:Initializing tune_model()
2024-07-13 10:06:03,870:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C4B442FDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=1, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-13 10:06:03,870:INFO:Checking exceptions
2024-07-13 10:06:04,048:INFO:Copying training dataset
2024-07-13 10:06:04,327:INFO:Checking base model
2024-07-13 10:06:04,328:INFO:Base model : Light Gradient Boosting Machine
2024-07-13 10:06:04,333:INFO:Declaring metric variables
2024-07-13 10:06:04,336:INFO:Defining Hyperparameters
2024-07-13 10:06:04,499:INFO:Tuning with n_jobs=-1
2024-07-13 10:06:04,499:INFO:Initializing RandomizedSearchCV
2024-07-13 10:06:30,606:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.7}
2024-07-13 10:06:30,608:INFO:Hyperparameter search completed
2024-07-13 10:06:30,608:INFO:SubProcess create_model() called ==================================
2024-07-13 10:06:30,609:INFO:Initializing create_model()
2024-07-13 10:06:30,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C4B442FDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C4C8680090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 3, 'num_leaves': 256, 'n_estimators': 30, 'min_split_gain': 0.2, 'min_child_samples': 1, 'learning_rate': 0.0005, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.7})
2024-07-13 10:06:30,609:INFO:Checking exceptions
2024-07-13 10:06:30,609:INFO:Importing libraries
2024-07-13 10:06:30,609:INFO:Copying training dataset
2024-07-13 10:06:31,060:INFO:Defining folds
2024-07-13 10:06:31,060:INFO:Declaring metric variables
2024-07-13 10:06:31,067:INFO:Importing untrained model
2024-07-13 10:06:31,067:INFO:Declaring custom model
2024-07-13 10:06:31,072:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 10:06:31,081:INFO:Starting cross validation
2024-07-13 10:06:31,084:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 10:08:23,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 10:08:23,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 10:08:23,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 10:08:23,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 10:08:26,469:INFO:PyCaret ClassificationExperiment
2024-07-13 10:08:26,469:INFO:Logging name: credit
2024-07-13 10:08:26,469:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-13 10:08:26,470:INFO:version 3.3.2
2024-07-13 10:08:26,470:INFO:Initializing setup()
2024-07-13 10:08:26,470:INFO:self.USI: d792
2024-07-13 10:08:26,470:INFO:self._variable_keys: {'idx', 'exp_id', 'y_test', 'memory', 'data', 'fold_groups_param', 'y', '_available_plots', 'gpu_n_jobs_param', 'target_param', 'is_multiclass', 'pipeline', 'fold_shuffle_param', 'html_param', 'exp_name_log', 'seed', 'X', 'n_jobs_param', 'y_train', 'X_train', 'fold_generator', 'gpu_param', 'log_plots_param', '_ml_usecase', 'USI', 'fix_imbalance', 'X_test', 'logging_param'}
2024-07-13 10:08:26,470:INFO:Checking environment
2024-07-13 10:08:26,470:INFO:python_version: 3.11.7
2024-07-13 10:08:26,470:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2024-07-13 10:08:26,470:INFO:machine: AMD64
2024-07-13 10:08:26,470:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-13 10:08:26,475:INFO:Memory: svmem(total=16849293312, available=7755292672, percent=54.0, used=9094000640, free=7755292672)
2024-07-13 10:08:26,476:INFO:Physical Core: 12
2024-07-13 10:08:26,476:INFO:Logical Core: 16
2024-07-13 10:08:26,476:INFO:Checking libraries
2024-07-13 10:08:26,476:INFO:System:
2024-07-13 10:08:26,476:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2024-07-13 10:08:26,476:INFO:executable: c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\python.exe
2024-07-13 10:08:26,476:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-13 10:08:26,476:INFO:PyCaret required dependencies:
2024-07-13 10:08:26,504:INFO:                 pip: 24.1.2
2024-07-13 10:08:26,504:INFO:          setuptools: 65.5.0
2024-07-13 10:08:26,504:INFO:             pycaret: 3.3.2
2024-07-13 10:08:26,504:INFO:             IPython: 8.26.0
2024-07-13 10:08:26,504:INFO:          ipywidgets: 8.1.3
2024-07-13 10:08:26,504:INFO:                tqdm: 4.66.4
2024-07-13 10:08:26,504:INFO:               numpy: 1.26.4
2024-07-13 10:08:26,504:INFO:              pandas: 2.1.4
2024-07-13 10:08:26,504:INFO:              jinja2: 3.1.4
2024-07-13 10:08:26,504:INFO:               scipy: 1.11.4
2024-07-13 10:08:26,504:INFO:              joblib: 1.3.2
2024-07-13 10:08:26,504:INFO:             sklearn: 1.4.2
2024-07-13 10:08:26,504:INFO:                pyod: 2.0.1
2024-07-13 10:08:26,504:INFO:            imblearn: 0.12.3
2024-07-13 10:08:26,504:INFO:   category_encoders: 2.6.3
2024-07-13 10:08:26,506:INFO:            lightgbm: 4.4.0
2024-07-13 10:08:26,506:INFO:               numba: 0.60.0
2024-07-13 10:08:26,506:INFO:            requests: 2.32.3
2024-07-13 10:08:26,506:INFO:          matplotlib: 3.7.5
2024-07-13 10:08:26,506:INFO:          scikitplot: 0.3.7
2024-07-13 10:08:26,506:INFO:         yellowbrick: 1.5
2024-07-13 10:08:26,506:INFO:              plotly: 5.22.0
2024-07-13 10:08:26,506:INFO:    plotly-resampler: Not installed
2024-07-13 10:08:26,506:INFO:             kaleido: 0.2.1
2024-07-13 10:08:26,506:INFO:           schemdraw: 0.15
2024-07-13 10:08:26,506:INFO:         statsmodels: 0.14.2
2024-07-13 10:08:26,506:INFO:              sktime: 0.26.0
2024-07-13 10:08:26,506:INFO:               tbats: 1.1.3
2024-07-13 10:08:26,506:INFO:            pmdarima: 2.0.4
2024-07-13 10:08:26,506:INFO:              psutil: 6.0.0
2024-07-13 10:08:26,506:INFO:          markupsafe: 2.1.5
2024-07-13 10:08:26,506:INFO:             pickle5: Not installed
2024-07-13 10:08:26,506:INFO:         cloudpickle: 3.0.0
2024-07-13 10:08:26,507:INFO:         deprecation: 2.1.0
2024-07-13 10:08:26,507:INFO:              xxhash: 3.4.1
2024-07-13 10:08:26,507:INFO:           wurlitzer: Not installed
2024-07-13 10:08:26,507:INFO:PyCaret optional dependencies:
2024-07-13 10:08:26,529:INFO:                shap: Not installed
2024-07-13 10:08:26,530:INFO:           interpret: Not installed
2024-07-13 10:08:26,530:INFO:                umap: Not installed
2024-07-13 10:08:26,530:INFO:     ydata_profiling: Not installed
2024-07-13 10:08:26,530:INFO:  explainerdashboard: Not installed
2024-07-13 10:08:26,530:INFO:             autoviz: Not installed
2024-07-13 10:08:26,530:INFO:           fairlearn: Not installed
2024-07-13 10:08:26,530:INFO:          deepchecks: Not installed
2024-07-13 10:08:26,530:INFO:             xgboost: Not installed
2024-07-13 10:08:26,531:INFO:            catboost: Not installed
2024-07-13 10:08:26,531:INFO:              kmodes: Not installed
2024-07-13 10:08:26,531:INFO:             mlxtend: Not installed
2024-07-13 10:08:26,531:INFO:       statsforecast: Not installed
2024-07-13 10:08:26,531:INFO:        tune_sklearn: Not installed
2024-07-13 10:08:26,531:INFO:                 ray: Not installed
2024-07-13 10:08:26,531:INFO:            hyperopt: Not installed
2024-07-13 10:08:26,531:INFO:              optuna: Not installed
2024-07-13 10:08:26,531:INFO:               skopt: Not installed
2024-07-13 10:08:26,531:INFO:              mlflow: Not installed
2024-07-13 10:08:26,531:INFO:              gradio: Not installed
2024-07-13 10:08:26,531:INFO:             fastapi: Not installed
2024-07-13 10:08:26,531:INFO:             uvicorn: Not installed
2024-07-13 10:08:26,531:INFO:              m2cgen: Not installed
2024-07-13 10:08:26,531:INFO:           evidently: Not installed
2024-07-13 10:08:26,531:INFO:               fugue: Not installed
2024-07-13 10:08:26,531:INFO:           streamlit: Not installed
2024-07-13 10:08:26,532:INFO:             prophet: Not installed
2024-07-13 10:08:26,532:INFO:None
2024-07-13 10:08:26,532:INFO:Set up data.
2024-07-13 10:08:26,618:INFO:Set up folding strategy.
2024-07-13 10:08:26,619:INFO:Set up train/test split.
2024-07-13 10:08:26,896:INFO:Set up index.
2024-07-13 10:08:26,933:INFO:Assigning column types.
2024-07-13 10:08:27,023:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-13 10:08:27,066:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-13 10:08:27,074:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 10:08:27,111:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:27,112:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:27,154:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-13 10:08:27,155:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 10:08:27,182:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:27,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:27,183:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-13 10:08:27,227:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 10:08:27,254:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:27,254:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:27,299:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 10:08:27,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:27,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:27,326:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-13 10:08:27,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:27,400:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:27,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:27,473:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:27,476:INFO:Preparing preprocessing pipeline...
2024-07-13 10:08:27,496:INFO:Set up simple imputation.
2024-07-13 10:08:27,862:INFO:Set up encoding of ordinal features.
2024-07-13 10:08:27,892:INFO:Set up encoding of categorical features.
2024-07-13 10:08:27,893:INFO:Set up column transformation.
2024-07-13 10:08:27,893:INFO:Set up feature normalization.
2024-07-13 10:08:29,313:INFO:Finished creating preprocessing pipeline.
2024-07-13 10:08:29,335:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-07-13 10:08:29,335:INFO:Creating final display dataframe.
2024-07-13 10:08:30,921:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target              mau
2                   Target type           Binary
3           Original data shape     (600000, 13)
4        Transformed data shape     (600000, 30)
5   Transformed train set shape     (420000, 30)
6    Transformed test set shape     (180000, 30)
7              Numeric features                5
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Transformation             True
16        Transformation method         quantile
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           credit
25                          USI             d792
2024-07-13 10:08:31,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:31,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:31,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:31,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:31,105:INFO:setup() successfully completed in 4.65s...............
2024-07-13 10:08:31,115:INFO:gpu_param set to False
2024-07-13 10:08:31,196:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:31,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:31,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:31,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 10:08:31,291:INFO:Initializing create_model()
2024-07-13 10:08:31,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000267A0378510>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-13 10:08:31,292:INFO:Checking exceptions
2024-07-13 10:08:31,308:INFO:Importing libraries
2024-07-13 10:08:31,309:INFO:Copying training dataset
2024-07-13 10:08:31,661:INFO:Defining folds
2024-07-13 10:08:31,661:INFO:Declaring metric variables
2024-07-13 10:08:31,664:INFO:Importing untrained model
2024-07-13 10:08:31,669:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 10:08:31,676:INFO:Starting cross validation
2024-07-13 10:08:31,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 10:08:55,044:INFO:Calculating mean and std
2024-07-13 10:08:55,048:INFO:Creating metrics dataframe
2024-07-13 10:08:55,054:INFO:Finalizing model
2024-07-13 10:09:03,029:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 10:09:03,030:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-13 10:09:03,097:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023597 seconds.
2024-07-13 10:09:03,097:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 10:09:03,097:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 10:09:03,100:INFO:[LightGBM] [Info] Total Bins 643
2024-07-13 10:09:03,100:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-13 10:09:03,103:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-13 10:09:03,103:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-13 10:09:03,663:INFO:Uploading results into container
2024-07-13 10:09:03,664:INFO:Uploading model into container now
2024-07-13 10:09:03,677:INFO:_master_model_container: 1
2024-07-13 10:09:03,678:INFO:_display_container: 2
2024-07-13 10:09:03,678:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 10:09:03,679:INFO:create_model() successfully completed......................................
2024-07-13 10:09:03,919:INFO:Initializing tune_model()
2024-07-13 10:09:03,919:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000267A0378510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=1, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-13 10:09:03,919:INFO:Checking exceptions
2024-07-13 10:09:04,065:INFO:Copying training dataset
2024-07-13 10:09:04,252:INFO:Checking base model
2024-07-13 10:09:04,252:INFO:Base model : Light Gradient Boosting Machine
2024-07-13 10:09:04,256:INFO:Declaring metric variables
2024-07-13 10:09:04,259:INFO:Defining Hyperparameters
2024-07-13 10:09:04,420:INFO:Tuning with n_jobs=-1
2024-07-13 10:09:04,420:INFO:Initializing RandomizedSearchCV
2024-07-13 10:09:26,670:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.7}
2024-07-13 10:09:26,672:INFO:Hyperparameter search completed
2024-07-13 10:09:26,672:INFO:SubProcess create_model() called ==================================
2024-07-13 10:09:26,673:INFO:Initializing create_model()
2024-07-13 10:09:26,673:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000267A0378510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000267BFA9EB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 3, 'num_leaves': 256, 'n_estimators': 30, 'min_split_gain': 0.2, 'min_child_samples': 1, 'learning_rate': 0.0005, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.7})
2024-07-13 10:09:26,673:INFO:Checking exceptions
2024-07-13 10:09:26,673:INFO:Importing libraries
2024-07-13 10:09:26,673:INFO:Copying training dataset
2024-07-13 10:09:26,995:INFO:Defining folds
2024-07-13 10:09:26,995:INFO:Declaring metric variables
2024-07-13 10:09:27,000:INFO:Importing untrained model
2024-07-13 10:09:27,000:INFO:Declaring custom model
2024-07-13 10:09:27,004:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 10:09:27,011:INFO:Starting cross validation
2024-07-13 10:09:27,014:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 10:09:47,232:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 10:09:47,466:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 10:09:47,633:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 10:09:47,831:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 10:09:47,872:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 10:09:47,964:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 10:09:48,032:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 10:09:48,162:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 10:09:48,321:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 10:09:48,537:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 10:09:48,680:INFO:Calculating mean and std
2024-07-13 10:09:48,682:INFO:Creating metrics dataframe
2024-07-13 10:09:48,688:INFO:Finalizing model
2024-07-13 10:09:56,581:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-13 10:09:56,581:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-13 10:09:56,581:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-13 10:09:56,848:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 10:09:56,849:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-13 10:09:56,849:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-13 10:09:56,849:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-13 10:09:56,849:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-13 10:09:56,918:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023480 seconds.
2024-07-13 10:09:56,919:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 10:09:56,919:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 10:09:56,919:INFO:[LightGBM] [Info] Total Bins 647
2024-07-13 10:09:56,919:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 29
2024-07-13 10:09:56,926:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-13 10:09:56,926:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-13 10:09:56,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 10:09:57,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 10:09:57,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 10:09:57,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 10:09:57,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 10:09:57,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 10:09:57,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 10:09:57,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 10:09:57,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 10:09:57,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 10:09:57,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 10:09:57,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 10:09:57,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 10:09:57,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 10:09:57,627:INFO:Uploading results into container
2024-07-13 10:09:57,628:INFO:Uploading model into container now
2024-07-13 10:09:57,628:INFO:_master_model_container: 2
2024-07-13 10:09:57,629:INFO:_display_container: 3
2024-07-13 10:09:57,629:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 10:09:57,630:INFO:create_model() successfully completed......................................
2024-07-13 10:09:57,810:INFO:SubProcess create_model() end ==================================
2024-07-13 10:09:57,810:INFO:choose_better activated
2024-07-13 10:09:57,814:INFO:SubProcess create_model() called ==================================
2024-07-13 10:09:57,814:INFO:Initializing create_model()
2024-07-13 10:09:57,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000267A0378510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-13 10:09:57,814:INFO:Checking exceptions
2024-07-13 10:09:57,817:INFO:Importing libraries
2024-07-13 10:09:57,817:INFO:Copying training dataset
2024-07-13 10:09:58,135:INFO:Defining folds
2024-07-13 10:09:58,135:INFO:Declaring metric variables
2024-07-13 10:09:58,135:INFO:Importing untrained model
2024-07-13 10:09:58,135:INFO:Declaring custom model
2024-07-13 10:09:58,136:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 10:09:58,136:INFO:Starting cross validation
2024-07-13 10:09:58,137:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 10:10:17,648:INFO:Calculating mean and std
2024-07-13 10:10:17,650:INFO:Creating metrics dataframe
2024-07-13 10:10:17,652:INFO:Finalizing model
2024-07-13 10:10:25,782:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 10:10:25,783:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-13 10:10:25,848:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025953 seconds.
2024-07-13 10:10:25,849:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 10:10:25,849:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 10:10:25,849:INFO:[LightGBM] [Info] Total Bins 643
2024-07-13 10:10:25,849:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-13 10:10:25,852:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-13 10:10:25,852:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-13 10:10:26,427:INFO:Uploading results into container
2024-07-13 10:10:26,428:INFO:Uploading model into container now
2024-07-13 10:10:26,429:INFO:_master_model_container: 3
2024-07-13 10:10:26,429:INFO:_display_container: 4
2024-07-13 10:10:26,429:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 10:10:26,429:INFO:create_model() successfully completed......................................
2024-07-13 10:10:26,590:INFO:SubProcess create_model() end ==================================
2024-07-13 10:10:26,591:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0113
2024-07-13 10:10:26,591:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0
2024-07-13 10:10:26,592:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-07-13 10:10:26,592:INFO:choose_better completed
2024-07-13 10:10:26,592:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-13 10:10:26,603:INFO:_master_model_container: 3
2024-07-13 10:10:26,604:INFO:_display_container: 3
2024-07-13 10:10:26,604:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 10:10:26,605:INFO:tune_model() successfully completed......................................
2024-07-13 10:10:26,778:INFO:Initializing plot_model()
2024-07-13 10:10:26,778:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000267A0378510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-13 10:10:26,779:INFO:Checking exceptions
2024-07-13 10:10:26,894:INFO:Preloading libraries
2024-07-13 10:10:26,902:INFO:Copying training dataset
2024-07-13 10:10:26,902:INFO:Plot type: auc
2024-07-13 10:10:27,999:INFO:Fitting Model
2024-07-13 10:10:28,010:INFO:Scoring test/hold-out set
2024-07-13 10:10:28,700:INFO:Visual Rendered Successfully
2024-07-13 10:10:28,874:INFO:plot_model() successfully completed......................................
2024-07-13 10:10:28,893:INFO:Initializing plot_model()
2024-07-13 10:10:28,893:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000267A0378510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-13 10:10:28,893:INFO:Checking exceptions
2024-07-13 10:10:29,042:INFO:Preloading libraries
2024-07-13 10:10:29,050:INFO:Copying training dataset
2024-07-13 10:10:29,050:INFO:Plot type: pr
2024-07-13 10:10:30,277:INFO:Fitting Model
2024-07-13 10:10:30,296:INFO:Scoring test/hold-out set
2024-07-13 10:10:30,793:INFO:Visual Rendered Successfully
2024-07-13 10:10:30,971:INFO:plot_model() successfully completed......................................
2024-07-13 10:10:30,986:INFO:Initializing plot_model()
2024-07-13 10:10:30,988:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000267A0378510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-13 10:10:30,988:INFO:Checking exceptions
2024-07-13 10:10:31,089:INFO:Preloading libraries
2024-07-13 10:10:31,096:INFO:Copying training dataset
2024-07-13 10:10:31,096:INFO:Plot type: feature
2024-07-13 10:10:31,097:WARNING:No coef_ found. Trying feature_importances_
2024-07-13 10:10:31,612:INFO:Visual Rendered Successfully
2024-07-13 10:10:31,764:INFO:plot_model() successfully completed......................................
2024-07-13 10:10:31,777:INFO:Initializing plot_model()
2024-07-13 10:10:31,778:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000267A0378510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-13 10:10:31,778:INFO:Checking exceptions
2024-07-13 10:10:31,884:INFO:Preloading libraries
2024-07-13 10:10:31,892:INFO:Copying training dataset
2024-07-13 10:10:31,892:INFO:Plot type: confusion_matrix
2024-07-13 10:10:32,930:INFO:Fitting Model
2024-07-13 10:10:32,937:INFO:Scoring test/hold-out set
2024-07-13 10:10:33,337:INFO:Visual Rendered Successfully
2024-07-13 10:10:33,508:INFO:plot_model() successfully completed......................................
2024-07-13 10:10:33,540:INFO:Initializing predict_model()
2024-07-13 10:10:33,540:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000267A0378510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000267CC5F53A0>)
2024-07-13 10:10:33,540:INFO:Checking exceptions
2024-07-13 10:10:33,540:INFO:Preloading libraries
2024-07-13 10:10:35,037:INFO:Initializing finalize_model()
2024-07-13 10:10:35,038:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000267A0378510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-13 10:10:35,039:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 10:10:35,120:INFO:Initializing create_model()
2024-07-13 10:10:35,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000267A0378510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-13 10:10:35,120:INFO:Checking exceptions
2024-07-13 10:10:35,123:INFO:Importing libraries
2024-07-13 10:10:35,123:INFO:Copying training dataset
2024-07-13 10:10:35,134:INFO:Defining folds
2024-07-13 10:10:35,134:INFO:Declaring metric variables
2024-07-13 10:10:35,135:INFO:Importing untrained model
2024-07-13 10:10:35,135:INFO:Declaring custom model
2024-07-13 10:10:35,135:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 10:10:35,138:INFO:Cross validation set to False
2024-07-13 10:10:35,138:INFO:Fitting Model
2024-07-13 10:10:46,922:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 10:10:46,923:INFO:[LightGBM] [Info] Number of positive: 36643, number of negative: 563357
2024-07-13 10:10:47,010:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032698 seconds.
2024-07-13 10:10:47,010:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 10:10:47,010:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 10:10:47,011:INFO:[LightGBM] [Info] Total Bins 642
2024-07-13 10:10:47,011:INFO:[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 27
2024-07-13 10:10:47,015:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061072 -> initscore=-2.732691
2024-07-13 10:10:47,015:INFO:[LightGBM] [Info] Start training from score -2.732691
2024-07-13 10:10:47,778:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-13 10:10:47,778:INFO:create_model() successfully completed......................................
2024-07-13 10:10:47,940:INFO:_master_model_container: 3
2024-07-13 10:10:47,940:INFO:_display_container: 4
2024-07-13 10:10:47,959:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-13 10:10:47,959:INFO:finalize_model() successfully completed......................................
2024-07-13 10:10:48,187:INFO:Initializing predict_model()
2024-07-13 10:10:48,187:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000267A0378510>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000267A8F9EA20>)
2024-07-13 10:10:48,187:INFO:Checking exceptions
2024-07-13 10:10:48,187:INFO:Preloading libraries
2024-07-13 10:10:48,190:INFO:Set up data.
2024-07-13 10:10:48,225:INFO:Set up index.
2024-07-13 10:10:50,747:INFO:Initializing save_model()
2024-07-13 10:10:50,748:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=Final Light GBM Model Jul2024, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-13 10:10:50,748:INFO:Adding model into prep_pipe
2024-07-13 10:10:50,748:WARNING:Only Model saved as it was a pipeline.
2024-07-13 10:10:50,768:INFO:Final Light GBM Model Jul2024.pkl saved in current working directory
2024-07-13 10:10:50,789:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-13 10:10:50,790:INFO:save_model() successfully completed......................................
2024-07-13 12:58:41,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 12:58:41,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 12:58:41,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 12:58:41,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-13 12:58:50,471:INFO:PyCaret ClassificationExperiment
2024-07-13 12:58:50,471:INFO:Logging name: credit
2024-07-13 12:58:50,471:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-13 12:58:50,471:INFO:version 3.3.2
2024-07-13 12:58:50,471:INFO:Initializing setup()
2024-07-13 12:58:50,471:INFO:self.USI: d2d9
2024-07-13 12:58:50,471:INFO:self._variable_keys: {'fix_imbalance', 'y_train', 'html_param', 'fold_generator', 'is_multiclass', 'gpu_n_jobs_param', 'y', 'idx', 'target_param', 'gpu_param', 'memory', 'logging_param', 'seed', 'pipeline', 'y_test', 'data', 'X_test', 'X', 'n_jobs_param', 'X_train', '_ml_usecase', 'fold_groups_param', 'log_plots_param', 'USI', 'fold_shuffle_param', 'exp_id', '_available_plots', 'exp_name_log'}
2024-07-13 12:58:50,471:INFO:Checking environment
2024-07-13 12:58:50,471:INFO:python_version: 3.11.7
2024-07-13 12:58:50,471:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2024-07-13 12:58:50,471:INFO:machine: AMD64
2024-07-13 12:58:50,471:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-13 12:58:50,476:INFO:Memory: svmem(total=16849293312, available=6454599680, percent=61.7, used=10394693632, free=6454599680)
2024-07-13 12:58:50,476:INFO:Physical Core: 12
2024-07-13 12:58:50,476:INFO:Logical Core: 16
2024-07-13 12:58:50,476:INFO:Checking libraries
2024-07-13 12:58:50,477:INFO:System:
2024-07-13 12:58:50,477:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2024-07-13 12:58:50,477:INFO:executable: c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\python.exe
2024-07-13 12:58:50,477:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-13 12:58:50,477:INFO:PyCaret required dependencies:
2024-07-13 12:58:50,974:INFO:                 pip: 24.1.2
2024-07-13 12:58:50,974:INFO:          setuptools: 65.5.0
2024-07-13 12:58:50,974:INFO:             pycaret: 3.3.2
2024-07-13 12:58:50,974:INFO:             IPython: 8.26.0
2024-07-13 12:58:50,974:INFO:          ipywidgets: 8.1.3
2024-07-13 12:58:50,974:INFO:                tqdm: 4.66.4
2024-07-13 12:58:50,974:INFO:               numpy: 1.26.4
2024-07-13 12:58:50,974:INFO:              pandas: 2.1.4
2024-07-13 12:58:50,974:INFO:              jinja2: 3.1.4
2024-07-13 12:58:50,974:INFO:               scipy: 1.11.4
2024-07-13 12:58:50,974:INFO:              joblib: 1.3.2
2024-07-13 12:58:50,974:INFO:             sklearn: 1.4.2
2024-07-13 12:58:50,974:INFO:                pyod: 2.0.1
2024-07-13 12:58:50,974:INFO:            imblearn: 0.12.3
2024-07-13 12:58:50,975:INFO:   category_encoders: 2.6.3
2024-07-13 12:58:50,975:INFO:            lightgbm: 4.4.0
2024-07-13 12:58:50,975:INFO:               numba: 0.60.0
2024-07-13 12:58:50,975:INFO:            requests: 2.32.3
2024-07-13 12:58:50,975:INFO:          matplotlib: 3.7.5
2024-07-13 12:58:50,975:INFO:          scikitplot: 0.3.7
2024-07-13 12:58:50,975:INFO:         yellowbrick: 1.5
2024-07-13 12:58:50,975:INFO:              plotly: 5.22.0
2024-07-13 12:58:50,975:INFO:    plotly-resampler: Not installed
2024-07-13 12:58:50,975:INFO:             kaleido: 0.2.1
2024-07-13 12:58:50,976:INFO:           schemdraw: 0.15
2024-07-13 12:58:50,976:INFO:         statsmodels: 0.14.2
2024-07-13 12:58:50,976:INFO:              sktime: 0.26.0
2024-07-13 12:58:50,976:INFO:               tbats: 1.1.3
2024-07-13 12:58:50,976:INFO:            pmdarima: 2.0.4
2024-07-13 12:58:50,976:INFO:              psutil: 6.0.0
2024-07-13 12:58:50,976:INFO:          markupsafe: 2.1.5
2024-07-13 12:58:50,976:INFO:             pickle5: Not installed
2024-07-13 12:58:50,976:INFO:         cloudpickle: 3.0.0
2024-07-13 12:58:50,976:INFO:         deprecation: 2.1.0
2024-07-13 12:58:50,976:INFO:              xxhash: 3.4.1
2024-07-13 12:58:50,976:INFO:           wurlitzer: Not installed
2024-07-13 12:58:50,976:INFO:PyCaret optional dependencies:
2024-07-13 12:58:50,990:INFO:                shap: Not installed
2024-07-13 12:58:50,990:INFO:           interpret: Not installed
2024-07-13 12:58:50,990:INFO:                umap: Not installed
2024-07-13 12:58:50,990:INFO:     ydata_profiling: Not installed
2024-07-13 12:58:50,990:INFO:  explainerdashboard: Not installed
2024-07-13 12:58:50,990:INFO:             autoviz: Not installed
2024-07-13 12:58:50,990:INFO:           fairlearn: Not installed
2024-07-13 12:58:50,990:INFO:          deepchecks: Not installed
2024-07-13 12:58:50,990:INFO:             xgboost: Not installed
2024-07-13 12:58:50,991:INFO:            catboost: Not installed
2024-07-13 12:58:50,991:INFO:              kmodes: Not installed
2024-07-13 12:58:50,991:INFO:             mlxtend: Not installed
2024-07-13 12:58:50,991:INFO:       statsforecast: Not installed
2024-07-13 12:58:50,991:INFO:        tune_sklearn: Not installed
2024-07-13 12:58:50,991:INFO:                 ray: Not installed
2024-07-13 12:58:50,991:INFO:            hyperopt: Not installed
2024-07-13 12:58:50,991:INFO:              optuna: Not installed
2024-07-13 12:58:50,991:INFO:               skopt: Not installed
2024-07-13 12:58:50,991:INFO:              mlflow: Not installed
2024-07-13 12:58:50,991:INFO:              gradio: Not installed
2024-07-13 12:58:50,991:INFO:             fastapi: Not installed
2024-07-13 12:58:50,991:INFO:             uvicorn: Not installed
2024-07-13 12:58:50,991:INFO:              m2cgen: Not installed
2024-07-13 12:58:50,991:INFO:           evidently: Not installed
2024-07-13 12:58:50,991:INFO:               fugue: Not installed
2024-07-13 12:58:50,991:INFO:           streamlit: Not installed
2024-07-13 12:58:50,991:INFO:             prophet: Not installed
2024-07-13 12:58:50,991:INFO:None
2024-07-13 12:58:50,991:INFO:Set up data.
2024-07-13 12:58:51,078:INFO:Set up folding strategy.
2024-07-13 12:58:51,078:INFO:Set up train/test split.
2024-07-13 12:58:51,361:INFO:Set up index.
2024-07-13 12:58:51,400:INFO:Assigning column types.
2024-07-13 12:58:51,507:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-13 12:58:51,562:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-13 12:58:51,568:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 12:58:51,609:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:51,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:51,654:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-13 12:58:51,655:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 12:58:51,684:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:51,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:51,685:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-13 12:58:51,729:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 12:58:51,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:51,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:51,805:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-13 12:58:51,834:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:51,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:51,835:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-13 12:58:51,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:51,911:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:51,985:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:51,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:51,991:INFO:Preparing preprocessing pipeline...
2024-07-13 12:58:52,010:INFO:Set up simple imputation.
2024-07-13 12:58:52,375:INFO:Set up encoding of ordinal features.
2024-07-13 12:58:52,408:INFO:Set up encoding of categorical features.
2024-07-13 12:58:52,409:INFO:Set up column transformation.
2024-07-13 12:58:52,409:INFO:Set up feature normalization.
2024-07-13 12:58:53,839:INFO:Finished creating preprocessing pipeline.
2024-07-13 12:58:53,857:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-07-13 12:58:53,857:INFO:Creating final display dataframe.
2024-07-13 12:58:55,221:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target              mau
2                   Target type           Binary
3           Original data shape     (600000, 13)
4        Transformed data shape     (600000, 30)
5   Transformed train set shape     (420000, 30)
6    Transformed test set shape     (180000, 30)
7              Numeric features                5
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Transformation             True
16        Transformation method         quantile
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           credit
25                          USI             d2d9
2024-07-13 12:58:55,304:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:55,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:55,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:55,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:55,379:INFO:setup() successfully completed in 4.94s...............
2024-07-13 12:58:55,394:INFO:gpu_param set to False
2024-07-13 12:58:55,474:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:55,474:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:55,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:55,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-13 12:58:55,568:INFO:Initializing create_model()
2024-07-13 12:58:55,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018077C9DED0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-13 12:58:55,568:INFO:Checking exceptions
2024-07-13 12:58:55,587:INFO:Importing libraries
2024-07-13 12:58:55,587:INFO:Copying training dataset
2024-07-13 12:58:55,909:INFO:Defining folds
2024-07-13 12:58:55,909:INFO:Declaring metric variables
2024-07-13 12:58:55,913:INFO:Importing untrained model
2024-07-13 12:58:55,917:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 12:58:55,924:INFO:Starting cross validation
2024-07-13 12:58:55,926:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 12:59:22,453:INFO:Calculating mean and std
2024-07-13 12:59:22,457:INFO:Creating metrics dataframe
2024-07-13 12:59:22,466:INFO:Finalizing model
2024-07-13 12:59:30,539:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 12:59:30,540:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-13 12:59:30,610:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021879 seconds.
2024-07-13 12:59:30,610:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 12:59:30,610:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 12:59:30,610:INFO:[LightGBM] [Info] Total Bins 643
2024-07-13 12:59:30,610:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-13 12:59:30,613:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-13 12:59:30,614:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-13 12:59:31,209:INFO:Uploading results into container
2024-07-13 12:59:31,210:INFO:Uploading model into container now
2024-07-13 12:59:31,226:INFO:_master_model_container: 1
2024-07-13 12:59:31,226:INFO:_display_container: 2
2024-07-13 12:59:31,227:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 12:59:31,227:INFO:create_model() successfully completed......................................
2024-07-13 12:59:31,513:INFO:Initializing tune_model()
2024-07-13 12:59:31,514:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018077C9DED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=1, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-13 12:59:31,514:INFO:Checking exceptions
2024-07-13 12:59:31,669:INFO:Copying training dataset
2024-07-13 12:59:31,862:INFO:Checking base model
2024-07-13 12:59:31,862:INFO:Base model : Light Gradient Boosting Machine
2024-07-13 12:59:31,867:INFO:Declaring metric variables
2024-07-13 12:59:31,872:INFO:Defining Hyperparameters
2024-07-13 12:59:32,034:INFO:Tuning with n_jobs=-1
2024-07-13 12:59:32,034:INFO:Initializing RandomizedSearchCV
2024-07-13 12:59:54,638:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.7}
2024-07-13 12:59:54,639:INFO:Hyperparameter search completed
2024-07-13 12:59:54,639:INFO:SubProcess create_model() called ==================================
2024-07-13 12:59:54,640:INFO:Initializing create_model()
2024-07-13 12:59:54,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018077C9DED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180093C1350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 3, 'num_leaves': 256, 'n_estimators': 30, 'min_split_gain': 0.2, 'min_child_samples': 1, 'learning_rate': 0.0005, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.7})
2024-07-13 12:59:54,640:INFO:Checking exceptions
2024-07-13 12:59:54,640:INFO:Importing libraries
2024-07-13 12:59:54,640:INFO:Copying training dataset
2024-07-13 12:59:54,952:INFO:Defining folds
2024-07-13 12:59:54,952:INFO:Declaring metric variables
2024-07-13 12:59:54,959:INFO:Importing untrained model
2024-07-13 12:59:54,959:INFO:Declaring custom model
2024-07-13 12:59:54,965:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 12:59:54,973:INFO:Starting cross validation
2024-07-13 12:59:54,977:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 13:00:14,484:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 13:00:14,904:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 13:00:15,327:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 13:00:15,395:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 13:00:15,502:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 13:00:15,547:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 13:00:15,594:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 13:00:15,627:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 13:00:15,741:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 13:00:15,870:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-13 13:00:16,018:INFO:Calculating mean and std
2024-07-13 13:00:16,020:INFO:Creating metrics dataframe
2024-07-13 13:00:16,026:INFO:Finalizing model
2024-07-13 13:00:23,948:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-13 13:00:23,949:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-13 13:00:23,949:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-13 13:00:24,225:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 13:00:24,225:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-13 13:00:24,225:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-13 13:00:24,225:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-13 13:00:24,227:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-13 13:00:24,302:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018932 seconds.
2024-07-13 13:00:24,302:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 13:00:24,302:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 13:00:24,302:INFO:[LightGBM] [Info] Total Bins 647
2024-07-13 13:00:24,303:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 29
2024-07-13 13:00:24,309:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-13 13:00:24,309:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-13 13:00:24,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 13:00:24,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 13:00:24,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 13:00:24,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 13:00:24,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 13:00:24,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 13:00:24,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 13:00:24,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 13:00:24,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 13:00:24,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 13:00:24,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 13:00:24,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 13:00:24,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 13:00:25,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-13 13:00:25,043:INFO:Uploading results into container
2024-07-13 13:00:25,044:INFO:Uploading model into container now
2024-07-13 13:00:25,045:INFO:_master_model_container: 2
2024-07-13 13:00:25,045:INFO:_display_container: 3
2024-07-13 13:00:25,046:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 13:00:25,046:INFO:create_model() successfully completed......................................
2024-07-13 13:00:25,227:INFO:SubProcess create_model() end ==================================
2024-07-13 13:00:25,228:INFO:choose_better activated
2024-07-13 13:00:25,232:INFO:SubProcess create_model() called ==================================
2024-07-13 13:00:25,233:INFO:Initializing create_model()
2024-07-13 13:00:25,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018077C9DED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-13 13:00:25,233:INFO:Checking exceptions
2024-07-13 13:00:25,235:INFO:Importing libraries
2024-07-13 13:00:25,235:INFO:Copying training dataset
2024-07-13 13:00:25,534:INFO:Defining folds
2024-07-13 13:00:25,534:INFO:Declaring metric variables
2024-07-13 13:00:25,534:INFO:Importing untrained model
2024-07-13 13:00:25,534:INFO:Declaring custom model
2024-07-13 13:00:25,535:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 13:00:25,535:INFO:Starting cross validation
2024-07-13 13:00:25,538:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-13 13:00:45,247:INFO:Calculating mean and std
2024-07-13 13:00:45,248:INFO:Creating metrics dataframe
2024-07-13 13:00:45,250:INFO:Finalizing model
2024-07-13 13:00:53,107:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 13:00:53,108:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-13 13:00:53,177:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020825 seconds.
2024-07-13 13:00:53,177:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 13:00:53,177:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 13:00:53,177:INFO:[LightGBM] [Info] Total Bins 643
2024-07-13 13:00:53,179:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-13 13:00:53,181:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-13 13:00:53,181:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-13 13:00:53,720:INFO:Uploading results into container
2024-07-13 13:00:53,720:INFO:Uploading model into container now
2024-07-13 13:00:53,721:INFO:_master_model_container: 3
2024-07-13 13:00:53,721:INFO:_display_container: 4
2024-07-13 13:00:53,721:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 13:00:53,721:INFO:create_model() successfully completed......................................
2024-07-13 13:00:53,898:INFO:SubProcess create_model() end ==================================
2024-07-13 13:00:53,898:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0113
2024-07-13 13:00:53,899:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0
2024-07-13 13:00:53,899:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-07-13 13:00:53,900:INFO:choose_better completed
2024-07-13 13:00:53,900:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-13 13:00:53,910:INFO:_master_model_container: 3
2024-07-13 13:00:53,910:INFO:_display_container: 3
2024-07-13 13:00:53,910:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 13:00:53,911:INFO:tune_model() successfully completed......................................
2024-07-13 13:00:54,087:INFO:Initializing plot_model()
2024-07-13 13:00:54,087:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018077C9DED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-13 13:00:54,087:INFO:Checking exceptions
2024-07-13 13:00:54,186:INFO:Preloading libraries
2024-07-13 13:00:54,194:INFO:Copying training dataset
2024-07-13 13:00:54,194:INFO:Plot type: auc
2024-07-13 13:00:55,232:INFO:Fitting Model
2024-07-13 13:00:55,244:INFO:Scoring test/hold-out set
2024-07-13 13:00:55,901:INFO:Visual Rendered Successfully
2024-07-13 13:00:56,068:INFO:plot_model() successfully completed......................................
2024-07-13 13:00:56,081:INFO:Initializing plot_model()
2024-07-13 13:00:56,081:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018077C9DED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-13 13:00:56,081:INFO:Checking exceptions
2024-07-13 13:00:56,180:INFO:Preloading libraries
2024-07-13 13:00:56,186:INFO:Copying training dataset
2024-07-13 13:00:56,187:INFO:Plot type: pr
2024-07-13 13:00:57,170:INFO:Fitting Model
2024-07-13 13:00:57,186:INFO:Scoring test/hold-out set
2024-07-13 13:00:57,664:INFO:Visual Rendered Successfully
2024-07-13 13:00:57,837:INFO:plot_model() successfully completed......................................
2024-07-13 13:00:57,855:INFO:Initializing plot_model()
2024-07-13 13:00:57,855:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018077C9DED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-13 13:00:57,855:INFO:Checking exceptions
2024-07-13 13:00:57,948:INFO:Preloading libraries
2024-07-13 13:00:57,956:INFO:Copying training dataset
2024-07-13 13:00:57,957:INFO:Plot type: feature
2024-07-13 13:00:57,957:WARNING:No coef_ found. Trying feature_importances_
2024-07-13 13:00:58,448:INFO:Visual Rendered Successfully
2024-07-13 13:00:58,608:INFO:plot_model() successfully completed......................................
2024-07-13 13:00:58,622:INFO:Initializing plot_model()
2024-07-13 13:00:58,623:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018077C9DED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-13 13:00:58,623:INFO:Checking exceptions
2024-07-13 13:00:58,734:INFO:Preloading libraries
2024-07-13 13:00:58,742:INFO:Copying training dataset
2024-07-13 13:00:58,742:INFO:Plot type: confusion_matrix
2024-07-13 13:00:59,734:INFO:Fitting Model
2024-07-13 13:00:59,739:INFO:Scoring test/hold-out set
2024-07-13 13:01:00,129:INFO:Visual Rendered Successfully
2024-07-13 13:01:00,301:INFO:plot_model() successfully completed......................................
2024-07-13 13:01:00,334:INFO:Initializing predict_model()
2024-07-13 13:01:00,335:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018077C9DED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000180212668E0>)
2024-07-13 13:01:00,335:INFO:Checking exceptions
2024-07-13 13:01:00,335:INFO:Preloading libraries
2024-07-13 13:01:01,769:INFO:Initializing finalize_model()
2024-07-13 13:01:01,769:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018077C9DED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-13 13:01:01,770:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-13 13:01:01,832:INFO:Initializing create_model()
2024-07-13 13:01:01,832:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018077C9DED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-13 13:01:01,832:INFO:Checking exceptions
2024-07-13 13:01:01,834:INFO:Importing libraries
2024-07-13 13:01:01,834:INFO:Copying training dataset
2024-07-13 13:01:01,843:INFO:Defining folds
2024-07-13 13:01:01,844:INFO:Declaring metric variables
2024-07-13 13:01:01,844:INFO:Importing untrained model
2024-07-13 13:01:01,844:INFO:Declaring custom model
2024-07-13 13:01:01,844:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-13 13:01:01,847:INFO:Cross validation set to False
2024-07-13 13:01:01,847:INFO:Fitting Model
2024-07-13 13:01:13,389:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-13 13:01:13,389:INFO:[LightGBM] [Info] Number of positive: 36643, number of negative: 563357
2024-07-13 13:01:13,475:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033510 seconds.
2024-07-13 13:01:13,475:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-13 13:01:13,475:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-13 13:01:13,476:INFO:[LightGBM] [Info] Total Bins 642
2024-07-13 13:01:13,476:INFO:[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 27
2024-07-13 13:01:13,480:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061072 -> initscore=-2.732691
2024-07-13 13:01:13,480:INFO:[LightGBM] [Info] Start training from score -2.732691
2024-07-13 13:01:14,293:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-13 13:01:14,293:INFO:create_model() successfully completed......................................
2024-07-13 13:01:14,450:INFO:_master_model_container: 3
2024-07-13 13:01:14,450:INFO:_display_container: 4
2024-07-13 13:01:14,468:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-13 13:01:14,468:INFO:finalize_model() successfully completed......................................
2024-07-13 13:01:14,739:INFO:Initializing predict_model()
2024-07-13 13:01:14,739:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018077C9DED0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018021266A20>)
2024-07-13 13:01:14,739:INFO:Checking exceptions
2024-07-13 13:01:14,739:INFO:Preloading libraries
2024-07-13 13:01:14,741:INFO:Set up data.
2024-07-13 13:01:14,769:INFO:Set up index.
2024-07-13 13:01:17,347:INFO:Initializing save_model()
2024-07-13 13:01:17,347:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=Final Light GBM Model Jul2024, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-13 13:01:17,347:INFO:Adding model into prep_pipe
2024-07-13 13:01:17,347:WARNING:Only Model saved as it was a pipeline.
2024-07-13 13:01:17,368:INFO:Final Light GBM Model Jul2024.pkl saved in current working directory
2024-07-13 13:01:17,390:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-13 13:01:17,390:INFO:save_model() successfully completed......................................
2024-07-15 10:36:30,728:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-15 10:36:30,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-15 10:36:30,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-15 10:36:30,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-15 10:36:47,014:INFO:PyCaret ClassificationExperiment
2024-07-15 10:36:47,014:INFO:Logging name: credit
2024-07-15 10:36:47,014:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-15 10:36:47,014:INFO:version 3.3.2
2024-07-15 10:36:47,014:INFO:Initializing setup()
2024-07-15 10:36:47,014:INFO:self.USI: d023
2024-07-15 10:36:47,014:INFO:self._variable_keys: {'html_param', 'fold_groups_param', 'y_train', 'target_param', 'USI', 'exp_id', 'log_plots_param', 'X', 'gpu_param', 'seed', 'data', 'fix_imbalance', 'fold_generator', 'exp_name_log', 'fold_shuffle_param', 'memory', 'n_jobs_param', 'idx', 'gpu_n_jobs_param', 'X_train', '_available_plots', 'y', 'y_test', 'X_test', '_ml_usecase', 'is_multiclass', 'logging_param', 'pipeline'}
2024-07-15 10:36:47,014:INFO:Checking environment
2024-07-15 10:36:47,014:INFO:python_version: 3.11.7
2024-07-15 10:36:47,014:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2024-07-15 10:36:47,014:INFO:machine: AMD64
2024-07-15 10:36:47,014:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-15 10:36:47,020:INFO:Memory: svmem(total=16849293312, available=4811812864, percent=71.4, used=12037480448, free=4811812864)
2024-07-15 10:36:47,020:INFO:Physical Core: 12
2024-07-15 10:36:47,020:INFO:Logical Core: 16
2024-07-15 10:36:47,020:INFO:Checking libraries
2024-07-15 10:36:47,020:INFO:System:
2024-07-15 10:36:47,020:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2024-07-15 10:36:47,020:INFO:executable: c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\python.exe
2024-07-15 10:36:47,020:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-15 10:36:47,020:INFO:PyCaret required dependencies:
2024-07-15 10:36:47,497:INFO:                 pip: 24.1.2
2024-07-15 10:36:47,497:INFO:          setuptools: 65.5.0
2024-07-15 10:36:47,497:INFO:             pycaret: 3.3.2
2024-07-15 10:36:47,497:INFO:             IPython: 8.26.0
2024-07-15 10:36:47,497:INFO:          ipywidgets: 8.1.3
2024-07-15 10:36:47,498:INFO:                tqdm: 4.66.4
2024-07-15 10:36:47,498:INFO:               numpy: 1.26.4
2024-07-15 10:36:47,498:INFO:              pandas: 2.1.4
2024-07-15 10:36:47,498:INFO:              jinja2: 3.1.4
2024-07-15 10:36:47,498:INFO:               scipy: 1.11.4
2024-07-15 10:36:47,498:INFO:              joblib: 1.3.2
2024-07-15 10:36:47,498:INFO:             sklearn: 1.4.2
2024-07-15 10:36:47,498:INFO:                pyod: 2.0.1
2024-07-15 10:36:47,498:INFO:            imblearn: 0.12.3
2024-07-15 10:36:47,498:INFO:   category_encoders: 2.6.3
2024-07-15 10:36:47,498:INFO:            lightgbm: 4.4.0
2024-07-15 10:36:47,498:INFO:               numba: 0.60.0
2024-07-15 10:36:47,498:INFO:            requests: 2.32.3
2024-07-15 10:36:47,498:INFO:          matplotlib: 3.7.5
2024-07-15 10:36:47,498:INFO:          scikitplot: 0.3.7
2024-07-15 10:36:47,498:INFO:         yellowbrick: 1.5
2024-07-15 10:36:47,498:INFO:              plotly: 5.22.0
2024-07-15 10:36:47,498:INFO:    plotly-resampler: Not installed
2024-07-15 10:36:47,498:INFO:             kaleido: 0.2.1
2024-07-15 10:36:47,498:INFO:           schemdraw: 0.15
2024-07-15 10:36:47,498:INFO:         statsmodels: 0.14.2
2024-07-15 10:36:47,498:INFO:              sktime: 0.26.0
2024-07-15 10:36:47,498:INFO:               tbats: 1.1.3
2024-07-15 10:36:47,499:INFO:            pmdarima: 2.0.4
2024-07-15 10:36:47,499:INFO:              psutil: 6.0.0
2024-07-15 10:36:47,499:INFO:          markupsafe: 2.1.5
2024-07-15 10:36:47,499:INFO:             pickle5: Not installed
2024-07-15 10:36:47,499:INFO:         cloudpickle: 3.0.0
2024-07-15 10:36:47,499:INFO:         deprecation: 2.1.0
2024-07-15 10:36:47,499:INFO:              xxhash: 3.4.1
2024-07-15 10:36:47,499:INFO:           wurlitzer: Not installed
2024-07-15 10:36:47,499:INFO:PyCaret optional dependencies:
2024-07-15 10:36:47,513:INFO:                shap: Not installed
2024-07-15 10:36:47,513:INFO:           interpret: Not installed
2024-07-15 10:36:47,513:INFO:                umap: Not installed
2024-07-15 10:36:47,513:INFO:     ydata_profiling: Not installed
2024-07-15 10:36:47,513:INFO:  explainerdashboard: Not installed
2024-07-15 10:36:47,513:INFO:             autoviz: Not installed
2024-07-15 10:36:47,513:INFO:           fairlearn: Not installed
2024-07-15 10:36:47,513:INFO:          deepchecks: Not installed
2024-07-15 10:36:47,513:INFO:             xgboost: Not installed
2024-07-15 10:36:47,513:INFO:            catboost: Not installed
2024-07-15 10:36:47,513:INFO:              kmodes: Not installed
2024-07-15 10:36:47,513:INFO:             mlxtend: Not installed
2024-07-15 10:36:47,513:INFO:       statsforecast: Not installed
2024-07-15 10:36:47,513:INFO:        tune_sklearn: Not installed
2024-07-15 10:36:47,513:INFO:                 ray: Not installed
2024-07-15 10:36:47,513:INFO:            hyperopt: Not installed
2024-07-15 10:36:47,513:INFO:              optuna: Not installed
2024-07-15 10:36:47,513:INFO:               skopt: Not installed
2024-07-15 10:36:47,513:INFO:              mlflow: Not installed
2024-07-15 10:36:47,513:INFO:              gradio: Not installed
2024-07-15 10:36:47,514:INFO:             fastapi: Not installed
2024-07-15 10:36:47,514:INFO:             uvicorn: Not installed
2024-07-15 10:36:47,514:INFO:              m2cgen: Not installed
2024-07-15 10:36:47,514:INFO:           evidently: Not installed
2024-07-15 10:36:47,514:INFO:               fugue: Not installed
2024-07-15 10:36:47,514:INFO:           streamlit: Not installed
2024-07-15 10:36:47,514:INFO:             prophet: Not installed
2024-07-15 10:36:47,514:INFO:None
2024-07-15 10:36:47,514:INFO:Set up data.
2024-07-15 10:36:47,601:INFO:Set up folding strategy.
2024-07-15 10:36:47,601:INFO:Set up train/test split.
2024-07-15 10:36:47,890:INFO:Set up index.
2024-07-15 10:36:47,929:INFO:Assigning column types.
2024-07-15 10:36:48,033:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-15 10:36:48,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-15 10:36:48,107:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-15 10:36:48,165:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:48,166:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:48,223:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-15 10:36:48,225:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-15 10:36:48,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:48,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:48,257:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-15 10:36:48,306:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-15 10:36:48,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:48,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:48,388:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-15 10:36:48,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:48,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:48,417:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-15 10:36:48,491:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:48,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:48,568:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:48,568:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:48,579:INFO:Preparing preprocessing pipeline...
2024-07-15 10:36:48,601:INFO:Set up simple imputation.
2024-07-15 10:36:48,975:INFO:Set up encoding of ordinal features.
2024-07-15 10:36:49,008:INFO:Set up encoding of categorical features.
2024-07-15 10:36:49,009:INFO:Set up column transformation.
2024-07-15 10:36:49,009:INFO:Set up feature normalization.
2024-07-15 10:36:50,460:INFO:Finished creating preprocessing pipeline.
2024-07-15 10:36:50,480:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-07-15 10:36:50,480:INFO:Creating final display dataframe.
2024-07-15 10:36:51,868:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target              mau
2                   Target type           Binary
3           Original data shape     (600000, 13)
4        Transformed data shape     (600000, 30)
5   Transformed train set shape     (420000, 30)
6    Transformed test set shape     (180000, 30)
7              Numeric features                5
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Transformation             True
16        Transformation method         quantile
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           credit
25                          USI             d023
2024-07-15 10:36:51,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:51,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:52,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:52,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:52,035:INFO:setup() successfully completed in 5.05s...............
2024-07-15 10:36:52,046:INFO:gpu_param set to False
2024-07-15 10:36:52,119:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:52,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:52,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:52,193:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:36:52,211:INFO:Initializing create_model()
2024-07-15 10:36:52,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029288976F50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-15 10:36:52,211:INFO:Checking exceptions
2024-07-15 10:36:52,229:INFO:Importing libraries
2024-07-15 10:36:52,229:INFO:Copying training dataset
2024-07-15 10:36:52,541:INFO:Defining folds
2024-07-15 10:36:52,541:INFO:Declaring metric variables
2024-07-15 10:36:52,545:INFO:Importing untrained model
2024-07-15 10:36:52,548:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-15 10:36:52,555:INFO:Starting cross validation
2024-07-15 10:36:52,558:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-15 10:37:21,582:INFO:Calculating mean and std
2024-07-15 10:37:21,586:INFO:Creating metrics dataframe
2024-07-15 10:37:21,596:INFO:Finalizing model
2024-07-15 10:37:29,435:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-15 10:37:29,436:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-15 10:37:29,501:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018266 seconds.
2024-07-15 10:37:29,501:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-15 10:37:29,501:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-15 10:37:29,501:INFO:[LightGBM] [Info] Total Bins 643
2024-07-15 10:37:29,502:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-15 10:37:29,505:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-15 10:37:29,505:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-15 10:37:30,181:INFO:Uploading results into container
2024-07-15 10:37:30,182:INFO:Uploading model into container now
2024-07-15 10:37:30,194:INFO:_master_model_container: 1
2024-07-15 10:37:30,194:INFO:_display_container: 2
2024-07-15 10:37:30,195:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-15 10:37:30,195:INFO:create_model() successfully completed......................................
2024-07-15 10:37:30,379:INFO:Initializing tune_model()
2024-07-15 10:37:30,380:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029288976F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=1, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-15 10:37:30,380:INFO:Checking exceptions
2024-07-15 10:37:30,539:INFO:Copying training dataset
2024-07-15 10:37:30,743:INFO:Checking base model
2024-07-15 10:37:30,744:INFO:Base model : Light Gradient Boosting Machine
2024-07-15 10:37:30,748:INFO:Declaring metric variables
2024-07-15 10:37:30,751:INFO:Defining Hyperparameters
2024-07-15 10:37:30,921:INFO:Tuning with n_jobs=-1
2024-07-15 10:37:30,921:INFO:Initializing RandomizedSearchCV
2024-07-15 10:37:53,994:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.7}
2024-07-15 10:37:53,995:INFO:Hyperparameter search completed
2024-07-15 10:37:53,996:INFO:SubProcess create_model() called ==================================
2024-07-15 10:37:53,997:INFO:Initializing create_model()
2024-07-15 10:37:53,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029288976F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002929D82EE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 3, 'num_leaves': 256, 'n_estimators': 30, 'min_split_gain': 0.2, 'min_child_samples': 1, 'learning_rate': 0.0005, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.7})
2024-07-15 10:37:53,997:INFO:Checking exceptions
2024-07-15 10:37:53,997:INFO:Importing libraries
2024-07-15 10:37:53,997:INFO:Copying training dataset
2024-07-15 10:37:54,353:INFO:Defining folds
2024-07-15 10:37:54,354:INFO:Declaring metric variables
2024-07-15 10:37:54,358:INFO:Importing untrained model
2024-07-15 10:37:54,359:INFO:Declaring custom model
2024-07-15 10:37:54,364:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-15 10:37:54,373:INFO:Starting cross validation
2024-07-15 10:37:54,377:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-15 10:38:15,359:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:38:15,853:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:38:16,063:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:38:16,164:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:38:16,385:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:38:16,448:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:38:16,581:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:38:16,662:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:38:16,712:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:38:16,825:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:38:16,971:INFO:Calculating mean and std
2024-07-15 10:38:16,975:INFO:Creating metrics dataframe
2024-07-15 10:38:16,989:INFO:Finalizing model
2024-07-15 10:38:25,142:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-15 10:38:25,142:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-15 10:38:25,143:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-15 10:38:25,431:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-15 10:38:25,432:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-15 10:38:25,432:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-15 10:38:25,432:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-15 10:38:25,433:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-15 10:38:25,515:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022636 seconds.
2024-07-15 10:38:25,515:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-15 10:38:25,515:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-15 10:38:25,515:INFO:[LightGBM] [Info] Total Bins 647
2024-07-15 10:38:25,516:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 29
2024-07-15 10:38:25,522:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-15 10:38:25,522:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-15 10:38:25,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:38:25,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:38:25,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:38:25,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:38:26,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:38:26,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:38:26,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:38:26,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:38:26,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:38:26,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:38:26,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:38:26,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:38:26,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:38:26,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:38:26,540:INFO:Uploading results into container
2024-07-15 10:38:26,542:INFO:Uploading model into container now
2024-07-15 10:38:26,543:INFO:_master_model_container: 2
2024-07-15 10:38:26,543:INFO:_display_container: 3
2024-07-15 10:38:26,544:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-15 10:38:26,545:INFO:create_model() successfully completed......................................
2024-07-15 10:38:26,930:INFO:SubProcess create_model() end ==================================
2024-07-15 10:38:26,930:INFO:choose_better activated
2024-07-15 10:38:26,935:INFO:SubProcess create_model() called ==================================
2024-07-15 10:38:26,936:INFO:Initializing create_model()
2024-07-15 10:38:26,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029288976F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-15 10:38:26,936:INFO:Checking exceptions
2024-07-15 10:38:26,939:INFO:Importing libraries
2024-07-15 10:38:26,939:INFO:Copying training dataset
2024-07-15 10:38:27,265:INFO:Defining folds
2024-07-15 10:38:27,265:INFO:Declaring metric variables
2024-07-15 10:38:27,265:INFO:Importing untrained model
2024-07-15 10:38:27,265:INFO:Declaring custom model
2024-07-15 10:38:27,266:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-15 10:38:27,266:INFO:Starting cross validation
2024-07-15 10:38:27,268:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-15 10:38:47,212:INFO:Calculating mean and std
2024-07-15 10:38:47,213:INFO:Creating metrics dataframe
2024-07-15 10:38:47,215:INFO:Finalizing model
2024-07-15 10:38:55,144:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-15 10:38:55,145:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-15 10:38:55,215:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022576 seconds.
2024-07-15 10:38:55,215:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-15 10:38:55,215:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-15 10:38:55,216:INFO:[LightGBM] [Info] Total Bins 643
2024-07-15 10:38:55,216:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-15 10:38:55,219:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-15 10:38:55,219:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-15 10:38:55,792:INFO:Uploading results into container
2024-07-15 10:38:55,793:INFO:Uploading model into container now
2024-07-15 10:38:55,794:INFO:_master_model_container: 3
2024-07-15 10:38:55,794:INFO:_display_container: 4
2024-07-15 10:38:55,794:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-15 10:38:55,794:INFO:create_model() successfully completed......................................
2024-07-15 10:38:55,949:INFO:SubProcess create_model() end ==================================
2024-07-15 10:38:55,949:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0113
2024-07-15 10:38:55,950:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0
2024-07-15 10:38:55,950:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-07-15 10:38:55,950:INFO:choose_better completed
2024-07-15 10:38:55,950:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-15 10:38:55,960:INFO:_master_model_container: 3
2024-07-15 10:38:55,960:INFO:_display_container: 3
2024-07-15 10:38:55,961:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-15 10:38:55,961:INFO:tune_model() successfully completed......................................
2024-07-15 10:38:56,140:INFO:Initializing plot_model()
2024-07-15 10:38:56,140:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029288976F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-15 10:38:56,140:INFO:Checking exceptions
2024-07-15 10:38:56,255:INFO:Preloading libraries
2024-07-15 10:38:56,263:INFO:Copying training dataset
2024-07-15 10:38:56,263:INFO:Plot type: auc
2024-07-15 10:38:57,347:INFO:Fitting Model
2024-07-15 10:38:57,358:INFO:Scoring test/hold-out set
2024-07-15 10:38:58,020:INFO:Visual Rendered Successfully
2024-07-15 10:38:58,192:INFO:plot_model() successfully completed......................................
2024-07-15 10:38:58,213:INFO:Initializing plot_model()
2024-07-15 10:38:58,213:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029288976F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-15 10:38:58,213:INFO:Checking exceptions
2024-07-15 10:38:58,309:INFO:Preloading libraries
2024-07-15 10:38:58,318:INFO:Copying training dataset
2024-07-15 10:38:58,318:INFO:Plot type: pr
2024-07-15 10:38:59,355:INFO:Fitting Model
2024-07-15 10:38:59,370:INFO:Scoring test/hold-out set
2024-07-15 10:38:59,861:INFO:Visual Rendered Successfully
2024-07-15 10:39:00,031:INFO:plot_model() successfully completed......................................
2024-07-15 10:39:00,045:INFO:Initializing plot_model()
2024-07-15 10:39:00,045:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029288976F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-15 10:39:00,045:INFO:Checking exceptions
2024-07-15 10:39:00,145:INFO:Preloading libraries
2024-07-15 10:39:00,153:INFO:Copying training dataset
2024-07-15 10:39:00,153:INFO:Plot type: feature
2024-07-15 10:39:00,154:WARNING:No coef_ found. Trying feature_importances_
2024-07-15 10:39:00,646:INFO:Visual Rendered Successfully
2024-07-15 10:39:00,800:INFO:plot_model() successfully completed......................................
2024-07-15 10:39:00,819:INFO:Initializing plot_model()
2024-07-15 10:39:00,819:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029288976F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-15 10:39:00,819:INFO:Checking exceptions
2024-07-15 10:39:00,916:INFO:Preloading libraries
2024-07-15 10:39:00,923:INFO:Copying training dataset
2024-07-15 10:39:00,923:INFO:Plot type: confusion_matrix
2024-07-15 10:39:01,939:INFO:Fitting Model
2024-07-15 10:39:01,945:INFO:Scoring test/hold-out set
2024-07-15 10:39:02,308:INFO:Visual Rendered Successfully
2024-07-15 10:39:02,469:INFO:plot_model() successfully completed......................................
2024-07-15 10:39:02,509:INFO:Initializing predict_model()
2024-07-15 10:39:02,509:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029288976F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000292888D3920>)
2024-07-15 10:39:02,509:INFO:Checking exceptions
2024-07-15 10:39:02,509:INFO:Preloading libraries
2024-07-15 10:39:03,948:INFO:Initializing finalize_model()
2024-07-15 10:39:03,948:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029288976F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-15 10:39:03,949:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-15 10:39:04,010:INFO:Initializing create_model()
2024-07-15 10:39:04,010:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029288976F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-15 10:39:04,010:INFO:Checking exceptions
2024-07-15 10:39:04,012:INFO:Importing libraries
2024-07-15 10:39:04,012:INFO:Copying training dataset
2024-07-15 10:39:04,020:INFO:Defining folds
2024-07-15 10:39:04,020:INFO:Declaring metric variables
2024-07-15 10:39:04,020:INFO:Importing untrained model
2024-07-15 10:39:04,021:INFO:Declaring custom model
2024-07-15 10:39:04,021:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-15 10:39:04,023:INFO:Cross validation set to False
2024-07-15 10:39:04,023:INFO:Fitting Model
2024-07-15 10:39:15,246:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-15 10:39:15,246:INFO:[LightGBM] [Info] Number of positive: 36643, number of negative: 563357
2024-07-15 10:39:15,341:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030565 seconds.
2024-07-15 10:39:15,341:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-15 10:39:15,341:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-15 10:39:15,344:INFO:[LightGBM] [Info] Total Bins 642
2024-07-15 10:39:15,344:INFO:[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 27
2024-07-15 10:39:15,348:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061072 -> initscore=-2.732691
2024-07-15 10:39:15,348:INFO:[LightGBM] [Info] Start training from score -2.732691
2024-07-15 10:39:16,166:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-15 10:39:16,166:INFO:create_model() successfully completed......................................
2024-07-15 10:39:16,315:INFO:_master_model_container: 3
2024-07-15 10:39:16,315:INFO:_display_container: 4
2024-07-15 10:39:16,333:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-15 10:39:16,333:INFO:finalize_model() successfully completed......................................
2024-07-15 10:39:16,553:INFO:Initializing predict_model()
2024-07-15 10:39:16,553:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029288976F50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000292888D3880>)
2024-07-15 10:39:16,553:INFO:Checking exceptions
2024-07-15 10:39:16,553:INFO:Preloading libraries
2024-07-15 10:39:16,555:INFO:Set up data.
2024-07-15 10:39:16,588:INFO:Set up index.
2024-07-15 10:39:19,320:INFO:Initializing save_model()
2024-07-15 10:39:19,321:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=Final Light GBM Model Jul2024, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-15 10:39:19,321:INFO:Adding model into prep_pipe
2024-07-15 10:39:19,321:WARNING:Only Model saved as it was a pipeline.
2024-07-15 10:39:19,342:INFO:Final Light GBM Model Jul2024.pkl saved in current working directory
2024-07-15 10:39:19,366:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-15 10:39:19,366:INFO:save_model() successfully completed......................................
2024-07-15 10:50:41,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-15 10:50:41,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-15 10:50:41,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-15 10:50:41,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-15 10:50:45,056:INFO:PyCaret ClassificationExperiment
2024-07-15 10:50:45,057:INFO:Logging name: credit
2024-07-15 10:50:45,057:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-15 10:50:45,057:INFO:version 3.3.2
2024-07-15 10:50:45,057:INFO:Initializing setup()
2024-07-15 10:50:45,057:INFO:self.USI: 227b
2024-07-15 10:50:45,057:INFO:self._variable_keys: {'gpu_param', 'seed', 'data', 'pipeline', 'X_test', 'y_train', 'gpu_n_jobs_param', 'html_param', 'exp_name_log', 'target_param', 'exp_id', '_available_plots', 'logging_param', 'is_multiclass', 'log_plots_param', 'X', 'fix_imbalance', 'y_test', '_ml_usecase', 'fold_generator', 'fold_shuffle_param', 'USI', 'idx', 'fold_groups_param', 'n_jobs_param', 'y', 'X_train', 'memory'}
2024-07-15 10:50:45,057:INFO:Checking environment
2024-07-15 10:50:45,057:INFO:python_version: 3.11.7
2024-07-15 10:50:45,057:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2024-07-15 10:50:45,057:INFO:machine: AMD64
2024-07-15 10:50:45,057:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-15 10:50:45,062:INFO:Memory: svmem(total=16849293312, available=7127957504, percent=57.7, used=9721335808, free=7127957504)
2024-07-15 10:50:45,062:INFO:Physical Core: 12
2024-07-15 10:50:45,062:INFO:Logical Core: 16
2024-07-15 10:50:45,062:INFO:Checking libraries
2024-07-15 10:50:45,062:INFO:System:
2024-07-15 10:50:45,062:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2024-07-15 10:50:45,062:INFO:executable: c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\python.exe
2024-07-15 10:50:45,062:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-15 10:50:45,063:INFO:PyCaret required dependencies:
2024-07-15 10:50:45,103:INFO:                 pip: 24.1.2
2024-07-15 10:50:45,104:INFO:          setuptools: 65.5.0
2024-07-15 10:50:45,104:INFO:             pycaret: 3.3.2
2024-07-15 10:50:45,104:INFO:             IPython: 8.26.0
2024-07-15 10:50:45,104:INFO:          ipywidgets: 8.1.3
2024-07-15 10:50:45,104:INFO:                tqdm: 4.66.4
2024-07-15 10:50:45,104:INFO:               numpy: 1.26.4
2024-07-15 10:50:45,104:INFO:              pandas: 2.1.4
2024-07-15 10:50:45,104:INFO:              jinja2: 3.1.4
2024-07-15 10:50:45,104:INFO:               scipy: 1.11.4
2024-07-15 10:50:45,104:INFO:              joblib: 1.3.2
2024-07-15 10:50:45,104:INFO:             sklearn: 1.4.2
2024-07-15 10:50:45,104:INFO:                pyod: 2.0.1
2024-07-15 10:50:45,104:INFO:            imblearn: 0.12.3
2024-07-15 10:50:45,104:INFO:   category_encoders: 2.6.3
2024-07-15 10:50:45,104:INFO:            lightgbm: 4.4.0
2024-07-15 10:50:45,104:INFO:               numba: 0.60.0
2024-07-15 10:50:45,104:INFO:            requests: 2.32.3
2024-07-15 10:50:45,104:INFO:          matplotlib: 3.7.5
2024-07-15 10:50:45,104:INFO:          scikitplot: 0.3.7
2024-07-15 10:50:45,104:INFO:         yellowbrick: 1.5
2024-07-15 10:50:45,104:INFO:              plotly: 5.22.0
2024-07-15 10:50:45,104:INFO:    plotly-resampler: Not installed
2024-07-15 10:50:45,104:INFO:             kaleido: 0.2.1
2024-07-15 10:50:45,104:INFO:           schemdraw: 0.15
2024-07-15 10:50:45,104:INFO:         statsmodels: 0.14.2
2024-07-15 10:50:45,104:INFO:              sktime: 0.26.0
2024-07-15 10:50:45,104:INFO:               tbats: 1.1.3
2024-07-15 10:50:45,104:INFO:            pmdarima: 2.0.4
2024-07-15 10:50:45,104:INFO:              psutil: 6.0.0
2024-07-15 10:50:45,104:INFO:          markupsafe: 2.1.5
2024-07-15 10:50:45,105:INFO:             pickle5: Not installed
2024-07-15 10:50:45,105:INFO:         cloudpickle: 3.0.0
2024-07-15 10:50:45,105:INFO:         deprecation: 2.1.0
2024-07-15 10:50:45,105:INFO:              xxhash: 3.4.1
2024-07-15 10:50:45,105:INFO:           wurlitzer: Not installed
2024-07-15 10:50:45,105:INFO:PyCaret optional dependencies:
2024-07-15 10:50:45,117:INFO:                shap: Not installed
2024-07-15 10:50:45,117:INFO:           interpret: Not installed
2024-07-15 10:50:45,117:INFO:                umap: Not installed
2024-07-15 10:50:45,117:INFO:     ydata_profiling: Not installed
2024-07-15 10:50:45,117:INFO:  explainerdashboard: Not installed
2024-07-15 10:50:45,118:INFO:             autoviz: Not installed
2024-07-15 10:50:45,118:INFO:           fairlearn: Not installed
2024-07-15 10:50:45,118:INFO:          deepchecks: Not installed
2024-07-15 10:50:45,118:INFO:             xgboost: Not installed
2024-07-15 10:50:45,118:INFO:            catboost: Not installed
2024-07-15 10:50:45,118:INFO:              kmodes: Not installed
2024-07-15 10:50:45,118:INFO:             mlxtend: Not installed
2024-07-15 10:50:45,118:INFO:       statsforecast: Not installed
2024-07-15 10:50:45,118:INFO:        tune_sklearn: Not installed
2024-07-15 10:50:45,118:INFO:                 ray: Not installed
2024-07-15 10:50:45,118:INFO:            hyperopt: Not installed
2024-07-15 10:50:45,118:INFO:              optuna: Not installed
2024-07-15 10:50:45,118:INFO:               skopt: Not installed
2024-07-15 10:50:45,118:INFO:              mlflow: Not installed
2024-07-15 10:50:45,118:INFO:              gradio: Not installed
2024-07-15 10:50:45,118:INFO:             fastapi: Not installed
2024-07-15 10:50:45,118:INFO:             uvicorn: Not installed
2024-07-15 10:50:45,118:INFO:              m2cgen: Not installed
2024-07-15 10:50:45,118:INFO:           evidently: Not installed
2024-07-15 10:50:45,118:INFO:               fugue: Not installed
2024-07-15 10:50:45,118:INFO:           streamlit: Not installed
2024-07-15 10:50:45,118:INFO:             prophet: Not installed
2024-07-15 10:50:45,118:INFO:None
2024-07-15 10:50:45,118:INFO:Set up data.
2024-07-15 10:50:45,197:INFO:Set up folding strategy.
2024-07-15 10:50:45,197:INFO:Set up train/test split.
2024-07-15 10:50:45,484:INFO:Set up index.
2024-07-15 10:50:45,518:INFO:Assigning column types.
2024-07-15 10:50:45,605:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-15 10:50:45,647:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-15 10:50:45,654:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-15 10:50:45,695:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:45,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:45,739:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-15 10:50:45,739:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-15 10:50:45,766:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:45,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:45,767:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-15 10:50:45,812:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-15 10:50:45,840:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:45,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:45,885:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-15 10:50:45,918:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:45,919:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:45,919:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-15 10:50:45,992:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:45,992:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:46,084:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:46,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:46,088:INFO:Preparing preprocessing pipeline...
2024-07-15 10:50:46,109:INFO:Set up simple imputation.
2024-07-15 10:50:46,452:INFO:Set up encoding of ordinal features.
2024-07-15 10:50:46,483:INFO:Set up encoding of categorical features.
2024-07-15 10:50:46,483:INFO:Set up column transformation.
2024-07-15 10:50:46,483:INFO:Set up feature normalization.
2024-07-15 10:50:47,984:INFO:Finished creating preprocessing pipeline.
2024-07-15 10:50:48,005:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-07-15 10:50:48,005:INFO:Creating final display dataframe.
2024-07-15 10:50:49,437:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target              mau
2                   Target type           Binary
3           Original data shape     (600000, 13)
4        Transformed data shape     (600000, 30)
5   Transformed train set shape     (420000, 30)
6    Transformed test set shape     (180000, 30)
7              Numeric features                5
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Transformation             True
16        Transformation method         quantile
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           credit
25                          USI             227b
2024-07-15 10:50:49,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:49,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:49,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:49,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:49,590:INFO:setup() successfully completed in 4.57s...............
2024-07-15 10:50:49,605:INFO:gpu_param set to False
2024-07-15 10:50:49,680:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:49,681:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:49,753:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:49,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:50:49,774:INFO:Initializing create_model()
2024-07-15 10:50:49,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015D3D1DBC10>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-15 10:50:49,775:INFO:Checking exceptions
2024-07-15 10:50:49,792:INFO:Importing libraries
2024-07-15 10:50:49,792:INFO:Copying training dataset
2024-07-15 10:50:50,073:INFO:Defining folds
2024-07-15 10:50:50,073:INFO:Declaring metric variables
2024-07-15 10:50:50,076:INFO:Importing untrained model
2024-07-15 10:50:50,080:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-15 10:50:50,088:INFO:Starting cross validation
2024-07-15 10:50:50,091:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-15 10:56:45,235:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-15 10:56:45,235:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-15 10:56:45,235:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-15 10:56:45,236:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-15 10:56:48,257:INFO:PyCaret ClassificationExperiment
2024-07-15 10:56:48,257:INFO:Logging name: credit
2024-07-15 10:56:48,257:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-15 10:56:48,257:INFO:version 3.3.2
2024-07-15 10:56:48,257:INFO:Initializing setup()
2024-07-15 10:56:48,257:INFO:self.USI: f5b5
2024-07-15 10:56:48,257:INFO:self._variable_keys: {'exp_id', 'n_jobs_param', 'y_train', 'pipeline', 'html_param', 'exp_name_log', 'log_plots_param', 'gpu_n_jobs_param', 'X_test', 'is_multiclass', 'target_param', 'seed', 'idx', 'memory', 'fold_generator', 'logging_param', 'X_train', '_ml_usecase', 'X', '_available_plots', 'gpu_param', 'fold_shuffle_param', 'USI', 'y_test', 'fold_groups_param', 'fix_imbalance', 'y', 'data'}
2024-07-15 10:56:48,257:INFO:Checking environment
2024-07-15 10:56:48,258:INFO:python_version: 3.11.7
2024-07-15 10:56:48,258:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2024-07-15 10:56:48,258:INFO:machine: AMD64
2024-07-15 10:56:48,258:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-15 10:56:48,262:INFO:Memory: svmem(total=16849293312, available=8065433600, percent=52.1, used=8783859712, free=8065433600)
2024-07-15 10:56:48,263:INFO:Physical Core: 12
2024-07-15 10:56:48,263:INFO:Logical Core: 16
2024-07-15 10:56:48,263:INFO:Checking libraries
2024-07-15 10:56:48,263:INFO:System:
2024-07-15 10:56:48,263:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2024-07-15 10:56:48,263:INFO:executable: c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\python.exe
2024-07-15 10:56:48,263:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-15 10:56:48,263:INFO:PyCaret required dependencies:
2024-07-15 10:56:48,296:INFO:                 pip: 24.1.2
2024-07-15 10:56:48,296:INFO:          setuptools: 65.5.0
2024-07-15 10:56:48,296:INFO:             pycaret: 3.3.2
2024-07-15 10:56:48,296:INFO:             IPython: 8.26.0
2024-07-15 10:56:48,296:INFO:          ipywidgets: 8.1.3
2024-07-15 10:56:48,296:INFO:                tqdm: 4.66.4
2024-07-15 10:56:48,296:INFO:               numpy: 1.26.4
2024-07-15 10:56:48,296:INFO:              pandas: 2.1.4
2024-07-15 10:56:48,296:INFO:              jinja2: 3.1.4
2024-07-15 10:56:48,296:INFO:               scipy: 1.11.4
2024-07-15 10:56:48,296:INFO:              joblib: 1.3.2
2024-07-15 10:56:48,296:INFO:             sklearn: 1.4.2
2024-07-15 10:56:48,296:INFO:                pyod: 2.0.1
2024-07-15 10:56:48,296:INFO:            imblearn: 0.12.3
2024-07-15 10:56:48,296:INFO:   category_encoders: 2.6.3
2024-07-15 10:56:48,296:INFO:            lightgbm: 4.4.0
2024-07-15 10:56:48,296:INFO:               numba: 0.60.0
2024-07-15 10:56:48,296:INFO:            requests: 2.32.3
2024-07-15 10:56:48,296:INFO:          matplotlib: 3.7.5
2024-07-15 10:56:48,296:INFO:          scikitplot: 0.3.7
2024-07-15 10:56:48,296:INFO:         yellowbrick: 1.5
2024-07-15 10:56:48,296:INFO:              plotly: 5.22.0
2024-07-15 10:56:48,296:INFO:    plotly-resampler: Not installed
2024-07-15 10:56:48,296:INFO:             kaleido: 0.2.1
2024-07-15 10:56:48,297:INFO:           schemdraw: 0.15
2024-07-15 10:56:48,297:INFO:         statsmodels: 0.14.2
2024-07-15 10:56:48,297:INFO:              sktime: 0.26.0
2024-07-15 10:56:48,297:INFO:               tbats: 1.1.3
2024-07-15 10:56:48,297:INFO:            pmdarima: 2.0.4
2024-07-15 10:56:48,297:INFO:              psutil: 6.0.0
2024-07-15 10:56:48,297:INFO:          markupsafe: 2.1.5
2024-07-15 10:56:48,297:INFO:             pickle5: Not installed
2024-07-15 10:56:48,297:INFO:         cloudpickle: 3.0.0
2024-07-15 10:56:48,297:INFO:         deprecation: 2.1.0
2024-07-15 10:56:48,297:INFO:              xxhash: 3.4.1
2024-07-15 10:56:48,297:INFO:           wurlitzer: Not installed
2024-07-15 10:56:48,297:INFO:PyCaret optional dependencies:
2024-07-15 10:56:48,310:INFO:                shap: Not installed
2024-07-15 10:56:48,311:INFO:           interpret: Not installed
2024-07-15 10:56:48,311:INFO:                umap: Not installed
2024-07-15 10:56:48,311:INFO:     ydata_profiling: Not installed
2024-07-15 10:56:48,311:INFO:  explainerdashboard: Not installed
2024-07-15 10:56:48,311:INFO:             autoviz: Not installed
2024-07-15 10:56:48,311:INFO:           fairlearn: Not installed
2024-07-15 10:56:48,311:INFO:          deepchecks: Not installed
2024-07-15 10:56:48,311:INFO:             xgboost: Not installed
2024-07-15 10:56:48,311:INFO:            catboost: Not installed
2024-07-15 10:56:48,311:INFO:              kmodes: Not installed
2024-07-15 10:56:48,311:INFO:             mlxtend: Not installed
2024-07-15 10:56:48,311:INFO:       statsforecast: Not installed
2024-07-15 10:56:48,311:INFO:        tune_sklearn: Not installed
2024-07-15 10:56:48,311:INFO:                 ray: Not installed
2024-07-15 10:56:48,311:INFO:            hyperopt: Not installed
2024-07-15 10:56:48,311:INFO:              optuna: Not installed
2024-07-15 10:56:48,311:INFO:               skopt: Not installed
2024-07-15 10:56:48,311:INFO:              mlflow: Not installed
2024-07-15 10:56:48,311:INFO:              gradio: Not installed
2024-07-15 10:56:48,311:INFO:             fastapi: Not installed
2024-07-15 10:56:48,311:INFO:             uvicorn: Not installed
2024-07-15 10:56:48,312:INFO:              m2cgen: Not installed
2024-07-15 10:56:48,312:INFO:           evidently: Not installed
2024-07-15 10:56:48,312:INFO:               fugue: Not installed
2024-07-15 10:56:48,312:INFO:           streamlit: Not installed
2024-07-15 10:56:48,312:INFO:             prophet: Not installed
2024-07-15 10:56:48,312:INFO:None
2024-07-15 10:56:48,312:INFO:Set up data.
2024-07-15 10:56:48,401:INFO:Set up folding strategy.
2024-07-15 10:56:48,401:INFO:Set up train/test split.
2024-07-15 10:56:48,671:INFO:Set up index.
2024-07-15 10:56:48,707:INFO:Assigning column types.
2024-07-15 10:56:48,794:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-15 10:56:48,839:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-15 10:56:48,843:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-15 10:56:48,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:48,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:48,926:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-15 10:56:48,927:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-15 10:56:48,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:48,954:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:48,955:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-15 10:56:48,999:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-15 10:56:49,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:49,029:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:49,074:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-15 10:56:49,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:49,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:49,105:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-15 10:56:49,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:49,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:49,254:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:49,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:49,257:INFO:Preparing preprocessing pipeline...
2024-07-15 10:56:49,277:INFO:Set up simple imputation.
2024-07-15 10:56:49,629:INFO:Set up encoding of ordinal features.
2024-07-15 10:56:49,661:INFO:Set up encoding of categorical features.
2024-07-15 10:56:49,662:INFO:Set up column transformation.
2024-07-15 10:56:49,662:INFO:Set up feature normalization.
2024-07-15 10:56:51,030:INFO:Finished creating preprocessing pipeline.
2024-07-15 10:56:51,047:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-07-15 10:56:51,047:INFO:Creating final display dataframe.
2024-07-15 10:56:52,405:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target              mau
2                   Target type           Binary
3           Original data shape     (600000, 13)
4        Transformed data shape     (600000, 30)
5   Transformed train set shape     (420000, 30)
6    Transformed test set shape     (180000, 30)
7              Numeric features                5
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Transformation             True
16        Transformation method         quantile
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           credit
25                          USI             f5b5
2024-07-15 10:56:52,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:52,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:52,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:52,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:52,556:INFO:setup() successfully completed in 4.32s...............
2024-07-15 10:56:52,571:INFO:gpu_param set to False
2024-07-15 10:56:52,645:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:52,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:52,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:52,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-15 10:56:52,741:INFO:Initializing create_model()
2024-07-15 10:56:52,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002311D8D5BD0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-15 10:56:52,742:INFO:Checking exceptions
2024-07-15 10:56:52,758:INFO:Importing libraries
2024-07-15 10:56:52,758:INFO:Copying training dataset
2024-07-15 10:56:53,055:INFO:Defining folds
2024-07-15 10:56:53,055:INFO:Declaring metric variables
2024-07-15 10:56:53,058:INFO:Importing untrained model
2024-07-15 10:56:53,062:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-15 10:56:53,069:INFO:Starting cross validation
2024-07-15 10:56:53,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-15 10:57:17,722:INFO:Calculating mean and std
2024-07-15 10:57:17,728:INFO:Creating metrics dataframe
2024-07-15 10:57:17,735:INFO:Finalizing model
2024-07-15 10:57:25,707:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-15 10:57:25,708:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-15 10:57:25,771:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024197 seconds.
2024-07-15 10:57:25,771:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-15 10:57:25,771:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-15 10:57:25,772:INFO:[LightGBM] [Info] Total Bins 643
2024-07-15 10:57:25,772:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-15 10:57:25,775:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-15 10:57:25,775:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-15 10:57:26,358:INFO:Uploading results into container
2024-07-15 10:57:26,359:INFO:Uploading model into container now
2024-07-15 10:57:26,372:INFO:_master_model_container: 1
2024-07-15 10:57:26,373:INFO:_display_container: 2
2024-07-15 10:57:26,373:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-15 10:57:26,374:INFO:create_model() successfully completed......................................
2024-07-15 10:57:26,621:INFO:Initializing tune_model()
2024-07-15 10:57:26,621:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002311D8D5BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=1, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-15 10:57:26,621:INFO:Checking exceptions
2024-07-15 10:57:26,765:INFO:Copying training dataset
2024-07-15 10:57:26,968:INFO:Checking base model
2024-07-15 10:57:26,968:INFO:Base model : Light Gradient Boosting Machine
2024-07-15 10:57:26,972:INFO:Declaring metric variables
2024-07-15 10:57:26,976:INFO:Defining Hyperparameters
2024-07-15 10:57:27,127:INFO:Tuning with n_jobs=-1
2024-07-15 10:57:27,127:INFO:Initializing RandomizedSearchCV
2024-07-15 10:57:49,532:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.7}
2024-07-15 10:57:49,533:INFO:Hyperparameter search completed
2024-07-15 10:57:49,534:INFO:SubProcess create_model() called ==================================
2024-07-15 10:57:49,535:INFO:Initializing create_model()
2024-07-15 10:57:49,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002311D8D5BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023146B79350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 3, 'num_leaves': 256, 'n_estimators': 30, 'min_split_gain': 0.2, 'min_child_samples': 1, 'learning_rate': 0.0005, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.7})
2024-07-15 10:57:49,535:INFO:Checking exceptions
2024-07-15 10:57:49,535:INFO:Importing libraries
2024-07-15 10:57:49,535:INFO:Copying training dataset
2024-07-15 10:57:49,839:INFO:Defining folds
2024-07-15 10:57:49,839:INFO:Declaring metric variables
2024-07-15 10:57:49,843:INFO:Importing untrained model
2024-07-15 10:57:49,843:INFO:Declaring custom model
2024-07-15 10:57:49,847:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-15 10:57:49,854:INFO:Starting cross validation
2024-07-15 10:57:49,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-15 10:58:09,882:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:58:10,151:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:58:10,166:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:58:10,197:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:58:10,200:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:58:10,280:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:58:10,361:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:58:10,414:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:58:10,893:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:58:10,942:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-15 10:58:11,087:INFO:Calculating mean and std
2024-07-15 10:58:11,088:INFO:Creating metrics dataframe
2024-07-15 10:58:11,095:INFO:Finalizing model
2024-07-15 10:58:18,904:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-15 10:58:18,905:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-15 10:58:18,905:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-15 10:58:19,186:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-15 10:58:19,186:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-15 10:58:19,187:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-15 10:58:19,187:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-15 10:58:19,187:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-15 10:58:19,244:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020558 seconds.
2024-07-15 10:58:19,245:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-15 10:58:19,245:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-15 10:58:19,245:INFO:[LightGBM] [Info] Total Bins 647
2024-07-15 10:58:19,246:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 29
2024-07-15 10:58:19,251:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-15 10:58:19,251:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-15 10:58:19,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:58:19,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:58:19,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:58:19,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:58:19,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:58:19,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:58:19,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:58:19,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:58:19,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:58:19,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:58:19,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:58:19,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:58:19,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:58:19,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-15 10:58:19,961:INFO:Uploading results into container
2024-07-15 10:58:19,963:INFO:Uploading model into container now
2024-07-15 10:58:19,963:INFO:_master_model_container: 2
2024-07-15 10:58:19,964:INFO:_display_container: 3
2024-07-15 10:58:19,965:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-15 10:58:19,965:INFO:create_model() successfully completed......................................
2024-07-15 10:58:20,140:INFO:SubProcess create_model() end ==================================
2024-07-15 10:58:20,140:INFO:choose_better activated
2024-07-15 10:58:20,144:INFO:SubProcess create_model() called ==================================
2024-07-15 10:58:20,144:INFO:Initializing create_model()
2024-07-15 10:58:20,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002311D8D5BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-15 10:58:20,145:INFO:Checking exceptions
2024-07-15 10:58:20,146:INFO:Importing libraries
2024-07-15 10:58:20,146:INFO:Copying training dataset
2024-07-15 10:58:20,436:INFO:Defining folds
2024-07-15 10:58:20,436:INFO:Declaring metric variables
2024-07-15 10:58:20,436:INFO:Importing untrained model
2024-07-15 10:58:20,436:INFO:Declaring custom model
2024-07-15 10:58:20,437:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-15 10:58:20,437:INFO:Starting cross validation
2024-07-15 10:58:20,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-15 10:58:39,952:INFO:Calculating mean and std
2024-07-15 10:58:39,952:INFO:Creating metrics dataframe
2024-07-15 10:58:39,954:INFO:Finalizing model
2024-07-15 10:58:47,917:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-15 10:58:47,918:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-15 10:58:47,999:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022549 seconds.
2024-07-15 10:58:47,999:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-15 10:58:48,000:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-15 10:58:48,000:INFO:[LightGBM] [Info] Total Bins 643
2024-07-15 10:58:48,000:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-15 10:58:48,003:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-15 10:58:48,003:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-15 10:58:48,715:INFO:Uploading results into container
2024-07-15 10:58:48,716:INFO:Uploading model into container now
2024-07-15 10:58:48,717:INFO:_master_model_container: 3
2024-07-15 10:58:48,717:INFO:_display_container: 4
2024-07-15 10:58:48,717:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-15 10:58:48,717:INFO:create_model() successfully completed......................................
2024-07-15 10:58:48,888:INFO:SubProcess create_model() end ==================================
2024-07-15 10:58:48,889:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0113
2024-07-15 10:58:48,889:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0
2024-07-15 10:58:48,890:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-07-15 10:58:48,890:INFO:choose_better completed
2024-07-15 10:58:48,890:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-15 10:58:48,900:INFO:_master_model_container: 3
2024-07-15 10:58:48,900:INFO:_display_container: 3
2024-07-15 10:58:48,900:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-15 10:58:48,900:INFO:tune_model() successfully completed......................................
2024-07-15 10:58:49,081:INFO:Initializing plot_model()
2024-07-15 10:58:49,081:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002311D8D5BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-15 10:58:49,081:INFO:Checking exceptions
2024-07-15 10:58:49,188:INFO:Preloading libraries
2024-07-15 10:58:49,196:INFO:Copying training dataset
2024-07-15 10:58:49,197:INFO:Plot type: auc
2024-07-15 10:58:50,307:INFO:Fitting Model
2024-07-15 10:58:50,317:INFO:Scoring test/hold-out set
2024-07-15 10:58:50,963:INFO:Visual Rendered Successfully
2024-07-15 10:58:51,138:INFO:plot_model() successfully completed......................................
2024-07-15 10:58:51,155:INFO:Initializing plot_model()
2024-07-15 10:58:51,156:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002311D8D5BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-15 10:58:51,156:INFO:Checking exceptions
2024-07-15 10:58:51,257:INFO:Preloading libraries
2024-07-15 10:58:51,266:INFO:Copying training dataset
2024-07-15 10:58:51,266:INFO:Plot type: pr
2024-07-15 10:58:52,331:INFO:Fitting Model
2024-07-15 10:58:52,370:INFO:Scoring test/hold-out set
2024-07-15 10:58:52,900:INFO:Visual Rendered Successfully
2024-07-15 10:58:53,059:INFO:plot_model() successfully completed......................................
2024-07-15 10:58:53,077:INFO:Initializing plot_model()
2024-07-15 10:58:53,078:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002311D8D5BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-15 10:58:53,078:INFO:Checking exceptions
2024-07-15 10:58:53,178:INFO:Preloading libraries
2024-07-15 10:58:53,190:INFO:Copying training dataset
2024-07-15 10:58:53,190:INFO:Plot type: feature
2024-07-15 10:58:53,190:WARNING:No coef_ found. Trying feature_importances_
2024-07-15 10:58:53,704:INFO:Visual Rendered Successfully
2024-07-15 10:58:53,851:INFO:plot_model() successfully completed......................................
2024-07-15 10:58:53,867:INFO:Initializing plot_model()
2024-07-15 10:58:53,867:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002311D8D5BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-15 10:58:53,867:INFO:Checking exceptions
2024-07-15 10:58:53,986:INFO:Preloading libraries
2024-07-15 10:58:53,995:INFO:Copying training dataset
2024-07-15 10:58:53,996:INFO:Plot type: confusion_matrix
2024-07-15 10:58:55,040:INFO:Fitting Model
2024-07-15 10:58:55,047:INFO:Scoring test/hold-out set
2024-07-15 10:58:55,423:INFO:Visual Rendered Successfully
2024-07-15 10:58:55,579:INFO:plot_model() successfully completed......................................
2024-07-15 10:58:55,633:INFO:Initializing predict_model()
2024-07-15 10:58:55,633:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002311D8D5BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023130DAE200>)
2024-07-15 10:58:55,633:INFO:Checking exceptions
2024-07-15 10:58:55,633:INFO:Preloading libraries
2024-07-15 10:58:57,068:INFO:Initializing finalize_model()
2024-07-15 10:58:57,068:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002311D8D5BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-15 10:58:57,069:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-15 10:58:57,152:INFO:Initializing create_model()
2024-07-15 10:58:57,152:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002311D8D5BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-15 10:58:57,152:INFO:Checking exceptions
2024-07-15 10:58:57,154:INFO:Importing libraries
2024-07-15 10:58:57,154:INFO:Copying training dataset
2024-07-15 10:58:57,165:INFO:Defining folds
2024-07-15 10:58:57,165:INFO:Declaring metric variables
2024-07-15 10:58:57,165:INFO:Importing untrained model
2024-07-15 10:58:57,165:INFO:Declaring custom model
2024-07-15 10:58:57,166:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-15 10:58:57,169:INFO:Cross validation set to False
2024-07-15 10:58:57,169:INFO:Fitting Model
2024-07-15 10:59:08,487:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-15 10:59:08,488:INFO:[LightGBM] [Info] Number of positive: 36643, number of negative: 563357
2024-07-15 10:59:08,574:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035118 seconds.
2024-07-15 10:59:08,574:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-15 10:59:08,574:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-15 10:59:08,575:INFO:[LightGBM] [Info] Total Bins 642
2024-07-15 10:59:08,575:INFO:[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 27
2024-07-15 10:59:08,578:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061072 -> initscore=-2.732691
2024-07-15 10:59:08,578:INFO:[LightGBM] [Info] Start training from score -2.732691
2024-07-15 10:59:09,553:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-15 10:59:09,553:INFO:create_model() successfully completed......................................
2024-07-15 10:59:09,722:INFO:_master_model_container: 3
2024-07-15 10:59:09,722:INFO:_display_container: 4
2024-07-15 10:59:09,744:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-15 10:59:09,745:INFO:finalize_model() successfully completed......................................
2024-07-15 10:59:10,031:INFO:Initializing predict_model()
2024-07-15 10:59:10,031:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002311D8D5BD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002311D868720>)
2024-07-15 10:59:10,031:INFO:Checking exceptions
2024-07-15 10:59:10,031:INFO:Preloading libraries
2024-07-15 10:59:10,033:INFO:Set up data.
2024-07-15 10:59:10,078:INFO:Set up index.
2024-07-15 10:59:12,625:INFO:Initializing save_model()
2024-07-15 10:59:12,625:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=Final Light GBM Model Jul2024, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-15 10:59:12,626:INFO:Adding model into prep_pipe
2024-07-15 10:59:12,626:WARNING:Only Model saved as it was a pipeline.
2024-07-15 10:59:12,650:INFO:Final Light GBM Model Jul2024.pkl saved in current working directory
2024-07-15 10:59:12,681:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-15 10:59:12,681:INFO:save_model() successfully completed......................................
2024-07-15 11:03:16,912:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\arraylike.py:396: RuntimeWarning: divide by zero encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)

2024-07-15 11:03:17,067:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\arraylike.py:396: RuntimeWarning: divide by zero encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)

2024-07-17 13:28:29,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-17 13:28:29,935:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-17 13:28:29,935:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-17 13:28:29,935:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-17 15:29:52,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-17 15:29:52,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-17 15:29:52,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-17 15:29:52,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-17 15:29:55,978:INFO:PyCaret ClassificationExperiment
2024-07-17 15:29:55,979:INFO:Logging name: credit
2024-07-17 15:29:55,979:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-17 15:29:55,979:INFO:version 3.3.2
2024-07-17 15:29:55,979:INFO:Initializing setup()
2024-07-17 15:29:55,979:INFO:self.USI: 6ebd
2024-07-17 15:29:55,979:INFO:self._variable_keys: {'exp_name_log', 'gpu_n_jobs_param', 'logging_param', 'X_train', 'idx', 'y_train', 'X', 'target_param', 'memory', 'fold_generator', '_ml_usecase', 'fix_imbalance', 'html_param', 'y', 'is_multiclass', 'USI', 'fold_groups_param', 'exp_id', 'y_test', 'log_plots_param', 'fold_shuffle_param', 'seed', 'n_jobs_param', 'pipeline', 'gpu_param', '_available_plots', 'X_test', 'data'}
2024-07-17 15:29:55,979:INFO:Checking environment
2024-07-17 15:29:55,979:INFO:python_version: 3.11.7
2024-07-17 15:29:55,979:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2024-07-17 15:29:55,979:INFO:machine: AMD64
2024-07-17 15:29:55,980:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-17 15:29:55,984:INFO:Memory: svmem(total=16849293312, available=5036744704, percent=70.1, used=11812548608, free=5036744704)
2024-07-17 15:29:55,985:INFO:Physical Core: 12
2024-07-17 15:29:55,985:INFO:Logical Core: 16
2024-07-17 15:29:55,985:INFO:Checking libraries
2024-07-17 15:29:55,985:INFO:System:
2024-07-17 15:29:55,985:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2024-07-17 15:29:55,985:INFO:executable: c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\python.exe
2024-07-17 15:29:55,985:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-17 15:29:55,985:INFO:PyCaret required dependencies:
2024-07-17 15:29:56,452:INFO:                 pip: 24.1.2
2024-07-17 15:29:56,453:INFO:          setuptools: 65.5.0
2024-07-17 15:29:56,453:INFO:             pycaret: 3.3.2
2024-07-17 15:29:56,453:INFO:             IPython: 8.26.0
2024-07-17 15:29:56,453:INFO:          ipywidgets: 8.1.3
2024-07-17 15:29:56,453:INFO:                tqdm: 4.66.4
2024-07-17 15:29:56,453:INFO:               numpy: 1.26.4
2024-07-17 15:29:56,453:INFO:              pandas: 2.1.4
2024-07-17 15:29:56,453:INFO:              jinja2: 3.1.4
2024-07-17 15:29:56,453:INFO:               scipy: 1.11.4
2024-07-17 15:29:56,453:INFO:              joblib: 1.3.2
2024-07-17 15:29:56,453:INFO:             sklearn: 1.4.2
2024-07-17 15:29:56,453:INFO:                pyod: 2.0.1
2024-07-17 15:29:56,453:INFO:            imblearn: 0.12.3
2024-07-17 15:29:56,453:INFO:   category_encoders: 2.6.3
2024-07-17 15:29:56,453:INFO:            lightgbm: 4.4.0
2024-07-17 15:29:56,453:INFO:               numba: 0.60.0
2024-07-17 15:29:56,453:INFO:            requests: 2.32.3
2024-07-17 15:29:56,453:INFO:          matplotlib: 3.7.5
2024-07-17 15:29:56,453:INFO:          scikitplot: 0.3.7
2024-07-17 15:29:56,453:INFO:         yellowbrick: 1.5
2024-07-17 15:29:56,453:INFO:              plotly: 5.22.0
2024-07-17 15:29:56,453:INFO:    plotly-resampler: Not installed
2024-07-17 15:29:56,453:INFO:             kaleido: 0.2.1
2024-07-17 15:29:56,453:INFO:           schemdraw: 0.15
2024-07-17 15:29:56,453:INFO:         statsmodels: 0.14.2
2024-07-17 15:29:56,453:INFO:              sktime: 0.26.0
2024-07-17 15:29:56,453:INFO:               tbats: 1.1.3
2024-07-17 15:29:56,453:INFO:            pmdarima: 2.0.4
2024-07-17 15:29:56,453:INFO:              psutil: 6.0.0
2024-07-17 15:29:56,453:INFO:          markupsafe: 2.1.5
2024-07-17 15:29:56,454:INFO:             pickle5: Not installed
2024-07-17 15:29:56,454:INFO:         cloudpickle: 3.0.0
2024-07-17 15:29:56,454:INFO:         deprecation: 2.1.0
2024-07-17 15:29:56,454:INFO:              xxhash: 3.4.1
2024-07-17 15:29:56,454:INFO:           wurlitzer: Not installed
2024-07-17 15:29:56,454:INFO:PyCaret optional dependencies:
2024-07-17 15:29:56,466:INFO:                shap: Not installed
2024-07-17 15:29:56,466:INFO:           interpret: Not installed
2024-07-17 15:29:56,466:INFO:                umap: Not installed
2024-07-17 15:29:56,466:INFO:     ydata_profiling: Not installed
2024-07-17 15:29:56,466:INFO:  explainerdashboard: Not installed
2024-07-17 15:29:56,466:INFO:             autoviz: Not installed
2024-07-17 15:29:56,467:INFO:           fairlearn: Not installed
2024-07-17 15:29:56,467:INFO:          deepchecks: Not installed
2024-07-17 15:29:56,467:INFO:             xgboost: Not installed
2024-07-17 15:29:56,467:INFO:            catboost: Not installed
2024-07-17 15:29:56,467:INFO:              kmodes: Not installed
2024-07-17 15:29:56,467:INFO:             mlxtend: Not installed
2024-07-17 15:29:56,467:INFO:       statsforecast: Not installed
2024-07-17 15:29:56,467:INFO:        tune_sklearn: Not installed
2024-07-17 15:29:56,467:INFO:                 ray: Not installed
2024-07-17 15:29:56,467:INFO:            hyperopt: Not installed
2024-07-17 15:29:56,467:INFO:              optuna: Not installed
2024-07-17 15:29:56,467:INFO:               skopt: Not installed
2024-07-17 15:29:56,467:INFO:              mlflow: Not installed
2024-07-17 15:29:56,467:INFO:              gradio: Not installed
2024-07-17 15:29:56,467:INFO:             fastapi: Not installed
2024-07-17 15:29:56,467:INFO:             uvicorn: Not installed
2024-07-17 15:29:56,467:INFO:              m2cgen: Not installed
2024-07-17 15:29:56,467:INFO:           evidently: Not installed
2024-07-17 15:29:56,467:INFO:               fugue: Not installed
2024-07-17 15:29:56,467:INFO:           streamlit: Not installed
2024-07-17 15:29:56,467:INFO:             prophet: Not installed
2024-07-17 15:29:56,467:INFO:None
2024-07-17 15:29:56,467:INFO:Set up data.
2024-07-17 15:29:56,549:INFO:Set up folding strategy.
2024-07-17 15:29:56,549:INFO:Set up train/test split.
2024-07-17 15:29:56,818:INFO:Set up index.
2024-07-17 15:29:56,859:INFO:Assigning column types.
2024-07-17 15:29:56,945:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-17 15:29:57,005:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-17 15:29:57,017:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-17 15:29:57,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:29:57,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:29:57,111:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-17 15:29:57,111:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-17 15:29:57,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:29:57,141:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:29:57,141:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-17 15:29:57,189:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-17 15:29:57,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:29:57,217:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:29:57,264:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-17 15:29:57,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:29:57,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:29:57,293:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-17 15:29:57,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:29:57,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:29:57,437:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:29:57,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:29:57,439:INFO:Preparing preprocessing pipeline...
2024-07-17 15:29:57,457:INFO:Set up simple imputation.
2024-07-17 15:29:57,793:INFO:Set up encoding of ordinal features.
2024-07-17 15:29:57,822:INFO:Set up encoding of categorical features.
2024-07-17 15:29:57,823:INFO:Set up column transformation.
2024-07-17 15:29:57,823:INFO:Set up feature normalization.
2024-07-17 15:29:59,207:INFO:Finished creating preprocessing pipeline.
2024-07-17 15:29:59,223:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-07-17 15:29:59,223:INFO:Creating final display dataframe.
2024-07-17 15:30:00,524:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target              mau
2                   Target type           Binary
3           Original data shape     (600000, 13)
4        Transformed data shape     (600000, 30)
5   Transformed train set shape     (420000, 30)
6    Transformed test set shape     (180000, 30)
7              Numeric features                5
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Transformation             True
16        Transformation method         quantile
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           credit
25                          USI             6ebd
2024-07-17 15:30:00,601:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:30:00,601:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:30:00,669:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:30:00,670:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:30:00,671:INFO:setup() successfully completed in 4.73s...............
2024-07-17 15:30:00,680:INFO:gpu_param set to False
2024-07-17 15:30:00,750:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:30:00,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:30:00,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:30:00,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-17 15:30:00,833:INFO:Initializing create_model()
2024-07-17 15:30:00,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C72E9E6B50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-17 15:30:00,834:INFO:Checking exceptions
2024-07-17 15:30:00,856:INFO:Importing libraries
2024-07-17 15:30:00,856:INFO:Copying training dataset
2024-07-17 15:30:01,143:INFO:Defining folds
2024-07-17 15:30:01,143:INFO:Declaring metric variables
2024-07-17 15:30:01,147:INFO:Importing untrained model
2024-07-17 15:30:01,151:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-17 15:30:01,158:INFO:Starting cross validation
2024-07-17 15:30:01,161:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-17 15:30:29,642:INFO:Calculating mean and std
2024-07-17 15:30:29,653:INFO:Creating metrics dataframe
2024-07-17 15:30:29,678:INFO:Finalizing model
2024-07-17 15:30:37,446:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-17 15:30:37,448:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-17 15:30:37,509:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024288 seconds.
2024-07-17 15:30:37,509:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-17 15:30:37,509:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-17 15:30:37,509:INFO:[LightGBM] [Info] Total Bins 643
2024-07-17 15:30:37,509:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-17 15:30:37,512:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-17 15:30:37,513:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-17 15:30:38,057:INFO:Uploading results into container
2024-07-17 15:30:38,058:INFO:Uploading model into container now
2024-07-17 15:30:38,075:INFO:_master_model_container: 1
2024-07-17 15:30:38,075:INFO:_display_container: 2
2024-07-17 15:30:38,076:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-17 15:30:38,077:INFO:create_model() successfully completed......................................
2024-07-17 15:30:38,502:INFO:Initializing tune_model()
2024-07-17 15:30:38,503:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C72E9E6B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=1, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-17 15:30:38,503:INFO:Checking exceptions
2024-07-17 15:30:38,660:INFO:Copying training dataset
2024-07-17 15:30:38,846:INFO:Checking base model
2024-07-17 15:30:38,846:INFO:Base model : Light Gradient Boosting Machine
2024-07-17 15:30:38,851:INFO:Declaring metric variables
2024-07-17 15:30:38,854:INFO:Defining Hyperparameters
2024-07-17 15:30:39,021:INFO:Tuning with n_jobs=-1
2024-07-17 15:30:39,021:INFO:Initializing RandomizedSearchCV
2024-07-17 15:31:01,271:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.7}
2024-07-17 15:31:01,273:INFO:Hyperparameter search completed
2024-07-17 15:31:01,273:INFO:SubProcess create_model() called ==================================
2024-07-17 15:31:01,274:INFO:Initializing create_model()
2024-07-17 15:31:01,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C72E9E6B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C74A9561D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 3, 'num_leaves': 256, 'n_estimators': 30, 'min_split_gain': 0.2, 'min_child_samples': 1, 'learning_rate': 0.0005, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.7})
2024-07-17 15:31:01,274:INFO:Checking exceptions
2024-07-17 15:31:01,274:INFO:Importing libraries
2024-07-17 15:31:01,274:INFO:Copying training dataset
2024-07-17 15:31:01,563:INFO:Defining folds
2024-07-17 15:31:01,563:INFO:Declaring metric variables
2024-07-17 15:31:01,568:INFO:Importing untrained model
2024-07-17 15:31:01,568:INFO:Declaring custom model
2024-07-17 15:31:01,573:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-17 15:31:01,580:INFO:Starting cross validation
2024-07-17 15:31:01,582:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-17 15:31:20,643:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-17 15:31:21,512:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-17 15:31:21,525:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-17 15:31:21,551:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-17 15:31:21,761:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-17 15:31:21,975:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-17 15:31:22,076:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-17 15:31:22,107:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-17 15:31:22,129:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-17 15:31:22,320:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-17 15:31:22,459:INFO:Calculating mean and std
2024-07-17 15:31:22,460:INFO:Creating metrics dataframe
2024-07-17 15:31:22,471:INFO:Finalizing model
2024-07-17 15:31:29,812:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-17 15:31:29,812:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-17 15:31:29,812:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-17 15:31:30,072:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-17 15:31:30,072:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-17 15:31:30,072:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-17 15:31:30,072:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-17 15:31:30,073:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-17 15:31:30,139:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018923 seconds.
2024-07-17 15:31:30,139:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-17 15:31:30,139:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-17 15:31:30,139:INFO:[LightGBM] [Info] Total Bins 647
2024-07-17 15:31:30,140:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 29
2024-07-17 15:31:30,145:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-17 15:31:30,145:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-17 15:31:30,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-17 15:31:30,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-17 15:31:30,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-17 15:31:30,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-17 15:31:30,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-17 15:31:30,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-17 15:31:30,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-17 15:31:30,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-17 15:31:30,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-17 15:31:30,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-17 15:31:30,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-17 15:31:31,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-17 15:31:31,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-17 15:31:31,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-17 15:31:31,104:INFO:Uploading results into container
2024-07-17 15:31:31,105:INFO:Uploading model into container now
2024-07-17 15:31:31,105:INFO:_master_model_container: 2
2024-07-17 15:31:31,106:INFO:_display_container: 3
2024-07-17 15:31:31,107:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-17 15:31:31,107:INFO:create_model() successfully completed......................................
2024-07-17 15:31:31,360:INFO:SubProcess create_model() end ==================================
2024-07-17 15:31:31,360:INFO:choose_better activated
2024-07-17 15:31:31,363:INFO:SubProcess create_model() called ==================================
2024-07-17 15:31:31,364:INFO:Initializing create_model()
2024-07-17 15:31:31,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C72E9E6B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-17 15:31:31,364:INFO:Checking exceptions
2024-07-17 15:31:31,366:INFO:Importing libraries
2024-07-17 15:31:31,366:INFO:Copying training dataset
2024-07-17 15:31:31,638:INFO:Defining folds
2024-07-17 15:31:31,638:INFO:Declaring metric variables
2024-07-17 15:31:31,638:INFO:Importing untrained model
2024-07-17 15:31:31,638:INFO:Declaring custom model
2024-07-17 15:31:31,639:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-17 15:31:31,640:INFO:Starting cross validation
2024-07-17 15:31:31,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-17 15:31:50,306:INFO:Calculating mean and std
2024-07-17 15:31:50,307:INFO:Creating metrics dataframe
2024-07-17 15:31:50,309:INFO:Finalizing model
2024-07-17 15:31:58,115:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-17 15:31:58,115:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-17 15:31:58,177:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022740 seconds.
2024-07-17 15:31:58,177:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-17 15:31:58,177:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-17 15:31:58,178:INFO:[LightGBM] [Info] Total Bins 643
2024-07-17 15:31:58,178:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-17 15:31:58,181:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-17 15:31:58,181:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-17 15:31:58,686:INFO:Uploading results into container
2024-07-17 15:31:58,686:INFO:Uploading model into container now
2024-07-17 15:31:58,687:INFO:_master_model_container: 3
2024-07-17 15:31:58,687:INFO:_display_container: 4
2024-07-17 15:31:58,688:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-17 15:31:58,688:INFO:create_model() successfully completed......................................
2024-07-17 15:31:58,870:INFO:SubProcess create_model() end ==================================
2024-07-17 15:31:58,871:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0113
2024-07-17 15:31:58,871:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0
2024-07-17 15:31:58,872:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-07-17 15:31:58,872:INFO:choose_better completed
2024-07-17 15:31:58,872:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-17 15:31:58,889:INFO:_master_model_container: 3
2024-07-17 15:31:58,889:INFO:_display_container: 3
2024-07-17 15:31:58,890:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-17 15:31:58,890:INFO:tune_model() successfully completed......................................
2024-07-17 15:31:59,066:INFO:Initializing plot_model()
2024-07-17 15:31:59,066:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C72E9E6B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-17 15:31:59,066:INFO:Checking exceptions
2024-07-17 15:31:59,171:INFO:Preloading libraries
2024-07-17 15:31:59,179:INFO:Copying training dataset
2024-07-17 15:31:59,179:INFO:Plot type: auc
2024-07-17 15:32:00,223:INFO:Fitting Model
2024-07-17 15:32:00,234:INFO:Scoring test/hold-out set
2024-07-17 15:32:00,896:INFO:Visual Rendered Successfully
2024-07-17 15:32:01,069:INFO:plot_model() successfully completed......................................
2024-07-17 15:32:01,087:INFO:Initializing plot_model()
2024-07-17 15:32:01,087:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C72E9E6B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-17 15:32:01,087:INFO:Checking exceptions
2024-07-17 15:32:01,183:INFO:Preloading libraries
2024-07-17 15:32:01,191:INFO:Copying training dataset
2024-07-17 15:32:01,191:INFO:Plot type: pr
2024-07-17 15:32:02,180:INFO:Fitting Model
2024-07-17 15:32:02,194:INFO:Scoring test/hold-out set
2024-07-17 15:32:02,708:INFO:Visual Rendered Successfully
2024-07-17 15:32:02,875:INFO:plot_model() successfully completed......................................
2024-07-17 15:32:02,893:INFO:Initializing plot_model()
2024-07-17 15:32:02,893:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C72E9E6B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-17 15:32:02,893:INFO:Checking exceptions
2024-07-17 15:32:02,989:INFO:Preloading libraries
2024-07-17 15:32:02,996:INFO:Copying training dataset
2024-07-17 15:32:02,996:INFO:Plot type: feature
2024-07-17 15:32:02,997:WARNING:No coef_ found. Trying feature_importances_
2024-07-17 15:32:03,487:INFO:Visual Rendered Successfully
2024-07-17 15:32:03,657:INFO:plot_model() successfully completed......................................
2024-07-17 15:32:03,679:INFO:Initializing plot_model()
2024-07-17 15:32:03,680:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C72E9E6B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-17 15:32:03,680:INFO:Checking exceptions
2024-07-17 15:32:03,786:INFO:Preloading libraries
2024-07-17 15:32:03,794:INFO:Copying training dataset
2024-07-17 15:32:03,794:INFO:Plot type: confusion_matrix
2024-07-17 15:32:04,781:INFO:Fitting Model
2024-07-17 15:32:04,786:INFO:Scoring test/hold-out set
2024-07-17 15:32:05,149:INFO:Visual Rendered Successfully
2024-07-17 15:32:05,314:INFO:plot_model() successfully completed......................................
2024-07-17 15:32:05,376:INFO:Initializing predict_model()
2024-07-17 15:32:05,376:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C72E9E6B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C72BA29800>)
2024-07-17 15:32:05,376:INFO:Checking exceptions
2024-07-17 15:32:05,376:INFO:Preloading libraries
2024-07-17 15:32:06,804:INFO:Initializing finalize_model()
2024-07-17 15:32:06,804:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C72E9E6B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-17 15:32:06,805:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-17 15:32:06,866:INFO:Initializing create_model()
2024-07-17 15:32:06,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C72E9E6B50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-17 15:32:06,866:INFO:Checking exceptions
2024-07-17 15:32:06,867:INFO:Importing libraries
2024-07-17 15:32:06,867:INFO:Copying training dataset
2024-07-17 15:32:06,877:INFO:Defining folds
2024-07-17 15:32:06,877:INFO:Declaring metric variables
2024-07-17 15:32:06,877:INFO:Importing untrained model
2024-07-17 15:32:06,877:INFO:Declaring custom model
2024-07-17 15:32:06,878:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-17 15:32:06,880:INFO:Cross validation set to False
2024-07-17 15:32:06,880:INFO:Fitting Model
2024-07-17 15:32:17,735:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-17 15:32:17,736:INFO:[LightGBM] [Info] Number of positive: 36643, number of negative: 563357
2024-07-17 15:32:17,848:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030041 seconds.
2024-07-17 15:32:17,848:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-17 15:32:17,849:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-17 15:32:17,851:INFO:[LightGBM] [Info] Total Bins 642
2024-07-17 15:32:17,852:INFO:[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 27
2024-07-17 15:32:17,855:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061072 -> initscore=-2.732691
2024-07-17 15:32:17,855:INFO:[LightGBM] [Info] Start training from score -2.732691
2024-07-17 15:32:18,631:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-17 15:32:18,631:INFO:create_model() successfully completed......................................
2024-07-17 15:32:18,785:INFO:_master_model_container: 3
2024-07-17 15:32:18,785:INFO:_display_container: 4
2024-07-17 15:32:18,801:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-17 15:32:18,801:INFO:finalize_model() successfully completed......................................
2024-07-17 15:32:19,033:INFO:Initializing predict_model()
2024-07-17 15:32:19,034:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C72E9E6B50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C74A388D60>)
2024-07-17 15:32:19,034:INFO:Checking exceptions
2024-07-17 15:32:19,034:INFO:Preloading libraries
2024-07-17 15:32:19,036:INFO:Set up data.
2024-07-17 15:32:19,070:INFO:Set up index.
2024-07-17 15:32:21,758:INFO:Initializing save_model()
2024-07-17 15:32:21,758:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=Final Light GBM Model Jul2024, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-17 15:32:21,759:INFO:Adding model into prep_pipe
2024-07-17 15:32:21,759:WARNING:Only Model saved as it was a pipeline.
2024-07-17 15:32:21,785:INFO:Final Light GBM Model Jul2024.pkl saved in current working directory
2024-07-17 15:32:21,807:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-17 15:32:21,807:INFO:save_model() successfully completed......................................
2024-07-18 10:16:41,196:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 10:16:41,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 10:16:41,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 10:16:41,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 10:16:44,427:INFO:PyCaret ClassificationExperiment
2024-07-18 10:16:44,428:INFO:Logging name: credit
2024-07-18 10:16:44,428:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-18 10:16:44,428:INFO:version 3.3.2
2024-07-18 10:16:44,428:INFO:Initializing setup()
2024-07-18 10:16:44,428:INFO:self.USI: d6bf
2024-07-18 10:16:44,428:INFO:self._variable_keys: {'fold_shuffle_param', '_ml_usecase', 'pipeline', 'X_test', 'n_jobs_param', 'fold_generator', '_available_plots', 'fix_imbalance', 'memory', 'X', 'is_multiclass', 'USI', 'fold_groups_param', 'gpu_n_jobs_param', 'log_plots_param', 'logging_param', 'seed', 'exp_id', 'data', 'y_train', 'y_test', 'X_train', 'target_param', 'html_param', 'gpu_param', 'y', 'exp_name_log', 'idx'}
2024-07-18 10:16:44,428:INFO:Checking environment
2024-07-18 10:16:44,428:INFO:python_version: 3.11.7
2024-07-18 10:16:44,428:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2024-07-18 10:16:44,428:INFO:machine: AMD64
2024-07-18 10:16:44,428:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-18 10:16:44,434:INFO:Memory: svmem(total=16849293312, available=4156620800, percent=75.3, used=12692672512, free=4156620800)
2024-07-18 10:16:44,434:INFO:Physical Core: 12
2024-07-18 10:16:44,435:INFO:Logical Core: 16
2024-07-18 10:16:44,435:INFO:Checking libraries
2024-07-18 10:16:44,435:INFO:System:
2024-07-18 10:16:44,435:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2024-07-18 10:16:44,435:INFO:executable: c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\python.exe
2024-07-18 10:16:44,436:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-18 10:16:44,436:INFO:PyCaret required dependencies:
2024-07-18 10:16:44,489:INFO:                 pip: 24.1.2
2024-07-18 10:16:44,489:INFO:          setuptools: 65.5.0
2024-07-18 10:16:44,490:INFO:             pycaret: 3.3.2
2024-07-18 10:16:44,490:INFO:             IPython: 8.26.0
2024-07-18 10:16:44,490:INFO:          ipywidgets: 8.1.3
2024-07-18 10:16:44,490:INFO:                tqdm: 4.66.4
2024-07-18 10:16:44,490:INFO:               numpy: 1.26.4
2024-07-18 10:16:44,490:INFO:              pandas: 2.1.4
2024-07-18 10:16:44,490:INFO:              jinja2: 3.1.4
2024-07-18 10:16:44,490:INFO:               scipy: 1.11.4
2024-07-18 10:16:44,490:INFO:              joblib: 1.3.2
2024-07-18 10:16:44,490:INFO:             sklearn: 1.4.2
2024-07-18 10:16:44,490:INFO:                pyod: 2.0.1
2024-07-18 10:16:44,490:INFO:            imblearn: 0.12.3
2024-07-18 10:16:44,490:INFO:   category_encoders: 2.6.3
2024-07-18 10:16:44,490:INFO:            lightgbm: 4.4.0
2024-07-18 10:16:44,490:INFO:               numba: 0.60.0
2024-07-18 10:16:44,490:INFO:            requests: 2.32.3
2024-07-18 10:16:44,490:INFO:          matplotlib: 3.7.5
2024-07-18 10:16:44,490:INFO:          scikitplot: 0.3.7
2024-07-18 10:16:44,490:INFO:         yellowbrick: 1.5
2024-07-18 10:16:44,490:INFO:              plotly: 5.22.0
2024-07-18 10:16:44,490:INFO:    plotly-resampler: Not installed
2024-07-18 10:16:44,490:INFO:             kaleido: 0.2.1
2024-07-18 10:16:44,490:INFO:           schemdraw: 0.15
2024-07-18 10:16:44,490:INFO:         statsmodels: 0.14.2
2024-07-18 10:16:44,490:INFO:              sktime: 0.26.0
2024-07-18 10:16:44,490:INFO:               tbats: 1.1.3
2024-07-18 10:16:44,490:INFO:            pmdarima: 2.0.4
2024-07-18 10:16:44,490:INFO:              psutil: 6.0.0
2024-07-18 10:16:44,490:INFO:          markupsafe: 2.1.5
2024-07-18 10:16:44,490:INFO:             pickle5: Not installed
2024-07-18 10:16:44,491:INFO:         cloudpickle: 3.0.0
2024-07-18 10:16:44,491:INFO:         deprecation: 2.1.0
2024-07-18 10:16:44,491:INFO:              xxhash: 3.4.1
2024-07-18 10:16:44,491:INFO:           wurlitzer: Not installed
2024-07-18 10:16:44,491:INFO:PyCaret optional dependencies:
2024-07-18 10:16:44,503:INFO:                shap: Not installed
2024-07-18 10:16:44,503:INFO:           interpret: Not installed
2024-07-18 10:16:44,503:INFO:                umap: Not installed
2024-07-18 10:16:44,503:INFO:     ydata_profiling: Not installed
2024-07-18 10:16:44,503:INFO:  explainerdashboard: Not installed
2024-07-18 10:16:44,503:INFO:             autoviz: Not installed
2024-07-18 10:16:44,503:INFO:           fairlearn: Not installed
2024-07-18 10:16:44,503:INFO:          deepchecks: Not installed
2024-07-18 10:16:44,503:INFO:             xgboost: Not installed
2024-07-18 10:16:44,503:INFO:            catboost: Not installed
2024-07-18 10:16:44,503:INFO:              kmodes: Not installed
2024-07-18 10:16:44,503:INFO:             mlxtend: Not installed
2024-07-18 10:16:44,503:INFO:       statsforecast: Not installed
2024-07-18 10:16:44,503:INFO:        tune_sklearn: Not installed
2024-07-18 10:16:44,503:INFO:                 ray: Not installed
2024-07-18 10:16:44,503:INFO:            hyperopt: Not installed
2024-07-18 10:16:44,504:INFO:              optuna: Not installed
2024-07-18 10:16:44,504:INFO:               skopt: Not installed
2024-07-18 10:16:44,504:INFO:              mlflow: Not installed
2024-07-18 10:16:44,504:INFO:              gradio: Not installed
2024-07-18 10:16:44,504:INFO:             fastapi: Not installed
2024-07-18 10:16:44,504:INFO:             uvicorn: Not installed
2024-07-18 10:16:44,504:INFO:              m2cgen: Not installed
2024-07-18 10:16:44,504:INFO:           evidently: Not installed
2024-07-18 10:16:44,504:INFO:               fugue: Not installed
2024-07-18 10:16:44,504:INFO:           streamlit: Not installed
2024-07-18 10:16:44,504:INFO:             prophet: Not installed
2024-07-18 10:16:44,504:INFO:None
2024-07-18 10:16:44,504:INFO:Set up data.
2024-07-18 10:16:44,583:INFO:Set up folding strategy.
2024-07-18 10:16:44,583:INFO:Set up train/test split.
2024-07-18 10:16:44,847:INFO:Set up index.
2024-07-18 10:16:44,883:INFO:Assigning column types.
2024-07-18 10:16:44,970:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-18 10:16:45,014:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-18 10:16:45,021:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 10:16:45,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:45,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:45,114:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-18 10:16:45,115:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 10:16:45,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:45,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:45,144:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-18 10:16:45,189:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 10:16:45,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:45,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:45,265:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 10:16:45,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:45,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:45,292:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-18 10:16:45,363:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:45,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:45,435:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:45,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:45,438:INFO:Preparing preprocessing pipeline...
2024-07-18 10:16:45,465:INFO:Set up simple imputation.
2024-07-18 10:16:45,820:INFO:Set up encoding of ordinal features.
2024-07-18 10:16:45,850:INFO:Set up encoding of categorical features.
2024-07-18 10:16:45,851:INFO:Set up column transformation.
2024-07-18 10:16:45,851:INFO:Set up feature normalization.
2024-07-18 10:16:47,277:INFO:Finished creating preprocessing pipeline.
2024-07-18 10:16:47,298:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-07-18 10:16:47,298:INFO:Creating final display dataframe.
2024-07-18 10:16:48,728:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target              mau
2                   Target type           Binary
3           Original data shape     (600000, 13)
4        Transformed data shape     (600000, 30)
5   Transformed train set shape     (420000, 30)
6    Transformed test set shape     (180000, 30)
7              Numeric features                5
8          Categorical features                5
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Transformation             True
16        Transformation method         quantile
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           credit
25                          USI             d6bf
2024-07-18 10:16:48,816:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:48,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:48,902:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:48,903:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:48,904:INFO:setup() successfully completed in 4.5s...............
2024-07-18 10:16:48,915:INFO:gpu_param set to False
2024-07-18 10:16:48,992:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:48,993:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:49,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:49,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-18 10:16:49,089:INFO:Initializing create_model()
2024-07-18 10:16:49,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001980A2BC050>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-18 10:16:49,089:INFO:Checking exceptions
2024-07-18 10:16:49,107:INFO:Importing libraries
2024-07-18 10:16:49,107:INFO:Copying training dataset
2024-07-18 10:16:49,404:INFO:Defining folds
2024-07-18 10:16:49,405:INFO:Declaring metric variables
2024-07-18 10:16:49,409:INFO:Importing untrained model
2024-07-18 10:16:49,413:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 10:16:49,421:INFO:Starting cross validation
2024-07-18 10:16:49,424:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 10:17:17,795:INFO:Calculating mean and std
2024-07-18 10:17:17,797:INFO:Creating metrics dataframe
2024-07-18 10:17:17,803:INFO:Finalizing model
2024-07-18 10:17:25,728:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-18 10:17:25,729:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-18 10:17:25,794:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024649 seconds.
2024-07-18 10:17:25,795:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-18 10:17:25,795:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-18 10:17:25,795:INFO:[LightGBM] [Info] Total Bins 643
2024-07-18 10:17:25,796:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-18 10:17:25,798:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-18 10:17:25,798:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-18 10:17:26,344:INFO:Uploading results into container
2024-07-18 10:17:26,346:INFO:Uploading model into container now
2024-07-18 10:17:26,356:INFO:_master_model_container: 1
2024-07-18 10:17:26,357:INFO:_display_container: 2
2024-07-18 10:17:26,357:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-18 10:17:26,358:INFO:create_model() successfully completed......................................
2024-07-18 10:17:26,580:INFO:Initializing tune_model()
2024-07-18 10:17:26,580:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001980A2BC050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=1, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-18 10:17:26,580:INFO:Checking exceptions
2024-07-18 10:17:26,721:INFO:Copying training dataset
2024-07-18 10:17:26,906:INFO:Checking base model
2024-07-18 10:17:26,908:INFO:Base model : Light Gradient Boosting Machine
2024-07-18 10:17:26,911:INFO:Declaring metric variables
2024-07-18 10:17:26,914:INFO:Defining Hyperparameters
2024-07-18 10:17:27,066:INFO:Tuning with n_jobs=-1
2024-07-18 10:17:27,066:INFO:Initializing RandomizedSearchCV
2024-07-18 10:17:49,432:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.7}
2024-07-18 10:17:49,433:INFO:Hyperparameter search completed
2024-07-18 10:17:49,433:INFO:SubProcess create_model() called ==================================
2024-07-18 10:17:49,434:INFO:Initializing create_model()
2024-07-18 10:17:49,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001980A2BC050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001981EA1AA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 3, 'num_leaves': 256, 'n_estimators': 30, 'min_split_gain': 0.2, 'min_child_samples': 1, 'learning_rate': 0.0005, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.7})
2024-07-18 10:17:49,435:INFO:Checking exceptions
2024-07-18 10:17:49,435:INFO:Importing libraries
2024-07-18 10:17:49,435:INFO:Copying training dataset
2024-07-18 10:17:49,749:INFO:Defining folds
2024-07-18 10:17:49,749:INFO:Declaring metric variables
2024-07-18 10:17:49,753:INFO:Importing untrained model
2024-07-18 10:17:49,754:INFO:Declaring custom model
2024-07-18 10:17:49,760:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 10:17:49,770:INFO:Starting cross validation
2024-07-18 10:17:49,773:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 10:18:09,531:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-18 10:18:10,090:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-18 10:18:10,358:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-18 10:18:10,372:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-18 10:18:10,528:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-18 10:18:10,578:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-18 10:18:10,689:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-18 10:18:10,724:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-18 10:18:10,996:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-18 10:18:11,151:WARNING:c:\Users\rafael_doepfer\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-18 10:18:11,294:INFO:Calculating mean and std
2024-07-18 10:18:11,296:INFO:Creating metrics dataframe
2024-07-18 10:18:11,303:INFO:Finalizing model
2024-07-18 10:18:18,882:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-18 10:18:18,882:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-18 10:18:18,882:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-18 10:18:19,140:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-18 10:18:19,141:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-07-18 10:18:19,141:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-07-18 10:18:19,141:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-07-18 10:18:19,141:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-18 10:18:19,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019681 seconds.
2024-07-18 10:18:19,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-18 10:18:19,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-18 10:18:19,201:INFO:[LightGBM] [Info] Total Bins 647
2024-07-18 10:18:19,201:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 29
2024-07-18 10:18:19,208:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-18 10:18:19,208:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-18 10:18:19,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 10:18:19,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 10:18:19,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 10:18:19,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 10:18:19,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 10:18:19,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 10:18:19,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 10:18:19,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 10:18:19,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 10:18:19,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 10:18:20,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 10:18:20,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 10:18:20,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 10:18:20,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 10:18:20,172:INFO:Uploading results into container
2024-07-18 10:18:20,173:INFO:Uploading model into container now
2024-07-18 10:18:20,174:INFO:_master_model_container: 2
2024-07-18 10:18:20,174:INFO:_display_container: 3
2024-07-18 10:18:20,175:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-18 10:18:20,176:INFO:create_model() successfully completed......................................
2024-07-18 10:18:20,440:INFO:SubProcess create_model() end ==================================
2024-07-18 10:18:20,440:INFO:choose_better activated
2024-07-18 10:18:20,444:INFO:SubProcess create_model() called ==================================
2024-07-18 10:18:20,445:INFO:Initializing create_model()
2024-07-18 10:18:20,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001980A2BC050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-18 10:18:20,445:INFO:Checking exceptions
2024-07-18 10:18:20,447:INFO:Importing libraries
2024-07-18 10:18:20,447:INFO:Copying training dataset
2024-07-18 10:18:20,753:INFO:Defining folds
2024-07-18 10:18:20,753:INFO:Declaring metric variables
2024-07-18 10:18:20,753:INFO:Importing untrained model
2024-07-18 10:18:20,753:INFO:Declaring custom model
2024-07-18 10:18:20,754:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 10:18:20,754:INFO:Starting cross validation
2024-07-18 10:18:20,756:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 10:18:39,395:INFO:Calculating mean and std
2024-07-18 10:18:39,395:INFO:Creating metrics dataframe
2024-07-18 10:18:39,398:INFO:Finalizing model
2024-07-18 10:18:47,386:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-18 10:18:47,387:INFO:[LightGBM] [Info] Number of positive: 25650, number of negative: 394350
2024-07-18 10:18:47,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022226 seconds.
2024-07-18 10:18:47,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-18 10:18:47,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-18 10:18:47,455:INFO:[LightGBM] [Info] Total Bins 643
2024-07-18 10:18:47,456:INFO:[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 27
2024-07-18 10:18:47,459:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061071 -> initscore=-2.732695
2024-07-18 10:18:47,459:INFO:[LightGBM] [Info] Start training from score -2.732695
2024-07-18 10:18:48,118:INFO:Uploading results into container
2024-07-18 10:18:48,118:INFO:Uploading model into container now
2024-07-18 10:18:48,119:INFO:_master_model_container: 3
2024-07-18 10:18:48,119:INFO:_display_container: 4
2024-07-18 10:18:48,119:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-18 10:18:48,120:INFO:create_model() successfully completed......................................
2024-07-18 10:18:48,277:INFO:SubProcess create_model() end ==================================
2024-07-18 10:18:48,278:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0113
2024-07-18 10:18:48,279:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=30, n_jobs=-1, num_leaves=256, objective=None,
               random_state=123, reg_alpha=3, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0
2024-07-18 10:18:48,279:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-07-18 10:18:48,279:INFO:choose_better completed
2024-07-18 10:18:48,280:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-18 10:18:48,294:INFO:_master_model_container: 3
2024-07-18 10:18:48,294:INFO:_display_container: 3
2024-07-18 10:18:48,294:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-18 10:18:48,294:INFO:tune_model() successfully completed......................................
2024-07-18 10:18:48,497:INFO:Initializing plot_model()
2024-07-18 10:18:48,497:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001980A2BC050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-18 10:18:48,497:INFO:Checking exceptions
2024-07-18 10:18:48,602:INFO:Preloading libraries
2024-07-18 10:18:48,610:INFO:Copying training dataset
2024-07-18 10:18:48,610:INFO:Plot type: auc
2024-07-18 10:18:49,714:INFO:Fitting Model
2024-07-18 10:18:49,730:INFO:Scoring test/hold-out set
2024-07-18 10:18:50,385:INFO:Visual Rendered Successfully
2024-07-18 10:18:50,555:INFO:plot_model() successfully completed......................................
2024-07-18 10:18:50,574:INFO:Initializing plot_model()
2024-07-18 10:18:50,574:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001980A2BC050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-18 10:18:50,574:INFO:Checking exceptions
2024-07-18 10:18:50,674:INFO:Preloading libraries
2024-07-18 10:18:50,682:INFO:Copying training dataset
2024-07-18 10:18:50,682:INFO:Plot type: pr
2024-07-18 10:18:51,688:INFO:Fitting Model
2024-07-18 10:18:51,704:INFO:Scoring test/hold-out set
2024-07-18 10:18:52,256:INFO:Visual Rendered Successfully
2024-07-18 10:18:52,423:INFO:plot_model() successfully completed......................................
2024-07-18 10:18:52,444:INFO:Initializing plot_model()
2024-07-18 10:18:52,444:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001980A2BC050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-18 10:18:52,444:INFO:Checking exceptions
2024-07-18 10:18:52,547:INFO:Preloading libraries
2024-07-18 10:18:52,553:INFO:Copying training dataset
2024-07-18 10:18:52,554:INFO:Plot type: feature
2024-07-18 10:18:52,554:WARNING:No coef_ found. Trying feature_importances_
2024-07-18 10:18:53,080:INFO:Visual Rendered Successfully
2024-07-18 10:18:53,248:INFO:plot_model() successfully completed......................................
2024-07-18 10:18:53,268:INFO:Initializing plot_model()
2024-07-18 10:18:53,268:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001980A2BC050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-18 10:18:53,268:INFO:Checking exceptions
2024-07-18 10:18:53,393:INFO:Preloading libraries
2024-07-18 10:18:53,401:INFO:Copying training dataset
2024-07-18 10:18:53,401:INFO:Plot type: confusion_matrix
2024-07-18 10:18:54,452:INFO:Fitting Model
2024-07-18 10:18:54,460:INFO:Scoring test/hold-out set
2024-07-18 10:18:54,871:INFO:Visual Rendered Successfully
2024-07-18 10:18:55,040:INFO:plot_model() successfully completed......................................
2024-07-18 10:18:55,103:INFO:Initializing predict_model()
2024-07-18 10:18:55,104:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001980A2BC050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000019869DC39C0>)
2024-07-18 10:18:55,104:INFO:Checking exceptions
2024-07-18 10:18:55,104:INFO:Preloading libraries
2024-07-18 10:18:56,678:INFO:Initializing finalize_model()
2024-07-18 10:18:56,678:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001980A2BC050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-18 10:18:56,678:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-18 10:18:56,751:INFO:Initializing create_model()
2024-07-18 10:18:56,751:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001980A2BC050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-18 10:18:56,752:INFO:Checking exceptions
2024-07-18 10:18:56,753:INFO:Importing libraries
2024-07-18 10:18:56,755:INFO:Copying training dataset
2024-07-18 10:18:56,766:INFO:Defining folds
2024-07-18 10:18:56,766:INFO:Declaring metric variables
2024-07-18 10:18:56,766:INFO:Importing untrained model
2024-07-18 10:18:56,766:INFO:Declaring custom model
2024-07-18 10:18:56,767:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 10:18:56,769:INFO:Cross validation set to False
2024-07-18 10:18:56,770:INFO:Fitting Model
2024-07-18 10:19:08,580:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-18 10:19:08,582:INFO:[LightGBM] [Info] Number of positive: 36643, number of negative: 563357
2024-07-18 10:19:08,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034425 seconds.
2024-07-18 10:19:08,699:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-18 10:19:08,699:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-18 10:19:08,701:INFO:[LightGBM] [Info] Total Bins 642
2024-07-18 10:19:08,701:INFO:[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 27
2024-07-18 10:19:08,705:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061072 -> initscore=-2.732691
2024-07-18 10:19:08,705:INFO:[LightGBM] [Info] Start training from score -2.732691
2024-07-18 10:19:09,533:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-18 10:19:09,533:INFO:create_model() successfully completed......................................
2024-07-18 10:19:09,696:INFO:_master_model_container: 3
2024-07-18 10:19:09,696:INFO:_display_container: 4
2024-07-18 10:19:09,713:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-18 10:19:09,713:INFO:finalize_model() successfully completed......................................
2024-07-18 10:19:09,957:INFO:Initializing predict_model()
2024-07-18 10:19:09,958:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001980A2BC050>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001982353B6A0>)
2024-07-18 10:19:09,958:INFO:Checking exceptions
2024-07-18 10:19:09,958:INFO:Preloading libraries
2024-07-18 10:19:09,961:INFO:Set up data.
2024-07-18 10:19:10,008:INFO:Set up index.
2024-07-18 10:19:12,596:INFO:Initializing save_model()
2024-07-18 10:19:12,596:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=Final Light GBM Model Jul2024, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\RAFAEL~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=123,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 10:19:12,596:INFO:Adding model into prep_pipe
2024-07-18 10:19:12,597:WARNING:Only Model saved as it was a pipeline.
2024-07-18 10:19:12,614:INFO:Final Light GBM Model Jul2024.pkl saved in current working directory
2024-07-18 10:19:12,638:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-18 10:19:12,638:INFO:save_model() successfully completed......................................
